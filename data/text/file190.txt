
	
	
		
COMPARISON OF PREDICTIVE MODELING METHODS OF AIRCRAFT LANDING SPEEDOusmane N. Diallo, Ph.D
Ames Research Center
SUMMARYExpected increases in air traffic demand have stimulated the development of air traffic control tools intended to assist the air traffic controller in accurately and precisely spacing aircraft landing at congested airports.Such tools will require an accurate landing-speed prediction to increase throughput while decreasing necessary controller interventions for avoiding separation violations.There are many practical challenges to developing an accurate landing-speed model that has acceptable prediction errors.This paper discusses the development of a near-term implementation, using readily available information, to estimate/model final approach speed from the top of the descent phase of flight to the landing runway.As a first approach, all variables found to contribute directly to the landing-speed prediction model are used to build a multi-regression technique of the response surface equation (RSE).Data obtained from operations of a major airlines for a passenger transport aircraft type to the Dallas/Fort Worth International Airport are used to predict the landing speed.The approach was promising because it decreased the standard deviation of the landing-speed error prediction by at least 18% from the standard deviation of the baseline error, depending on the gust condition at the airport.However, when the number of variables is reduced to the most likely obtainable at other major airports, the RSE model shows little improvement over the existing methods.Consequently, a neural network that relies on a nonlinear regression technique is utilized as an alternative modeling approach.For the reduced number of variables cases, the standard deviation of the neural network models errors represent over 5% reduction compared to the RSE model errors, and at least 10% reduction over the baseline predicted landing-speed error standard deviation.Overall, the constructed models predict the landing-speed more accurately and precisely than the current state-of-the-art.
INTRODUCTIONOne of the goals of our nation's Next-Generation Air Transportation System (NextGen) is the accommodation of an expected traffic-demand increase in the already congested terminal airspace (ref.1).To meet that objective in the near term, there is a need to create tools to predict separation violations in order to plan conflict-resolution strategies.Overall, there are two categories of tools for the final approach: tools that maximize throughput such as the Traffic Management Advisor (TMA) (ref.Independent of the decision support tool used, accurate landing-speed estimates are needed to provide accurate space between successive arriving aircraft because all the tools rely on predictions of the flight-path of the aircraft.The air traffic controllers' practice and procedures dictate aircraft speed throughout most of the airspace, but the flight crew (and aircraft procedures) dictates the speed on approach in preparation for landing.Therefore, accurate landing-speed prediction will be required for tools intended for use on final approach.Uncertainty in landing speed is manifested as either an increase in separation violations or as increased separation buffers (leading to reduced throughput).There exist many different approaches to establish the landing speed of an aircraft to be used in the decision support tools.However, most of the options would require an upgrade to avionics equipment or a flight crew to verbally report landing speed, thereby increasing the workload for both the flight crew and the controllers.Thus, to fulfill the goal of this work for near-term implementation with no additional equipment requirement, the focus of this research is to develop an accurate landing-speed model based on information that is readily available in today's air traffic control system.As a first choice, the multivariable regression technique based on the response surface equation (RSE) is used to develop a statistical model of aircraft approach speed.The regression technique employed data for descent and approach phases of flight, as well as environmental and airport characteristics data.The MD80 (SP80) aircraft characteristics and the physical characteristics data of the Dallas/Fort Worth International Airport (DFW) provide a test bed to implement the proposed statistical modeling approach.There is a trade-off between the amount of information needed to build the model and its accuracy.Then, as a need to expand the study to other major airports arises, the modeling approach is restricted to input variables that are more likely to be available (airlines internal data are usually difficult to obtain).However, because with the reduced number of variables the RSE performs poorly, an alternative approach, the feed-forward neural network, is developed.The remainder of the paper is organized as follows: Section 2 sets the context, background, and motivation for the problem addressed.Section 3 presents the modeling methodologies.Then section 4 summarizes the current state-of-the-art or baseline for the landing-speed prediction.In section 5 the modeling methodologies are applied to actual recorded data, and the results are presented and discussed.Finally, section 6 summarizes the findings.
BACKGROUND AND MOTIVATION
BackgroundNextGen is the Federal Aviation Administration (FAA)'s plan to modernize the National Airspace System (NAS) in order to increase its capacity by 2025.While the plan projects an increase in the traffic demand, which would exceed the current capacity of the NAS, there are concerns about the increase in air traffic controllers' workload.The air traffic controllers' function is to guide aircraft from departure to destination safely and efficiently.There is a need to create tools that can facilitate and strengthen the air traffic controllers' decision process, while not compromising the safety requirement.This paper focuses on tools in the terminal environment, specifically those that address separation between successive arrivals.To maintain runway arrival throughput, controllers sequence aircraft as they approach the airport for landing and try to ensure there are no separation violations between any pair of aircraft.The task of separating aircraft becomes increasingly complex in highly congested terminal airspace (ref.6).Research in the field of air traffic management (ATM) investigates ways to automate separation assurance, to predict potential future violations, and to develop procedures to avoid such violations.Conflict prediction and resolution tools require the estimation of the landing speed of an aircraft to construct an accurate trajectory from its current position to the runway threshold.As a pair of successive arriving aircraft approaches the landing runway, there is a natural process of compression of the distance between the pair when the leading aircraft is slowed ahead of the trailing aircraft (ref.7).Knowledge of the landing speed of the leading aircraft is required for determination of the approach-speed profile of the trailing aircraft.Since the air traffic controller does not prescribe a landing speed, those data must either come from the aircraft or be estimated.Landing-speed estimation must be accurate to be used effectively by the different air traffic control (ATC) tools.
MotivationThe main objective of this work is to build a landing-speed model based on variables readily available in today's air traffic automation systems.A landing-speed model is necessary because for a given pair of aircraft on final approach, the leading aircraft landing-speed must be predicted with sufficient lead time to allow tools to prescribe trajectory changes to be communicated to the trailing aircraft to avoid separation violations, with a potential risk of wake vortex hazards if too little separation is prescribed.To mitigate the impact of inaccurate landing-speed estimates and to account for uncertainty of trajectory prediction, it is common for air traffic controllers to add excess separation between pairs of aircraft, leading directly to loss of runway throughput.There are three viable options to consider when determining the landing speed of an aircraft:1.The intended landing speed can be electronically communicated (e.g., via ADS-B message data) to controllers by the flight crew.This approach would require special avionics.2. Controllers could verbally request the landing speed from the flight crew and input it in an interactive tool.This approach could increase the controller's and/or flight crew's workload.3. A model can be built to estimate the landing speed of the aircraft.The first two options require changes to the ground equipment and/or controller procedures: significant undertakings that could face resistance in their implementation.This paper focuses on the third option, which concentrates on near-term implementation, using readily available information to estimate the landing speed.
MODELING METHODOLOGIESWhile there are many data-driven modeling techniques that can be used to build predictive models, all of them rely on the quality of the raw data and processing approach utilized.To be useful, raw data typically need to go through a thorough cleaning-up process.
Data Selection and ProcessingThis paper proposes to predict a landing-speed estimate using regression of multi-variables to fit contributing inputs to corresponding historical landing speed as output.The first step of any such data-driven technique is data collection and processing.Although there are many different ways to collect and process historical data, a methodical approach leveraging previous work (ref.8) is used and summarized as follows:
Data CollectionThe first step of a model development consists of identifying and collecting as many variables as possible to make sure no impactful variables are overlooked.Thus, for this landing-speed modeling, a model is built for a specific aircraft type at a given airport because each airport has its specific characteristics.The raw data are composed of all airline monitored flight parameters (e.g., fuel consumption, aircraft weight, etc.), radar recorded data (e.g., ground speed, etc.) and airport environmental conditions (e.g., wind, visibility, ceiling, etc.).
ScreeningThe screening step is important to center the analysis on variables that directly impact the modeling task.Thus, the screening is necessary to get rid of duplicative and unnecessary information for the model.This step serves to detect the parameters that contribute the most to the landing-speed behavior.Also, during the screening step obvious parameters with no impact (e.g., departure airport, etc.) on the model are eliminated.
Physically Relevant ParametersIt is common practice by airlines to track both the planned and actual variables for many key parameters.However, in this work, only the actual values (as opposed to planned values) of the variables are used.The use of actual variables would allow achieving more realistic models because planned variables are typically based on the predicted actual variables augmented by a margin value to account for the uncertainty of flight parameters (e.g., fuel burn, time, etc.).Also, the variables irrelevant to these modeling methods such as city-pair, route information (domestic or foreign), etc. are discarded.
Mathematical Modeling: Multi-variable Regression ModelingThe mathematical modeling is focused on two regression approaches.The first choice is the linear regression technique because is easier to build and implement.However, when the linear approach fails to provide an acceptable predictive model, the nonlinear feed-forward neural network is used.
Response Surface EquationThe linear regression used in this study is the multivariate regression technique of the Response Surface Methodology (RSM) (ref.9).The RSM consists of building a response surface equation (RSE), which constitutes simplified polynomial equations used to model behavior of complex systems.RSE is used to relate the factors (or predictors) to the measured responses (landing speed) over some specified region of interest.Use of the RSE can be justified by its ability to combine parameters of different natures, and their cross-effects, in a single equation.The most popularly used RSE is the second-order Taylor series approximation because it requires a minimal computational investment: (1) where: R: the dependent parameter (response) of interest : the intercept term : regression coefficients for the first-order terms : coefficients for the pure quadratic terms : the coefficients for the cross-product terms : the independent variables : the number of factors : the error associated with neglecting higher-order effects The RSE assumes that for any model the error, ε, should be normally distributed as N(0,1).
Neural Network ModelingIn general neural networks are an alternative to Response Surface Methods in the creation of regression models for problems where the polynomial representation of the RSE does not perform well (ref.10).Among the neural network types, the feed-forward back propagation (FFBP) is one of the easiest to build and implement.Usually, it is a good starting point to build a model because a feed-forward neural network can theoretically fit any nonlinear relationship between inputs and target.R = b 0 + b i x i i=1 k  + b ii x i 2 i=1 k  + b ij x i x j + ε j =i+1 k  i=1 k -1  o b i b ii b ij b j i x x ; k ε Figure 1. Feed-forward neural network illustration.
Neural Network BackgroundArchitecturally a neural network is composed of an input layer, hidden layers, and an output layer as illustrated in Figure 1.The hidden layer is the data processing center of the network.The output layer is the response to the simulation.A layer is composed of neurons.In a layer, each input element is connected to each neuron through a weight (w), and a bias (b) is added to the weighted input.Typically, there are three main steps to build a neural network: training, validation and testing.Consequently, a dataset composed of an input set and corresponding target output are divided into those three groups.Usually there is a pre-processing step to get the data into a useful form.Then the training step consists of tuning the values of weights and biases of the network to optimize network performance (ref. 11).The validation step consists of using the second (validation) set of the data to adjust the quality of the regression.Finally, the test set serves to check the network on a set different from the one used for its construction.Many training algorithms exist.The Levenberg-Marquardt is the most commonly used algorithm for feed-forward networks when rapid training is desired.Based on the nature of this research to model a regression of the input variables to predict the corresponding landing speed, the network is trained for function approximation as opposed to the pattern recognition.A proper training requires a training set based on known inputs and corresponding target outputs.It is also customary for neural networks to undergo the training process (retraining) a couple of times to improve the quality of the fit.Then, the performance function used as the stopping criteria is the Mean Square Error (MSE) defined in equation (2) as:∑ ∑ (2)
PROOF OF CONCEPTPrevious studies (refs. 7, 12) suggested that airport-specific parameters (airport elevation, runway length, etc.) contribute to the final approach performance of a flight.More importantly, it is clear that each aircraft type (e.g., B737-800 or MD80) has specific performance parameters that would directly impact its landing speed.Consequently, to account for all these variations that may affect the fidelity of any landing-speed model, an airport-specific and aircraft-specific landing model was created using historical data.As a proof of the concept, the proposed methodologies to predict aircraft landing speed are applied to the MD80 aircraft type also referred to as the Super 80 (SP80) operations at the Dallas/Fort Worth International Airport.DFW was chosen because data for detailed analysis were available and the SP80 is highest number of a single aircraft type in service at this airport.
RSE Application to Thirteen Input VariablesThe different steps of the proposed methodology are carried out using DFW and the SP80 aircraft type.Step 1: Data collection A dataset of over 300 variables is recorded over time.Collected data are composed of airport topological (e.g., runway length and configuration), environmental information (e.g., visibility, wind condition, ceiling), flight-specific parameters (e.g., city pair flown, fuel burn rate, landing weight, etc.), and aircraft-specific parameters (e.g., empty gross weight, aircraft maximum payload, etc.).For the remainder of this paper the collected data are considered as the true value or actual value.Step 2: ScreeningThe main goal of this section is the identification of the predictive values of the parameters.First, variables that are known to be irrelevant are automatically eliminated (e.g., aircraft tail number, city of departure, etc.).Also, if two or more variables provide the same information, only one of them is used for the modeling.For example, as shown in Figure 2, the variables pax (number of passengers) and LF_pax (load factor for passengers) have a correlation coefficient of 1.For modeling purposes these two variables provide the same information, so one of them is sufficient.Consequently, after dropping the linear dependent parameters, LF_pax, FBR (fuel burn rate), and ESAD_nm (equivalent still air distance) are among the retained variables for modeling.Step 3: Physically irrelevant parameters to the model are eliminated.The result of the screening and physical relevance steps, based on the principle of using the minimum possible number of variables, yields a reduced set of thirteen parameters as the most relevant to aircraft landing speed (shown in Table 1).Only the selected thirteen variables are used as inputs to fit the multivariable regression model defined in equation ( 1), where the response is the landing speed.It should be noted, however, that not all of these parameters have equal importance.The MD80 flight manual provides a set of recommendations for low-and-no-gust condition and another set for high-gust condition (ref.13).Under the normal operating conditions, the MD80 flight manual defines the low-and-no-gust condition for reported wind between 0 and 10 knots, whereas it defines the high-gust condition for reported wind over 10 knots.A landing-speed model will be constructed for each of the two scenarios set forth by the MD80 flight manual.The model that predicted landing speed will be compared to the one recommended by the airlines' flight manual to highlight the benefits of the proposed modeling approach.
Low-and-No-Gust RSE ModelUsing the 13 retained parameters shown in Table 1, the coefficients of the first-order terms, the second-order terms, the cross-term, and the intercept are all calculated by fitting the variables into the response.The statistical package JMP is used to compute the different RSE coefficients (see appendix A).The equation obtained is the multivariable model.To illustrate the contribution of each variable and cross-term to the landing speed model for the low-and-no-gust condition, a Pareto chart shown in Figure 3 is generated.The Pareto chart provides much information to the system modelers.It shows the orthogonal estimate, which is the orthogonal projection of the model along the RSE terms.For example, the model projection along the APAY axis has a value of 3.62, which represents the norm (or weight) of the model vector along the APAY axis.Furthermore, it can be inferred from the Pareto chart that the variable APAY contributes the greatest variability to the landing-speed model with about 13.5% contribution, followed in decreasing order by the headwind (~8.2% contribution), the actual landing weight (~5.2% contribution), the ceiling (~4.3%), the cross-term of headwind-landing weight (~3% contribution), and so on.Also, the Pareto chart allows us to assess the relative importance of each term in the RSE; for example, the relative contribution of the headwind variable (with a value of 2.23) weights about 1.6 times the relative contribution of the actual landing weight (Act_Land_Wgt) variable (with a value of 1.42) to the landing-speed model for the low-and-no-gust condition.Other important information gained from the Pareto chart is the visualization of the cumulative effect of the RSE terms.Using the cumulative contribution curve, systems modelers can make a decision about the appropriate level of fidelity necessary.As illustrated in Figure 3, the cumulative contribution of the truncated Pareto chart showing the first 19 out of 104 terms represent 57% of the 13-variables RSE model for the lowand-no-gust condition.Other information obtained from the Pareto chart is that even though the flight manual proposes that headwind and gust wind play important roles in predicting the landing speed (see equations ( 2) and ( 3)), their significance is not as important as suggested, weighting only 8.2% and 2%, respectively, of the landing-speed model.After the model is obtained, the quality of the model is assessed using several goodness-of-fit metrics.Figure 4 illustrates the predicted landing-speed model compared to the recorded actual landing speed.The coefficient of determination R 2 and the root-mean-square (RMS) error are computed to be 0.43 and 6.16, respectively.The blue line represents the actual landing speed (also called the 45-degree line); a perfect predictor would have values along the blue line.As Figure 4 shows, there still is some sizable landing-speed prediction error for the low-and-no-gust condition despite the use of the same dataset modeling and testing.The error on baseline speed and the error on the model are calculated for the low-and-no-gust condition using equations ( 5) and ( 6), respectively.Figure 5
High-Gust RSE ModelFor the high-gust condition, the same thirteen input variables in Table 1 are used to construct a RSE model.A new set of RSE coefficients are calculated (see appendix A) and the Pareto chart is obtained and shown on Figure 6.Similar to the low-and-no-gust condition, the APAY variable is the biggest contributor to the landing speed for the high-gust condition, with 11%.However, the second contributor is the visibility (~8% contribution), contrary to the low-and-no-gust condition.Also, the relative contribution parameters are different from the low-and-no-gust case; thus, the Pareto chart for the high-gust condition is different from the low-and-no-gust one.Correspondingly, the error on baseline speed and the error on the model are calculated for the high-gust condition using the same equations, ( 5) and ( 6), respectively.Figure 8 illustrates the calculated error metrics for high-gust conditions.The red stars represent the absolute value of the model error, and the blue open circles, the absolute value of the target-speed error.As is evidence in Figure 5 (low-and-no-gust condition) and Figure 8 (high-gust condition), the value of the model error is consistently smaller than that of the target speed error.Although the model error is better than the target-speed error for both wind conditions, Figure 8 shows that model error values for the high-gust case are relatively smaller than the error values of the lowand-no-gust case, while Figure 5 shows larger errors for the low-and-no-gust case.
Summary and Discussion of Results for RSE Models with Thirteen Input VariablesTable 2 summarizes the statistical characteristics of the RSE model versus the baseline landingspeed error.It appears that the RSE model with thirteen input variables is better than the airline's flight manual-recommended target landing speed based on the statistical parameters metrics.The mean value of the error of both the low-and-no-gust and high-gust wind conditions is very close to 0 (i.e., -1.80e-4 and 5.07e-5, respectively), whereas the mean values for the target error landing speed are 4.25 for the low-and-no-gust wind condition and -6.92 for the high-gust wind condition.The fact that the mean of the model error is nearly 0 illustrates the closeness of the model to the actual landing speed.The standard deviations of the model error are also smaller (4.36 and 3.65, respectively, for low-and-no-gust and high-gust conditions) compared to the standard deviations of the target landing-speed error (5.18 and 4.38, respectively, for low-andno-gust and high-gust conditions), illustrating less dispersion of the model-predicted landing speed from the actual landing speed than the target landing speed.Overall, the standard deviation of the RSE model error reduced the standard deviation of the baseline error by 18% for the low-and-no-gust condition and 22% for the high-gust case.Another way to show the accuracy and precision of the RSE models compared to the baseline is by examining the error distributions.Figure 9 shows the absolute value of the model error (blue bar) and the baseline error (red bar) distributions for the low-and-no-gust condition.Figure 9 shows that out of the 1387 data points considered, around 950 of them have predicted landingspeed error within 0 to 4%, while there are only about 600 data points within the same error interval for the baseline error.On the opposite side, for a larger percentage error range of 8 to 12%, there are about 340 data points for the model error and about 500 data points for the baseline error.In summary, for the thirteen input variables case, the comparison metrics used all show that the RSE model is better than the current state-of-the-art (baseline).That is, for both the low-and-nogust and high-gust conditions, there is 18% less dispersion for the low-and-no-gust case and 22% less dispersion for the model error compared to the baseline error.This finding implies the model is more precise in predicting the landing speed.Also, for both gust conditions, there are more instances of data-point percentage error concentrated within the 0% to 4% range for the model than the baseline, indicating that the model is more accurate.However, the coefficients of determination R 2 (0.43 and 0.62, respectively) are smaller relative to the ideal value of 1.That lack of fit of the model may be explained in part by the model uncertainty and the lack of knowledge of the pilots' decision-making process to achieve landing.
Application to Reduced Number of Input Variables: Five InputsIt is important to note that the thirteen variables used in the previous example would not be available at most airports because airlines typically do not provide the data to the public.Therefore, the study is repeated for the more realistically obtainable variables composed of the In a similar approach, the data are divided into two groups: low-and-no-gust condition in one group and high-gust condition in another.As a first attempt, the multivariable linear regression modeling method of RSE is reproduced.
RSE ModelingThe RSE is built following the steps underlined in the modeling methodologies section using the same data points as in the case of thirteen input variables.However, only the five input parameters listed in Table 3 are fitted into a RSE with the recorded actual landing speed as target output for each of the gust conditions.
RSE Model for Landing with Low-and-No-Gust ConditionFigure 11 shows that for a study with only five variables, the main contributor is the aircraft landing weight, representing about 32% toward the model, followed by the headwind (18%), ceiling (9.5%), and visibility (5%), respectively.The computed coefficients of the second-order regression equation can be seen in appendix B for the low-and-no-gust condition.Then the crossterms of headwind-visibility, ceiling-landing weight, and the gust wind followed.In other words, the gust wind contributes to the model the least.The quality of the fit is assessed by calculating the values of the coefficient of determination R 2 of 0.37 and the RMS error (RMSE) is 6.29.These values show that the RSE approach performs worse for the five input variables case than the thirteen.
RSE Model for High-Gust ConditionLike in the low-and-no-gust case, as illustrated in Figure 12, the aircraft weight is main contributor to the landing speed for the reduced number of variables (five), representing over 28% of the high-gust model.The computed coefficients of the second-order regression equation can be seen in appendix B for the high-gust case.Contrary to the low-and-no-gust condition, the visibility is the second-highest contributor with a negative impact representing around 19%, followed by headwind, which contributes around 9%.The ceiling (2.5%) and the gust wind (0.4%) contribute marginally to the overall model.The quality of the fit is assessed by calculating the values of the coefficient of determination R 2 of 0.50, and the RMS error is 5.95.Similar to the low-and-no-gust case, it is clear that the RSE approach performs worse for the five input variables than for the thirteen.Because of the poor fit, other options such as the neural network are investigated.
Neural Network ModelingThe neural network model handles nonlinear relationships between inputs and target better than linear regression techniques.Because the linear regression technique of RSE did not provide high enough quality of fit, it is worth exploring a nonlinear technique such as the neural network.Like in the RSE modeling approach, a neural network model is built for the low-and-no-gust condition and another one for the high-gust condition.
Neural Network Model for Low-and-No-Gust ConditionThe five variables from Table 3 are used as inputs to build a feed-forward network with a schematic shown in Figure 13 for the low-and-no-gust condition.The dataset is randomly divided into three groups as follows: 70% used for training, 20% for validation, and the remaining 10% for testing.Then, the training process consists of tuning the weights and biases until the validation dataset converges as illustrated in Figure 14.After the training, validation, and testing steps, the model output is plotted versus the target for the dataset as shown in Figure 15.The graphs of all three datasets are shown for the sake of transparency.Also from the Figure 15, the regression values of the network output versus the target are 0.62, 0.58, and 0.56 for the training set, the validation, and the testing set, respectively.The fact that the correlation values of all three datasets are within the same range shows a consistency between the training sets and the testing set.The error distribution in Figure 16 shows the dispersion of the training, validation, and testing set errors between the network prediction and the target.The error distributions approximate a normal distribution for each dataset.The reduced standard deviation of the testing set may be explained by the smaller number of its data points.Additionally, Figure 16 stresses the fact that all three datasets have similar statistical characteristics.The remaining neural network model characteristics can be found in appendix C for both the low-and-no-gust and high-gust conditions.
Neural Network Model for Landing with High-Gust ConditionIn a similar fashion, a neural network model is built for the high-gust condition as illustrated in Figure 13.For the sake of consistency, the high-gust dataset is randomly divided into three groups: 70% used for training, 20% for validation and 10% for testing.Figure 17 illustrates the convergence of the network after twelve iterations, with the best validation performance reached at the sixth iteration.Figure 18 shows how well the model output for the training, validation, and testing datasets did versus the target values after 6 iterations.Also, it shows the regression fit in each case.The regression values of the network output versus the target are better for the high-gust condition than for the low-and-no-gust condition with 0.70, 0.65, and 0.62 for the training set, the validation, and the testing set, respectively.Similar to the low-and-no-gust condition, the correlation values of the three datasets are within the same range, showing a consistency among the datasets used to model the high-gust case.The error distribution in Figure 19 shows the dispersion of the training, validation, and testing set errors between the network prediction and the target.For the high-gust condition, the training and validation sets have similar error distributions, but they are different from the testing set.This lack of well-defined error distributions may be explained by the reduced number of data points for the high-gust condition at DFW.
Models Evaluation for Five Input VariablesThe two different modeling methodologies are evaluated and compared to the baseline landing speed using the two error metrics defined earlier in equations ( 5) and (6).Thus, the two models (RSE and neural network) are evaluated for both the low-and-no-gust and high-gust conditions using the error metrics defined earlier.For the low-and-no-gust condition, Figure 20 shows that the absolute value of the predicted landing-speed errors of the models are concentrated mostly between 0 and 6% for most of the 1387 data points used, while the flight-operating manual-predicted landing speed has most of the absolute value error within the 8% to 20% range for the same dataset.As for the high-gust condition, a visual inspection of Figure 21 shows that the magnitude of the absolute value of the predicted landing-speed errors of the model are mostly concentrated between 0 and 6% for most of the 426 data points used.However, the most of the absolute values of the flight-operating manual predicted landing-speed errors are within the 4% to 16% range for the same dataset.As illustrated in Figure 20 (low-and-no-gust condition) and Figure 21 (high-gust condition), the absolute values of the predicted landing-speed errors of the model (neural network (red stars) and RSE (black plus signs) are consistently lower than those of the current state-of-the-art landingspeed prediction (blue circles).
Results and Discussions for Five Input VariablesBecause the RSE model with the reduced number of input parameters poorly predicts the landing speed, the neural network models were built for both the low-and-no-gust and high-gust conditions.Then, the neural network models were assessed and compared to the RSE model and to the recommended landing speed provided by the operating flight manual.Despite the reduced number of input variables from thirteen to five, the neural network models provide better landing-speed predictions for both low-and-no-gust and high-gust conditions than the airlines' operating flight manual.Table 4 summarizes statistical parameters, comparing the errors between the neural network models and the flight manual.
Low an d No Gust Error High Gust E rrorAn analysis of Table 4 indicates that the mean values of the percentage error of the models are about 0 for both low-and-no-gust and high-gust conditions (-0.1% and -0.2%, respectively) compared to existing flight manual-recommended values (4.2% and -6.9%, respectively).Furthermore, the standard deviation is smaller for the models than the existing flight operating manual recommendations.These two statistical parameters demonstrate that the neural network landing-speed prediction models are closer to the actual landing speed for both the low-and-nogust and high-gust conditions.It is also worth comparing the neural network and the RSE models to see how each of them fared compared to the baseline.Figure 22 and Figure 23 show the comparative error distributions of the neural network model (blue bars), the RSE (light green bars) and the baseline (red bars) for the low-and-no-gust and the high-gust conditions, respectively.For both gust conditions, the error distributions of the models approximate a normal distribution, implying that the errors of the models are random, with peak around 0% error.A direct comparison between the two types of models shows that the neural network model performs better than the RSE model, because there are more instances of 0% to 2% error for the neural network than for the RSE.The number of instances of RSE error becomes larger for higher error values.There are also some important differences between the individual distributions.An analysis of the error distribution for the low-and-no-gust condition (Figure 22) shows that the neural network has the highest number of cases around 0%.As the error value increases, the number of instances of neural network model error decreases faster than the RSE, meaning there are fewer data points with larger predicted landing-speed errors for the neural network model than for the RSE.It is also clearly apparent in Figure 22 that both models (with peak value at 0%) perform better than the baseline (with peak at 5%).Another interesting observation from Figure 22 is that for the low-and-no-gust condition, the flight operating manual tends to underestimate the landing speed; that is, it under-predicts the landing speed (see equation ( 6)).In other words, at the low-and-no-gust condition, pilots overshoot the landing speed compared to the flight manual recommendation.Similarly, the error distribution of the high-gust condition shown in Figure 23 demonstrates that both the neural network model and the RSE model having their highest number of cases of error around 0% (with peak value at 0%) predict the landing speed with less error than the baseline (with peak at -10%) does.As the error value increases, the number of instances of neural network model error decreases faster than the RSE, whereas the error values get larger in the negative direction, so it is not clear which model performs better.However, an analytical analysis of the high-gust condition statistics shows that the neural network model predicts landing speed more precisely than the RSE model because while both models have mean values of error at 0 (i.e.similar accuracy), the neural network model error has a standard deviation 5.5% lower (less dispersion) than the RSE model.Moreover, while the neural network model represents a sizeable 9.5% landing-speed prediction precision improvement over the baseline prediction, the RSE is a mere 3.8% improvement over the baseline.Contrary to the low-and-no-gust condition, in the high-gust case shown in Figure 23 the flightoperating manual overestimates the landing speed.Thus, the predicted landing speed is over predicted compared to pilots' achieved landing speed.Overall, both models predict landing speed more accurately (e.g., 0 mean value) and more precisely (e.g.lower error standard deviation) than baseline under both gust conditions.For the normal landing-speed range, both models are capable of predicting the landing speed within a few knots for most data points.However, for a reduced number of input variables, the neural network models for both gust conditions yield a better landing-speed prediction than does the RSE modeling approach.More illustrative figures showing the advantages of the neural network model over the RSE model can be found in appendix D. The ability of neural networks to handle the nonlinear regression better is to be credited for the improved precision capability.One of the main disadvantages of using the neural network modeling approach for this type of study is that it works like a black box for the end user, providing no insight on the impact or the variance of each input variable on the landing speed.Therefore, valuable information provided to researchers about the contribution of each parameter to the RSE model shown on Pareto chart types would be lost in the neural network modeling approach.
CONCLUSIONSThe principal goal of this study is to create aircraft landing-speed models that are unbiased (accurate) with minimum variance (precise), and demonstrate potential for near-term implementation.An accurate predicted landing-speed is required for the achievement of NextGen goals, so that a trailing aircraft trajectory (speed and altitude) can be adjusted to avoid any predicted separation violations.Among the immediate potential benefits to having an accurate landing speed model are: an increase in airport throughput by decreasing the excess separation buffer between successive arrival aircraft, a potential increase in overall safety in lowvisibility conditions, and a possible decrease in fuel burn as a consequence of decreased travel time and landing procedures.It is worth noting that the inability to reduce or eliminate the excess separation buffer due to trajectory uncertainty at the nation's busiest airports is one of the key hurdles to meeting the anticipated demand of the NextGen NAS.As a proof of concept to the proposed multivariable regression technique of RSE, the thirteen most impactful variables for MD80 landing speed at DFW for the case of thirteen input variables are used.The qualities of fit of the models are assessed with a coefficient of determination R 2 of 0.43 for the low-and-no-gust model and R 2 of 0.62 for the high-gust RSE model.In order to expand the landing-speed prediction modeling approach to other major airports, the RSE modeling is repeated with the five likely readily available variables.The quality of fit for the RSE model deteriorates with coefficients of determination R 2 of 0.37 and 0.5 for low-and-nogust and high-gust conditions respectively.These results reveal that more work on the model is required to enhance its predictive ability.In an attempt to improve on the predictive performance of the RSE model with five input variables, feed-forward neural network models are developed for each gust condition.While both models have similar accuracy, the neural network models approximate the actual landing speed much better than the RSE models because the error standard deviations of the neural network models were reduced by 5.6% and 5.5% (better precision) for the low-and-no-gust and high-gust conditions, respectively.More importantly, the prediction of the landing speed of the neural network is an 18.8% and 9.5% precision improvement over the existing state-of-the-art that is the flight manual recommendation for low-and-no-gust and high-gust conditions respectively.Comparatively, the RSE models are 12.5% and a mere 3.8% improvement of the landing-speed prediction precision over the flight operating manual recommendation for low-and-no-gust and high-gust conditions, respectively.Ultimately, the proposed data-based modeling approach shows great potential for predicting actual landing speed far better than the existing operating flight manual recommendation for final approach speed commonly prescribed in commercial aircraft flight manuals.The two different regression techniques presented in this paper begin to address the research challenges in the prediction of final approach speed modeling.The models achieved a more accurate (mean value of error of 0) and precise (less dispersion) prediction of the landing speed for the narrowbody air transport used as a test-bed than the current flight operating procedure recommendation can.Thus under normal landing conditions, each of the constructed models predicted the landing speed within a couple of knots of the actual achieved speed.The next steps of this research should be applying these modeling approaches to other airports and aircraft types.Finally, the proposed modeling approach can be improved by identifying more relevant parameters and finding a way to quantify pilots' decision-making processes for the landing procedure.In the meantime, the study allows us to conclude that pilots tend to overcompensate landing speed in the low-and-no-gust condition and under-shoot landing speed under high-gust conditions.This finding is very important in trying to model pilots' behavior to improve existing and future terminal area tools.
APPENDIX A. RSE COEFFICIENTS FOR THIRTEEN VARIABLES
APPENDIX B. RSE MODELS FOR FIVE INPUT VARIABLESFigure 1 .1Figure 1.Feed-forward neural network illustration.................................................................. Figure 2. Example of correlated variables matrix................................................................... Figure 3. Truncated Pareto chart for low-and-no-gust condition............................................ Figure 4. Predicted vs. Actual speed for low-and-no-gust condition...................................... Figure 5. Model error vs. Target speed error for low-and-no-gust condition........................ Figure 6.Truncated Pareto chart for high-gust condition....................................................... Figure 7. Predicted vs. Actual speed for high-gust condition................................................. Figure 8. Model error vs. Recommended landing speed error for high-gust condition......... Figure 9. Low-and-no-gust error comparison......................................................................... Figure 10.High-gust error distribution..................................................................................... Figure 11.Pareto chart for low-and-no-gust condition for the reduced number of variables (5).............................................................................................................Figure 12. Pareto chart for high-gust for reduced number of variables (5)............................... Figure 13.Network for five input variables.............................................................................. Figure 14.Mean square error for low-and-no-gust condition................................................... Figure 15.Output vs. Target for training, validation and testing for low-and-no-gust dataset...................................................................................................................... Figure 16.Error distribution of training, validation and testing for low-and-no-gust condition.................................................................................................................. Figure 17.Mean square error for high-gust condition.............................................................. Figure 18.Output vs. Target for training, validation and testing for high-gust dataset............ Figure 19.Error distributions of training, validation and testing for high-gust condition........ Figure 20.Absolute value of percentage error for neural network, RSE, and baseline for low-and-no-gust condition....................................................................................... Figure 21.Absolute values of percentage error for neural network, RSE, and baseline for high-gust condition.................................................................................................. Figure 22.Percentage error distributions for low-and-no-gust condition................................. Figure 23.Percentage error distributions for high-gust condition............................................
Figure 4 .4Figure 1.Feed-forward neural network illustration.................................................................. Figure 2. Example of correlated variables matrix................................................................... Figure 3. Truncated Pareto chart for low-and-no-gust condition............................................ Figure 4. Predicted vs. Actual speed for low-and-no-gust condition...................................... Figure 5. Model error vs. Target speed error for low-and-no-gust condition........................ Figure 6.Truncated Pareto chart for high-gust condition....................................................... Figure 7. Predicted vs. Actual speed for high-gust condition................................................. Figure 8. Model error vs. Recommended landing speed error for high-gust condition......... Figure 9. Low-and-no-gust error comparison......................................................................... Figure 10.High-gust error distribution..................................................................................... Figure 11.Pareto chart for low-and-no-gust condition for the reduced number of variables (5).............................................................................................................Figure 12. Pareto chart for high-gust for reduced number of variables (5)............................... Figure 13.Network for five input variables.............................................................................. Figure 14.Mean square error for low-and-no-gust condition................................................... Figure 15.Output vs. Target for training, validation and testing for low-and-no-gust dataset...................................................................................................................... Figure 16.Error distribution of training, validation and testing for low-and-no-gust condition.................................................................................................................. Figure 17.Mean square error for high-gust condition.............................................................. Figure 18.Output vs. Target for training, validation and testing for high-gust dataset............ Figure 19.Error distributions of training, validation and testing for high-gust condition........ Figure 20.Absolute value of percentage error for neural network, RSE, and baseline for low-and-no-gust condition....................................................................................... Figure 21.Absolute values of percentage error for neural network, RSE, and baseline for high-gust condition.................................................................................................. Figure 22.Percentage error distributions for low-and-no-gust condition................................. Figure 23.Percentage error distributions for high-gust condition............................................
Figure A- 1 .1Figure A-1.Absolute values of percentage error distribution for low-and-no-gust condition for thirteen input variables ....................................................................................... Figure A-2.Absolute values of percentage error distribution for high-gust condition for thirteen input variables .............................................................................................
Figure C- 1 .Figure C- 3 .13Figure C-1.Training characteristics for low-and-no-gust condition........................................... Figure C-2.Regression plot for all the values (training, validation, and testing) together.........
Figure D- 1 .1Figure D-1.Absolute values of percentage error for low-and-no-gust condition for five input variables......................................................................................................... Figure D-2.Percentage of error distribution for low-and-no-gust condition for five input variables................................................................................................................... Figure D-3.Absolute values of percentage error for high-gust condition for five input variables................................................................................................................... Figure D-4.Percentages of error distribution for high-gust condition for five input variables. .
Figure 2 .2Figure 2. Example of correlated variables matrix.
Figure 3 .3Figure 3. Truncated Pareto chart for low-and-no-gust condition.
Figure 4 .4Figure 4. Predicted vs. Actual speed for low-and-no-gust condition.
Figure 5 .5Figure 5. Model error vs. Target speed error for low-and-no-gust condition.
represents a visual representation of the calculated error metrics for the low-and-no-gust condition.The red stars represent the absolute value of the model error, and the blue open circles, the absolute value of the targetspeed error.The error metric clearly shows that the baseline error is larger than the RSE model error for the low-and-no-gust condition.
Figure 77Figure7shows the predicted versus actual landing speed.The goodness of fit of the model is assessed with the calculation of the coefficient of determination R 2 of 0.62 and the RMS error of 5.79.The blue line on Figure7represents the actual landing speed (also called the 45-degree line).It also corresponds to the ideal fit of a coefficient of determination R 2 of 1.The goodnessof-fit metrics for the high-gust wind condition shows that overall the model for the high-gust condition is a better than the model obtained for the low-and-no-gust wind condition.It is worth
Figure 6 .6Figure 6.Truncated Pareto chart for high-gust condition.
Figure 7 .7Figure 7. Predicted vs. Actual speed for high-gust condition.
Figure 8 .8Figure 8. Model error vs. Recommended landing speed error for high-gust condition.
Figure 9 .9Figure 9. Low-and-no-gust error comparison.
Figure 10 .10Figure 10.High-gust error distribution.
Figure 10 represents10Figure10represents the error distributions of the absolute value of the RSE model (blue bar) and the baseline (red bar) for the high-gust condition.A similar tendency is observed for the highgust case as well.For the lower error percentage range (0 to 4%), there are about 310 out of 426 data points for the model compared to only about 90 data points or so for the baseline error.At the higher error range (8% to 12%) there are only 15 data points for the model versus 140 instances of baseline errors.
Figure 11 .11Figure 11.Pareto chart for low-and-no-gust condition for the reduced number of variables(5).
Figure 12 .12Figure 12.Pareto chart for high-gust for reduced number of variables (5).
Figure 13 .13Figure 13.Network for five input variables.
Figure 14 .14Figure 14.Mean square error for low-and-no-gust condition.
Figure 15 .15Figure 15.Output vs. Target for training, validation and testing for low-and-no-gust dataset.
Figure 16 .16Figure 16.Error distribution of training, validation and testing for low-and-no-gust condition.
Figure 17 .17Figure 17.Mean square error for high-gust condition.
Figure 20 and20Figure 20 and Figure 21 are visual representations of the error metrics for the low-and-no-gust and high-gust conditions, respectively.The blue open circles represent the absolute value of the baseline error, the red stars represents the absolute value of the neural network model error, and the black plus sign represent the absolute value of the RSE model error.
Figure 18 .18Figure 18.Output vs. Target for training, validation and testing for high-gust dataset.
Figure 19 .19Figure 19.Error distributions of training, validation and testing for high-gust condition.
Figure 20 .20Figure 20.Absolute value of percentage error for neural network, RSE, and baseline for low-and-no-gust condition.
Figure 21 .21Figure 21.Absolute values of percentage error for neural network, RSE, and baseline for high-gust condition.
Figure 22 .22Figure 22.Percentage error distributions for low-and-no-gust condition.
Figure 23 .23Figure 23.Percentage error distributions for high-gust condition.
Figure A- 11Figure A-1 and Figure A-2 show the absolute values of the percentage error distributions for the low-and-no-gust and high-gust conditions, respectively, for thirteen input variables example.
Figure A- 2 .2Figure A-2.Absolute values of percentage error distribution for high-gust condition for thirteen input variables.
Figure A- 1 .1Figure A-1.Absolute values of percentage error distribution for low-and-no-gust condition for thirteen input variables.
Figure C- 33Figure C-3 shows the error distribution for the 1387 (training, validation, and testing) data points.
Figure C- 44Figure C-4 shows the neural network model characteristics for high-gust condition
Figure C- 4 .4Figure C-4.Training characteristics for high-gust condition.
Figure C- 55Figure C-5 shows the regression plot for all the data (training, validation, and testing) together for the high-gust condition.
Figure C- 66Figure C-6 shows the error distribution for all 426 (training, validation, and testing) data point used to model the high-gust condition together.
Figure C- 5 .5Figure C-5.Regression plot for data together.
Figure C- 6 .6Figure C-6.Error histogram for all 426 data points together.
Figure C- 77Figure C-7 shows the absolute values of percentage error distribution for the high-gust neural network model for five input variables.It is clear that the error is more spread for the recommended (baseline) value for the high-gust case.As the error values increase, there are fewer instances of the model and more of the recommended.
Figure C- 88Figure C-8 also illustrates a larger spread of the recommended (baseline) error compared to the model for high-gust case.
Figure C- 7 .7Figure C-7.Absolute values of percentage error distribution for high-gust neural network model for five input variables.
Figure C- 8 .8Figure C-8.Regression plots comparison of neural network model error versus the recommendation error for high-gust condition.
Figure D- 33Figure D-3 gives the absolute values of percentage error, and Figure D-4 gives the percentages of error distribution for the high-gust condition for five input variables.
Figure D- 3 .3Figure D-3.Absolute values of percentage error for high-gust condition for five input variables.
Figure D- 4 .4Figure D-4.Percentages of error distribution for high-gust condition for five input variables.





Table 1 .1Variables Used for Modeling ...................................................................................
Table 2 .2Summary of Recommended Error vs. RSE Model Error for Landing Speed ..........
Table 3 .3Five Input Variables .................................................................................................
Table 4 .4Summary Landing Speed Models Error vs. Baseline Error for Five Input Variables ..................................................................................................................Table A-1.RSE Coefficients for Thirteen Input Variables ........................................................ Table B-1.RSE Coefficients for Five Input Variables .............................................................. Table B-2.RSE Terms Contribution for Low-and-No-Gust Case for Five Input Variables ..... Table B-3.RSE Terms Contribution for High-Gust Case for Five Input Variables ..................viii
TABLE 1 .1VARIABLES USED FOR MODELINGParameterDescriptionHead windHead WindGust wind Ceiling_ft Vis_ft asmsGust Wind Forecast Ceiling Forecast Visibility Available Seat MilesAPAY Act_Land_Wgt FUEL_LOADActual Payload Actual Landing Weight Fuel LoadAFUBO FBR RSVActual fuel burn Fuel burn rate Reserve fuelESAD_nm LF_paxEquivalent still air distance Load factor for passenger
TABLE 2 .2SUMMARY OF RECOMMENDED ERROR VS.RSE MODEL ERROR FOR LANDING SPEED
TABLE 3 .3FIVE INPUT VARIABLESParameterDescriptionHead windHead WindGust windGust WindCeiling_ftForecast CeilingVis_ftForecast VisibilityAct_Land_Wgt Actual Landing Weightfive parameters listed in
Table 3 .3These data are typically available to individuals through normal acquisition means (e.g., Federal Aviation Administration (FAA) websites).
TABLE 4 .4SUMMARY LANDING SPEED MODELS ERROR VS.BASELINE ERROR FOR FIVE INPUT VARIABLESSta tisticalP a ra me ter sNN_ Mo de lRS E _M odelB a selineNN_ModelR SE_M o de lB a selineMean-5.9E-02-1.4E-044.2-1.6E-011.3E-06-6.9std D e v4 . 44.65.24.04.24.4Min-13.5-14.9-14.5-12.5-13.3-19.2Me dia n-0.1-0.14.3-0.4-0.4-7.3Max29.532.840.913.415.07.625 Pe rcen tile-3.0-3.10.8-7.0-2.7-9.975 Pe rcen tile2.42.77.52.32.6-4.2
Table A -A1 list the RSE coefficients for thirteen input variables.
TABLE A -A1. RSE COEFFICIENTS FOR THIRTEEN INPUT VARIABLESTermLow Gust Coefficient EstimateHigh Gust Coefficient EstimateIntercept-575.351078.88headWind-8.76-6.74gustW ind-560.982.18Ceiling_ft-4.94E-035.48E -03Vis_ft5.06E -034.59E -03asms1.57E -030.03APAY6.53E -030.02Act_ Land_Wgt0.02-0.03FUEL_LOAD0.010.01AFUBO-0.01-0.01FBR1.191.66RSV-0.230.08ESAD_nm-0.02-4.83LF_pax-5.276.66headW i nd*headWind0.013.50E -03h e a dWind*gustW ind-0.294.23E -03gustWind*gustWind0.22-0.01h e a dWind*Ceiling_ft8.16E -061.02E -05gustW ind*Ceiling_ft1 . 5 6 E -0 5-2.60E-06Ceilin g_ft*Ceiling_ft7.55E -092.87E -08hea dWind*Vis_ft-5.98E-064.36E -05gustW ind*Vis_ft0.022.38E -05Ce i l i n g_ft*Vis_ft1 . 0 8 E -0 7-2.99E-08Vis_ft*Vis_ft-2.65E-08-5.69E-10hea dWind*asms-5.42E-063.28E -05gustWind*asms-4.98E-05-4.30E-05Cei l ing_ft*asms-6.83E-09-2.25E-08Vi s_ft*asms-4.13E-09-6.76E-08asms*asms-6.82E-092.36E -08hea dWind*APAY6.10E -06-4.92E-04gustWind*APAY-6.79E-053.77E -04Cei l ing_ft*APAY-2.34E-08-2.83E-08Vis_ft*APAY6.07E -093.73E -07a sms*APAY-6.08E-084.25E -07APAY*APAY8.68E -08-1.40E-07hea dWin d*Act_Land_Wgt1.17E -04-1.89E-05gustW ind*Act_Land_Wgt-6.66E-052.85E -05Ceili n g_f t*Act_Land_Wgt-3.33E-09-8.34E-08Vis_f t* Act_Land_Wgt-2.82E-089.67E -08a sms* Act_Land_Wgt-2.62E-08-3.15E-07AP AY* Act_Land_Wgt9 . 3 3 E -0 9-5.88E-07Act_ La nd_Wgt*Act_Land_Wgt-1.08E-071.43E -07hea dWin d*FUEL_LOAD-1.30E-043.87E -04gustWind*FUEL_LOAD-3.10E-05-2.92E-04Ceil i ng_ft*FUEL_LOAD3.38E -08-7.07E-09Vis_f t*FUEL_LOAD-1.02E-07-6.87E-08a sms*FUEL_LOAD9.76E -083.30E -07APAY *FUE L_LOAD1.49E -061.54E -06Act_ La nd_Wgt*FUEL_LOAD-5.65E-082.62E -09FUE L_LOAD*FUE L_LOAD-7.91E-082.20E -08h eadWind*AFUBO7.40E -06-2.80E-04gustW ind*AFUBO-1.50E-051.85E -04Cei ling_ft*AFUBO8.37E -092.76E -08Vis_ft*AFUBO1.24E -085.09E -08a sms*AFUBO7.16E -09-1.59E-08APAY*AFUBO-3.37E-07-5.91E-07Act_ La nd_Wgt*AFUBO8.27E -08-6.98E-08FUE L_LOAD*AFUBO-6.13E-077.54E -07AFUBO *AFUBO9.40E -09-4.59E-07headWind*FBR-7.51E-030.05gustWind*FBR-5.27E-03-0.02Cei l i ng_ft*FBR2.14E -066.13E -06Vis_ft*FBR-6.32E-06-2.87E-05a sms*FBR1.37E -05-9.66E-06APAY*FBR-1.84E-052.29E -04Act_ L a nd_Wgt*FBR-1.63E-053.37E -05FUE L_L OAD*FBR8.74E -055.08E -05AFUBO *FBR6.71E -061.38E -05FBR *FBR-2.95E-03-1.39E-03h ea dWind*RSV-2.57E-041.08E -03gustWind*RSV1.26E -04-1.13E-03Ceiling_ft*RSV3.56E -073.68E -07Vi s_ft*RSV-2.64E-07-3.20E-06a sms*RSV-1.62E-075.25E -07APAY*RSV-2.19E-06-3.05E-07Act_ L a nd_Wgt*RSV1.10E -06-7.24E-07FUE L_L OAD*R SV-2.86E-06-4.71E-06AFUBO *RSV1.36E -065.10E -06FBR *RSV3.27E -04-1.22E-03RSV*RSV1 . 5 3 E -0 53.52E -05h ea dWind*ESAD_nm9 . 6 0 E -0 4-1.51E-03gu stW ind*ESAD_nm7.04E -034.58E -03Ce i l i n g_ft*ESAD_nm9 . 2 9 E -0 73.19E -06Vi s_ f t*ESAD_nm7.07E -071.02E -05a sms*ESAD_nm1.88E -06-7.89E-06APAY *ESAD_nm1.26E -05-6.05E-05Act_ L a nd_Wgt*ESAD_nm2.84E -065.24E -05FUE L_LOAD*E SAD_nm-4.31E-06-6.40E-05AFUBO *ESAD_nm-2.31E-071.35E -05FBR *ESAD_nm-2.42E-031.47E -03RS V*ESAD_nm4 . 0 3 E -0 6-1.47E-04ESAD _ nm*ESAD_nm-1.49E-045.98E -04h eadWind*LF_pax-0.030.13gu stW ind*LF_pax0.05-0.11Cei ling_ft*LF_pax4.84E -063.11E -05Vi s_ft*LF_pax1.39E -05-1.20E-04a sms*LF_pax2.43E -05-3.18E-05AP AY*LF_pax-2.33E-052.81E -04Act_ L an d_Wgt*LF_pax4.87E -057.18E -05FUE L_LOAD*LF_pax-4.01E-04-4.35E-04AFUBO*LF_pax6.73E -051.69E -04FBR*LF_pax0.01-0.07R SV*LF_pax-5.87E-05-5.86E-04E SAD _nm*LF_pax0.002.46E -03L F _ pax*LF_pax-0.01-0.05
Table B -B1 gives the response surface equation (RSE) coefficients for the low-and-no-gust and high-gust conditions for the five input variables.Table B-2 and TableB-3 give their contribution for the low-and-no-gust and high-gust conditions, respectively.
TABLE B -B1. RSE COEFFICIENTS FOR FIVE INPUT VARIABLESTe r mLow Gust CoefficientHigh Gus t CoefficientEstimateEstimateI n ter cept37.543892301.49002h e a dWin d0.15337886.1802607gustWin d-613.7826-4.735832Ce ilin g_f t-0.001962-0.001217Vis_ ft0.0006099-0.00105A ct_L a n d_ W gt0.0011325-0.003061h e a dWin d*h e a dWind0.00251220.0379639h e a dWin d*gustWind-0.280288-0.069674gu stWin d*gustWind0.20229180.0209201h e a dWin d*Ce ilin g_ft9.08E-062.57E-05gustWin d* C e ilin g_ft8.01E-06-1.59E-05Ceilin g_ft* Ce ilin g_ft9.36E-092.19E-08h e a dWind* Vis_ ft-1.72E-05-7.32E-05gu stWin d*Vis_ f t0.01936260.0001126Ce ilin g_ft*Vis_ f t2.99E-089.66E-10V is_ ft*V is_ f t-1.90E-08-1.86E-08h e a dWin d*A ct_L a n d_Wgt5.12E-06-3.13E-05gu stWin d*A ct_L a n d_Wgt1.93E-061.45E-05C e ilin g_ ft* Act_ L an d_Wgt5.40E-094.84E-09V is_ ft* Act_ L an d_Wgt2.28E-094.22E-09A ct_L a n d_W gt*A ct_L a nd_Wgt-3.12E-091.61E-08
		
		
			
TABLE OF CONTENTS (cont.)Appendix: Mean Square Error, the average squared error between the network outputs and target outputs : i th error between the network outputs and target outputs : i th target or actual output : i th network predicted output : number of inputs
BASELINING: FLIGHT OPERATING MANUAL RECOMMENDATIONAircraft operating manuals provide landing-speed recommendations for each aircraft type based on the landing-aircraft weight.In order to assess the quality of the proposed models, the current aircraft operating manual recommendations are used as a baseline.As a case study, one of the most common narrow-body air-transport aircraft is used.
BaseliningThe MD80 super 80 version has two recommendations: one for low-and-no-gust condition defined as gust wind below 10 knots and a high-gust condition for gust wind greater than 10 knots.
Landing with Low-and-No-Gust ConditionIn the low-and-no-gust condition on the final approach, pilots are recommended to aim for a target approach speed of: (3) where:: Final approach target speed (knots indicated airspeed (IAS))
: Reference speed (knots IAS)The reference speed is provided in the flight manual as a function of aircraft weight and aircraft type.
Landing with High-Gust ConditionIn the high-gust condition, it is recommended in the final approach that pilots use a target approach speed of: (4) where:: Final approach target speed (knots IAS) : Reference speed (knots IAS) : Steady wind defined as the headwind component of the reported winds : Gust wind defined as the headwind differential between the reported winds and the reported gusts However, for the high-gust condition there is also a restriction that the total wind additive to the V ref should not exceed 20 knots.
Model EvaluationAfter building the landing-speed model, there is a need to compare the model with the recommended landing speed or target approach speed, which is the best available prediction of landing speed.To compare the model against the target speed, two metrics are defined:Error Vtarget : calculated as the error between the V Target (i.e.baseline speed) and the actual landing speed as illustrated in equation ( 5): (5) Error Model : calculated as the error between the model predicted landing speed and the actual landing speed using the formula in equation ( 6): (6) with:V Actual : Actual speed or true speed is defined as the sum ground speed (obtained from the terminal radar approach control facilities (TRACON) radar data) and the reported wind at the airport (from METAR), V Target : Target speed or flight manual-recommended landing speed is defined as the flight manual-recommended approach speed based on aircraft type and aircraft weight.This speed is used as the baseline landing speed for comparison.V Model : Landing speed of the model is defined as the model predicted landing speed.			
			

				


	
		The Next-Generation Air Transportation System's Joint Planning Environment: A Decision Support System
		
			EdgarWaggoner
		
		
			ScottGoldsmith
		
		
			JoshElliot
		
		10.2514/6.2009-7011
	
	
		9th AIAA Aviation Technology, Integration, and Operations Conference (ATIO)
		
			American Institute of Aeronautics and Astronautics
			June 2007
		
	
	Joint Planning and Development Office: Concept of Operations for the Next Generation Air Transportation System. Version 2.0, June 2007.



	
		Design and Operational Evaluation of the Traffic Management Advisor at the Fort Worth Air Route Traffic Control Center. 1st USA
		
			HNSwenson
		
		
			T;Hoang
		
		
			SEngelland
		
		
			DVincent
		
		
			TSanders
		
		
			BSanford
		
		
			KHeere
		
	
	
		Europe Air Traffic Management R&D Seminar
		
			June 1997
			Saclay, France
		
	
	Swenson, H.N.; Hoang, T; Engelland, S.; Vincent, D.; Sanders, T.; Sanford, B.; and Heere, K.: Design and Operational Evaluation of the Traffic Management Advisor at the Fort Worth Air Route Traffic Control Center. 1st USA/Europe Air Traffic Management R&D Seminar, Saclay, France, June 1997.



	
		Design and Evaluation of the Terminal Area Precision Scheduling and Spacing System
		
			HNSwenson
		
		
			JThipphavong
		
		
			ASadovsky
		
		
			LChen
		
		
			CSullivan
		
		
			LMartin
		
	
	
		th USA/Europe ATM R&D Seminar (ATM2011)
		Berlin, Germany
		
			June 14-17, 2011
		
	
	Swenson, H.N.; Thipphavong, J.; Sadovsky, A.; Chen, L.; Sullivan, C.; and Martin, L.: Design and Evaluation of the Terminal Area Precision Scheduling and Spacing System. 9th USA/Europe ATM R&D Seminar (ATM2011), Berlin, Germany, June 14-17, 2011.



	
		Terminal Area Forecast 1977-1987. Aviation Forecast Branch, Office of Aviation Policy, Federal Aviation Administration, Department of Transportation, Washington, D.C. 20591. February 1976. Various paging
		10.1177/004728757701500317
		ATO0T-CARTS-1055
	
	
		Journal of Travel Research
		Journal of Travel Research
		0047-2875
		1552-6763
		
			15
			3
			
			
			SAGE Publications
			Washington, D.C
		
	
	Functional Description Narrative N32422: Automated Terminal Proximity Alert (ATPA)- Final Approach Course. ATO0T-CARTS-1055, U.S. Department of Transportation, Federal Aviation Administration, Washington, D.C.



	
		THE FINAL APPROACH SPACING TOOL
		
			TJDavis
		
		
			KJKrzeczowski
		
		
			CBergh
		
		10.1016/b978-0-08-042238-1.50015-x
	
	
		Automatic Control in Aerospace 1994 (Aerospace Control '94)
		Palo Alto, California
		
			Elsevier
			Sept. 1994
			
		
	
	Davis, T.J.; Krzeczowski, K.J.; and Bergh, C.: The Final Approach Spacing Tool IFAC Thirteenth Symposium on Automatic Control in Aerospace, Palo Alto, California, Sept. 1994.



	
		Benefits of Continuous Descent Operations in High-Density Terminal Airspace Considering Scheduling Constraints
		
			JohnRobinson Iii
		
		
			MaryamKamgarpour
		
		10.2514/6.2010-9115
	
	
		10th AIAA Aviation Technology, Integration, and Operations (ATIO) Conference
		Fort Worth, Texas
		
			American Institute of Aeronautics and Astronautics
			Sept. 2010
		
	
	Robinson, J.E. and Kamgarpour, M.: Benefits of Continuous Descent Operations in High- Density Terminal Airspace Under Scheduling Constraints. ATIO Conference, Fort Worth, Texas, Sept. 2010.



	
		Comparison of Trajectory Synthesis Algorithms for Monitoring Final Approach Compression
		
			JohnRobinson Iii
		
		
			OusmaneDiallo
		
		
			RonaldReisman
		
		10.2514/6.2011-6900
	
	
		11th AIAA Aviation Technology, Integration, and Operations (ATIO) Conference
		Virginia Beach, Virginia
		
			American Institute of Aeronautics and Astronautics
			Sept. 2011
		
	
	Robinson, J.E.; Diallo, O.N.; and Reisman, R.J.: Comparison of Trajectory Synthesis Algorithms for Monitoring Final Approach Compression. ATIO Conference, Virginia Beach, Virginia, Sept. 2011.



	
		Prognostics for Gas Turbine Engines
		
			ONDiallo
		
		10.4271/air5871
		
			2010
			SAE International
		
		
			Georgia Institute of Technology, Thesis office
		
	
	Ph.D. Thesis
	Diallo, O.N.: A Data Analytics Approach to Gas Turbine Prognostics and Health Management. Ph.D. Thesis, Georgia Institute of Technology, Thesis office, 2010.



	
		
			RHMyers
		
		
			DCMontgomery
		
		
			Anderson-Cook
		
		
			CM
		
		Response Surface Methodology: Process and Product Optimization Using Designed Experiments
		
			John Wiley & Sons Inc
			2009
			705
		
	
	Myers, R.H.; Montgomery, D.C.; and Anderson-Cook, C.M.: Response Surface Methodology: Process and Product Optimization Using Designed Experiments. Vol. 705. 2009: John Wiley & Sons Inc.



	
		Basic Features of Statistical Packages and Data Documentation
		
			CJohnson
		
		
			JSchutte
		
		10.4324/9781315748788-10
	
	
		Regression Analysis for the Social Sciences
		
			Routledge
			Jan. 2009
			
		
	
	Johnson, C.; and Schutte, J.: Basic Regression Analysis for Integrated Neural Networks (BRAINN) Documentation. Version 2.3, Jan. 2009.



	
		
			MHBeale
		
		
			MTHagan
		
		
			HBDemuth
		
		Neural Network Toolbox User's Guide. Version R2011b
		
			2011
		
	
	Beale, M.H.; Hagan, M.T.; and Demuth, H.B.: Neural Network Toolbox User's Guide. Version R2011b, 2011.



	
		A Final Approach Trajectory Model for Current Operations
		
			ChesterGong
		
		
			AlexanderSadovsky
		
		10.2514/6.2010-9117
		AIAA-2010-9117
	
	
		10th AIAA Aviation Technology, Integration, and Operations (ATIO) Conference
		Fort Worth, Texas
		
			American Institute of Aeronautics and Astronautics
			Sept. 13-15, 2010
		
	
	Gong, C.; and Sadovsky, A.: A Final Approach Trajectory Model for Current Operations. AIAA Aviation Technology, Integration, and Operations (ATIO) Conference, Fort Worth, Texas, Paper No. AIAA-2010-9117, Sept. 13-15, 2010.


				
			
		
	
