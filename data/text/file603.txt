
	
	
		
Executive SummaryNASA's UAS Traffic Management (UTM) Project has been tasked with developing concepts and initial implementations for integrating and managing small unmanned aircraft systems (UAS) into the low altitude airspace.To accomplish this task, the UTM Project planned a phased approach based on four Technical Capability Levels (TCLs).As of this writing, TCL4 is currently in development for a late Spring 2019 flight demonstration.This TCL is focused on operations in an urban environment and includes the handling of high density environments, large-scale off-nominal conditions, vehicle-to-vehicle communications, detect-and-avoid technologies, communication requirements, public safety operations, airspace restrictions, and other related goals.Through research and testing to date, NASA has developed an architecture for UTM that depends on commercial entities collaboratively providing services that are traditionally provided by the Air Navigation Service Provider (ANSP) in manned aviation.A key component of this architecture is the UAS Service Supplier (USS), which acts as a communications bridge between UAS operators and the ANSP when necessary.In addition, the collection of USSs form a USS Network to collaboratively manage the airspace through the sharing of data and the adherence to a standard or set of standards required to participate in this USS Network.This document provides a record of the second of four planned steps in the development of interoperable USSs that will ultimately support TCL4 flight testing and formalization of the overall UTM concept.To develop these USSs and their underlying specifications, NASA has planned a series of "Sprints" to work with industry partners in implementing the features and develop proposed specifications for USSs in order to to participate in TCL4.This report describes Sprint Two.In this Sprint, there was a major theme with four goals.The theme was the development and testing of a new USS discovery system, to better enable USSs to find and communicate with each other.The goals supporting this theme were: participants needed to implement and exercise the discovery service for USS-USS communications; USSs needed to demonstrate strategic deconfliction through operation sharing; the systems were to use discovery to aid in handling off-nominal operations; and finally, there was an investigation of an initial off-nominal reporting capability.
BackgroundFor a comprehensive overview on the UTM concept and NASA's efforts to develop it in partnership with the Federal Aviation Administration (FAA), the UTM Project currently has a document repository [NASA 2018b] that contains documentation of many UTM R&D capabilities.An initial understanding of UTM can be gained from two Concept of Operations papers, one from NASA in 2016 [Kopardekar 2016] and one from the FAA in 2018 [FAA 2018].At a high level, UTM is focused on access to the low-altitude airspace for beyond visual line-of-sight (BVLOS), commercial, sUAS operations.To date, such access has been governed by lengthy, one-off applications for waivers, or are limited to restricted airspace.To make widespread sUAS operations safe, fair, efficient, and routine, a set of services to manage the airspace will be required.The functional decomposition of these services in terms of which stakeholders provide which services is an open research question.The major drivers of how the services are defined reflect the scale of intended operations (potentially orders of magnitude more than current manned operations [FAA 2018b]) and the automation envisioned to support that scale.As an illustrative example, flight planning services will likely be an operator function, authorization to access the airspace will likely belong to the ANSP, communication of the operation with other stakeholders would rely on the USS, and some conflict management services may reside within the vehicle itself.Injecting manual processes throughout this collection of services could degrade the overall effectiveness of the system, especially in regard to scalability.The NASA UTM Project has provided initial insights into how such an architecture should look in the future [Kopardekar 2016].The overall architecture (evolved from [Kopardekar 2016]) is shown in Figure 1 below.The Project has also provided inspiration and guidance for systems already providing services to small UAS (sUAS) that did not exist prior to NASA's efforts.The primary example is the FAA's Low Altitude Authorization and Notification Capability (LAANC), which "provides access to controlled airspace near airports through near real-time processing of airspace authorizations below approved altitudes in controlled airspace" [LAANC 2018].A key component of the UTM architecture are USSs.A USS is a state-appointed or third party operated system that will provide service options that are similar to what is traditionally offered to manned operations solely by a state-appointed ANSP.USSs are components that do not have an exact analogy in manned aviation, but are inspired by elements such as Airline Operations Centers and Flight Service Stations.One of the key differences between those examples and a USS is the set of responsibilities and capabilities envisioned for a USS.Services provided by a USS will include strategic deconfliction of operations and conformance monitoring of live operations, amongst others.Many of these services are to be provided in a collaborative and mostly automated manner via communications between USSs forming what is termed a USS Network.In UTM, there will not be a central authority providing guidance in every traffic management decision, as there typically is in manned aviation.To ensure compatibility and interoperability for USSs, NASA has developed a set of APIs and protocols for exchanging data [NASA 2018].These APIs describe many of the connections in Figure 1.
USS DiscoveryIn TCL2 and TCL3, NASA developed a service called "USS Discovery" that enabled USSs to obtain information about each other, which enabled USSs to communicate with each other by providing the USS coverage areas and endpoints for data exchanges.USSs could have several geographic areas and times for which they were providing services.Each of these different areas were called "USS Instances" for that USS.If USS Instances for two different USSs intersected in time and space, then there were rules in the draft USS Specification that described what data those USSs were required to share and under what circumstances.For example, two intersecting USS Instances were required to share new operation announcements with each other, but were not required to share position reports unless other conditions were met (such as a non-conforming operation or intersecting operation plans).All of the USS Instances that intersected a given USS Instance were described as that USS Instance's "Local USS Network" or LUN.See Figure 2 for an example of intersecting USS Instances.In Figure 2, the LUN for USS Instance B would be A1, C, and E. Whereas USS Instance C's LUN would just be B. If an instance did not intersect any other instances, as with D1, then its LUN would be empty.Two instances from the same USS, like A1 and A2 from USS A were allowed to overlap as well.USS Instances were registered with the USS Discovery service as shown in the sequence diagram in Figure 3.Note that USSs were required to have an identity known to Flight Information Management System (FIMS) in order to be authorized to act as a USS.This identity and its privileges was checked against an authorization service called FIMS Authorization or FIMS Authz.Existing USS instances would be notified of new USS instance registrations.That process is described with the sequence diagram in Figure 4. Upon being notified of this new USS Instance, it was the responsibility of that notified USS Instance to determine if the new USS Instance was in its LUN and then to communicate appropriately with that new USS Instance.This process for discovery was proven functional through implementation, simulation, and field demonstrations in activities for TCL2 and TCL3.However, some shortcomings were identified.Firstly, it is a centralized service, thus it is a single point of failure in the architecture.If USS Discovery was unavailable for any duration, USSs would have no certainty as to the status of other USS Instances nor their operations.Secondly, it was built to live within FIMS, a new system that the ANSP would therefore need to provide.ANSPs may be reluctant to provide new services if other options are available.If the system is provided by a third party, other questions must be addressed, including how that third party is chosen, how they are reimbursed for providing that service, who oversees that service, etc.In addition, while flexibility is a positive trait for USSs by defining exactly in which areas they would like to provide services, that flexibility adds some complexity in assuming that USSs can effectively recognize and track their LUNs.Finally, there were issues with USS Instances that may become unresponsive themselves; in these cases, it great uncertainty about the state of the airspace results, as it is not clear if that USS is still providing services or if that USS incorrectly senses its state as being available.It was this list of shortcomings that provided opportunity for additional approaches to be developed.Project Wing proposed a distributed, gridded approach to discovery, which they called "InterUSS."
InterUSSInterUSS divides the airspace into a regular array of grid cells.These grid cells are backed by a shared ledger (currently implemented using Apache ZooKeeper [Apache 2017]) that provides guarantees on the ordering of data that are stored within it.This shared ledger is distributed amongst several servers and, thus, offers positive qualities in terms of availability and scalability.In addition, its distributed nature allows for deployment options wherein the USSs themselves may host nodes in that distributed ledger.For a deeper understanding of InterUSS, the documentation provided by Project Wing is most informative and will not be duplicated here [Wing 2018].However, as a summary, a simple description of the concept follows.USSs determine which grid(s) a proposed operation will intersect.Data related to the USS managing those operations are written to those grids and includes elements such as the name of the USS, the URLs from which requests for data can be made, timestamps for when the data are written or updated, etc.The detailed API, including a version specific for TCL4, is currently available publicly online and the interested reader is directed there for further details [Wing 2018b].In this initial concept, no operational data are written to the grid, just metadata related to the operation allowing for fetching of the operational data directly from the associated USS.Ordering of the data that is written is provided through the use of a 'sync_token' for each grid which is fetched from the system together with the current state of USSs active in that grid.The USS with the proposed operation checks that there are no conflicts by requesting operation data from the active USSs.When the USS with the proposed operation is satisfied that there are no conflicts, the appropriate information is written to the shared ledger with the sync_token.If the state of the grid has not changed in the meantime, the write is successful and now other USSs will be aware that another USS is active in that grid with an operation that is either planned or may now be active.InterUSS is a trademarked system referring to a particular implementation of this concept.The trademarking is in place to protect the "main" implementation as proposed by Wing while allowing alternate branches or forks of the code to be untrademarked as features and concepts are developed.NASA requested specific changes to InterUSS to better align and support NASA's concepts and requirements within UTM for TCL4.Project Wing has implemented those changes (and continues to do so) within a non-trademarked TCL4 branch of their codebase.The modified, non-trademarked version is called Gridded USS Discovery (GUD).Three key modifications for GUD are as follows:1. Per-operation data are stored in the grid in the form of the primary key of each operation (the Globally-Unique Flight Identifier or GUFI) along with key elements like start and end time of the operation along with fields for signatures of the data represented in the grid.WIthout this modification, when a USS updates its information in the grid (modifying an existing operation or adding a new one), other USSs need to retrieve ALL of that USSs operations and then determine what is new in that data set.This can be tedious, involve excessive data exchange, and may be error-prone.By allowing individual flight metadata to be stored in the grid, it is easier for other USSs to determine what has changed in the grid.2. Convenience methods for updating the per-operation data without needing to write all of a USS's operation data with each update for that USS.Without this improvement, if a USS has many operations in a given grid, then all of the data for each of those operations needed to be rewritten to the grid to affect a change for any of them or to add a new operation for that USS. 3. Convenience methods for writing to multiple grids as a single transaction.This was requested by several USS implementers due to the complexity of sending cross-grid plans to GUD.Rather than have each USS manage that complexity, it was agreed that these convenience methods allowed for more consistent and correct implementation of cross-grid plans.This modified system is referred to as the Gridded USS Discovery or GUD approach.It is a version of GUD that is tested in Sprint 2 as described in this document.
Conformance Monitoring ServiceA key service that NASA envisions being required for all future UTM USSs is the Conformance Monitoring Service.Details on the requirements of this service will be published in the near future, but a short summary is provided here.The Conformance Monitoring Service supports a UAS operator with compliance related to their intended operation volumes.Alerts from the USS to the operator and from the USS to other USSs are required when an operation leaves its conformance volumes and operation volumes.For example, when an operation reports positions outside of its operation volumes, it must be designated as a ROGUE operation and that state is communicated to other USSs.Prior to becoming ROGUE, an operation may be deemed NONCONFORMING with respect to its conformance volumes (which are contained within the operation volumes).This is a primary form of situational awareness for USSs in terms of conflict management.Operators themselves would not have a reliable way to make this information known to other operators without the assistance of a USS and, thus, it is a required service for all USSs.In this Sprint, analysis of the USSs performance in regard to Conformance Monitoring will be performed, but this is not listed as an explicit goal of the Sprint.Investigating Conformance Monitoring will be a focus area of Sprint 4, but the data collected during this sprint allowed for early analysis and feedback to the implementers.
Progression of USS DevelopmentThe checkout process for components of UTM is important for several reasons.Primarily it ensures that the various components are built to the specification and will be appropriately interoperable.Secondarily, the process allows for conceptual shakeout by performing data exchanges between components, which enables researchers to check whether the defined use cases are being met.The key components in the initial phase of UTM development are the UAS Operator Client, the USSs, and FIMS.These three components are central to all of the key use cases in UTM and their appropriate interconnection must be verified to ensure proper execution of simulations and flight tests.For a summary of how USSs were developed and "checked out" in previous UTM TCL flight activities, the interested reader is directed to the Sprint 1 report [Rios 2018b].This process will ultimately provide insight into how USSs should be evaluated in the future for operational use.
TCL4 USS Checkout ProcessesInternalizing the lessons learned from TCLs 1-3, and planning for TCL4, NASA decided to take a more proactive and prescriptive approach to development.A plan was developed to implement features as a cohort of USSs over the course of many months.The features were broken into 4 major "Sprints" with a capstone activity in each sprint being a collaborative simulation exercising the features.This activity is collaborative in that plans are discussed with all USS implementers, feedback is provided by those implementers, plans are documented, and a schedule is agreed upon for testing and execution within each sprint cycle.Each team may have its own internal sprint cycles to achieve the goals of the cross-team sprints.For example, the NASA USS development team uses 2 week sprints to implement and test features to prepare for the collaborative simulation.The process is depicted in Figure 5.
Sprint 2 OverviewIn this section, we provide an overview of this second sprint, including the participants and overall goals.The collaborative simulation was executed on October 2, 2018.
ParticipantsNine industry partners participated in Sprint 2. They are listed in alphabetical order in Table 1 along with their respective call sign and contribution during the activity:
WING
Project Wing Discovery Service ProviderThere were also two NASA implementations (NUSS and AOLN) of a USS that participated, giving a total of 10 USS implementations available to evaluate requirements, performance, and overall interoperability.This report will not provide details on the performance of any given USS in an identifiable manner.
GoalsThe following list of goals/features were agreed to by NASA and industry USS implementers and targeted during Sprint 2. Further context for these items is provided in the subsequent subsections.
1.Implement and exercise discovery service enabling USS-USS communications 2.Demonstrate strategic deconfliction through operation sharing 3.Use discovery to aid in handling off-nominal operation 4.Develop initial off-nominal reporting
Implement and exercise discovery service enabling USS-USS commsThis is the first activity wherein GUD is implemented and tested by multiple USSs.
Demonstrate strategic deconfliction through operation sharingUsing GUD and requesting appropriate Operation data, USSs are able to stay separated from each other on a strategic, pre-departure time horizon.This approach meets the strategic deconfliction requirements for UTM [Rios 2018].
Use discovery to aid in handling off-nominal operationIn cases wherein operations enter an off-nominal state (fly away, loss of navigation, etc.), it is a requirement under the Conformance Monitoring Service provided by every USS to its operators to alert other USSs about that operation's condition.GUD allows a USS to determine which other USSs require alerting.This functionality was exercised in this Sprint.
Develop initial off-nominal reportingAfter an off-nominal event for an operation, it is a requirement under Off-Nominal Situations Management for the operator and USS to collect data to report on that situation.This process was exercised in this Sprint.
Test DetailsIn this section, the organization of the collaborative simulation for TCL4 Sprint 2 is provided, followed by details of the actual mechanics of execution.
Test OrganizationTo execute the collaborative simulation with USS implementers, the following definitions were developed:Table 2. Definitions used for simulation planning.
Definitions:Actor An entity participating in this simulation activity.In this case, it is primarily USS implementers.Role A set of steps for an actor to enact.
SceneA defined collection of Roles along with notes for how those Roles are expected to interact.
ConfigurationEach Scene may be run several times.Each run will have different Roles assigned to different Actors.A Configuration is defined as a unique assignment of Roles to Actors.Each role-test pairing will specify the relevant geography/geographies to be used by the Actor.The "Actors" were the USSs defined in the table above in addition to various NASA actors: two for the NASA USSs, one for test coordination, and one for data collection.The "Roles" were defined as follows:Table 3. Roles defined for use within simulation.
Roles:RegularRay A nominal operation.NevermindNina Plan announced, but cancelled prior to operation start.
DeconflictedDianaA nominal operation that needs to deconflict from an already present Operation plan.
ReportingRickyThis operation goes NONCONFORMING in some sense.The USS prompts for off-nominal report, gets data, submits to service.
FlexibleFelixThis operation knows its goals and dynamically plans and replans as needed to accomplish goals using information from GUD and other USS.The "Scenes" were defined as follows:Table 4. Scenes defined for use within simulation.
Scenes:Blood Simple Initial scene with no planned conflicts or off-nominals.Operations do not simulate flight.Fargo Some nominal ops, some ops that will be in strategic conflict.O Brother, Where Art Thou?Some nominal ops, and then one or two off-nominals.Test comms from USS-USS and post operation reporting.
True GritEveryone has mission objectives known only to them.Work with discovery and other USSs to accomplish.Each Role is provided a geographical region within which to execute its simulated operation.Each configuration for Sprint 2 will not be published here, but within Table 5 is a sample from the "Fargo" scene: The geographical information was shared with partners in the form of a GeoJSON file.The various geographies had labels for common referencing.A lightly populated area of North Dakota, one of the FAA test sites, away from major airports and national parks, was chosen for this activity.Outlines of the various geographies are visible in Figure 6.Two key differences in these geographical definitions from Sprint 1 [Rios 2018] are the inclusion of the grid boundaries (the four large white squares) and the inclusion of several markers that allowed for new types of mission directives for the various roles.
ExecutionThe USS implementers managed their systems remotely.NASA orchestrated and monitored the collaborative simulation from Ames Research Center at Moffett Field, CA.An open telecon line included all stakeholders.NASA announced scenes and configurations over the telecon line and prompted for status checks as the USSs steps through their actions.Occasionally the group (NASA and USS implementers) would make dynamic decisions to re-run a configuration, skip a configuration, or drop a USS that may have technical difficulties.For detailed debugging or specific questions between stakeholders, a separate set of online chat channels were available.These channels were also used to mark certain common, key steps with each simulated operation.For example, USSs would send a message to indicate that an operation was announced to the discovery system, was activated, went non-conforming, or was closed.Having this record persisted in the chat application allowed for debugging and reconstructing events if needed after the event and to track key points in the scenes.For example, NASA sometimes would wait until seeing an announcement by all USSs in the chat application before moving on to the next step in a scene.To complete all configuration runs of all scenes, NASA allotted four hours.The collaborative simulation for Sprint 2 was completed in under 3.5 hours.
Data CollectionDuring the event, NASA had a system named the "USS Data Collector" (UDC) which serves the same API as the USSs, but is not an actual USS.It is active solely to receive data from other USSs.All operations, position reports, and UTM messages are sent to UDC whenever they might be sent to any other system.UDC allows for real-time collection and viewing of operational data.After the event, the USS implementers were asked to provide data related to the data exchanges.These data included expected and actual responses, latency, endpoint names, etc.From this self-reported data, NASA can begin to measure overall system latency and interoperability amongst USSs.A sample of the USSExchange data model provided by one of the partners after the simulation is shown in Figure 7 with certain fields redacted.A partner may develop thousands of such USSExchange instances depending on the volume of data exchanged during the simulation.{ "measurement_id": "6235b2b4-f58a-4ff0-ab43-f1cd4ba26c69" , "event_id": "TCL4_USS_Sprint_1" , "exchanged_data_pk": "c734ef47-6c3e-4e4d-9c82-faa2976bec9d" , "exchanged_data_type": "UTM_MESSAGE" , "source_uss": "<redacted>" , "target_uss": "<redacted>" , "reporting_uss_role": "TARGET_USS" , "time_request_initiation": "2018-08-21T16:03:17.998Z" , "time_request_completed": "2018-08-21T16:03:18.108Z" , "endpoint": "https://<base_url_redacted>/utm_messages/c734ef47-6c3e-4e4d-9c82-faa2976be c9d" , "expected_http_response": 204 , "actual_http_response": 204 , "jws": "<redacted for brevity>" , "jws_public_key": "<redacted>" , "comments": "" } This Sprint introduced off-nominal reporting.Each operation that experienced an off-nominal event (either planned for that scene or otherwise) was requested to submit an off-nominal report.These reports were defined by a schema shared with the USSs prior to testing called an OffNominalReport.Many of the elements of this schema are designed for human operators to complete, so the focus was mostly on the process of obtaining, organizing and submitting the data rather than emulating "true" data submissions.A sample of the off-nominal data with many of the "human supplied" data elements missing by design, is shown in Figure 8. { "autopilot_maker": "mypilot RW" , "autopilot_model": "mypilot203" , "comm_system": "super comm at 892 MHz" , "contact": { "comments": "this is a comment" , "email_addresses": [ "me@example.com"], "name": "John Doe" , "phone_numbers": [ "5550000000" ] }, "gcs_program": "myGCS" , "gufi": "cf800c21-b7eb-4f4f-b78f-ffd9902f97fa" , "reporter_narrative": "A non-conforming message was generated and sent to surrounding USSs after a scripted operator purposely stopped sending position updates for 5 seconds.", "reason_for_report": "NONCONFORMING" , "report_id": "9e3843b0-fa62-48e0-b516-9a3523f0877a" , "scripted": false , "time_occurance": "2018-10-02T15:13:32.331Z" }
Initial Results and DiscussionIn this section, some analysis of the collected data is provided.This includes some relevant statistics from the UDC data as well as the USSExchange and OffNominalReport data.
Operational DataThe operational data collected by UDC are summarized in Table 6.In some scenes, it was not required that an operation actually commence, so it is not appropriate to assume that the expression "number of operations/number of positions" would provide an average number of positions per operation.Similarly for the relationship of messages to operations.In general, these data simply provide a sense of the volume of data exchanged during this simulation.While there were only 209 messages and 4585 positions, recall that those elements typically have multiple recipients, so the overall data traffic is actually larger than may be indicated in this table alone.A breakdown of the types of messages sent during this simulation is provided in Figure 9.In the current concept, the announcement of OPERATION_CLOSED is only required when that operation is (or was at some time) a NONCONFORMING or ROGUE operation.However, USS implementers have commented that having that message improves efficient use of the airspace as other stakeholders know when a particular operation is complete.The OPERATION_CONFORMING message is only required when a NONCONFORMING operation comes back into conformance.However, some USSs have found utility in using that message to announce when an operation becomes ACTIVE since that announcement is not required in the current specification.Again, this may add to stakeholder awareness of airspace activity, increasing their operational decision-making related to safety and efficiency of their own operations and will be revisited when updating the USS specification.
Off-Nominal ReportsThis sprint was the first opportunity to test the flow of data related to OffNominalReports.As such, the focus was mostly on the data schema and the process for collection rather than analyzing the correctness of these data.High level summary is provided in Table 7. Interpretation of these data is not necessarily obvious.Firstly, each NONCONFORMING or ROGUE operation may submit multiple OffNominalReports.For example, if an operation becomes NONCONFORMING more than once during its operation, then it would require a report for each such instance of the transition to NONCONFORMING.This requirement exists given the possibility that the transition to NONCONFORMING may be due to different reasons each time.Secondly, it is possible for an operation to be NONCONFORMING for reasons beyond 4D containment within its operation volumes.In this test some USSs were asked to become NONCONFORMING due to insufficient position reports from the simulated operator.The current requirement in the USS specification is to have an operator performing a beyond visual line-of-sight operation to report positions to its USS at a rate of 1Hz.If that operator fails to do so, that operation becomes NONCONFORMING.If it fails to produce the correct rate of position reports, it may become ROGUE.Thus, some NONCONFORMING messages counted in the table above include operations that did not leave its operation volumes, but were simulated to have insufficient position reports.Operations that should have produced OffNominalReports and appropriate UTM Messages during the simulation, but failed to do so are discussed in the next section.
Uncaught Off-NominalsThree separate USSs were caught with operations that left their announced 4D volumes without accompanying alert messages to other USSs.This is a fundamental failure of those USSs to implement Conformance Monitoring.In general, this is a difficult element to test prior to simulation since any scripted non-conformance can be shown by the USS to work properly, but demonstrating that all off-nominal operations are caught in an automated way is not feasible.A total of 16 operations across three USSs left their 4D operational volumes without accompanying alert messages to other USSs.These operations were caught via post-operations analysis of the collected position reports and their respective operation volumes.Since operation volumes often intersect in time and space, it is non-trivial to determine the operation volume within which a position should have been.This is because at any given time, more than one operational volume may have had temporal boundaries that could enclose the time the position was reported.This means that the positions have to be shown to be outside of all operation volumes in four dimensions.For all 16 flagged operations, none were problematic due to lateral violations.Stated another way, all positions for all 16 operations were valid if just examined in the planar dimensions.All violations occurred due to positions being either:1. reported after the valid time window(s) for that operation's volume(s), 2. reported at altitudes over the maximum or under the minimum for all volumes that were valid at that time, 3. or both.This implies that the USS implementers may have the correct logic in place to catch 2D violations, but need to refine their implementations to capture temporal and altitude violations.Regardless, these examples provide solid examples for all USSs on improper Conformance Monitoring implementation which has value in the long run for USS development and standardization.Some altitude errors were reported as being due to incomplete or poor implementation of conversion between Above Ground Level (AGL) and Mean Sea Level (MSL) altitude values in the simulation of those operations.This may point to the need for some implementers to use Supplemental Data Service Providers (SDSPs) to aid in that conversion or to spend more development effort to implement that feature completely and correctly.There was a decrease in data collected from Sprint 1 to Sprint 2 (40,851 USSExchange data samples down to 3,656 along with three fewer USSs submitting data), however the analysis still provides some insight into the performance of the USSs.The interoperability metric improved from 22.2% unexpected responses to 1.2% unexpected responses.Sprint 2 results summarized in Figure 10.Some contributors to this improvement include the relaxation of the requirement to provide a message signature in the HTTP header of the exchanged data and the improvement of implementation by the USS implementers.In terms of data exchange latency, the smaller sample size may have had an effect in increasing the standard deviation of the response times.However, there were no extreme outliers in the 10's of seconds for Sprint 2. Again, this is partly due to the smaller sample size, but is still encouraging that the system is able to handle responses in a reasonable amount of time.The results are deemed "reasonable" via satisfaction of the indicated use cases without stakeholders indicating excessive or even human-noticeable lag in the data exchanges.No further detailed analysis was performed in relation to latency.
USS Exchange Data
SummaryIn preparation for NASA's TCL4 flight demonstrations, development is underway on USS implementations.These implementations are being tested in a collaborative manner with USS industry partners to ensure the goals of a future flight test will be met while calculating interoperability and performance metrics.This series of collaborative simulations provides insight into the UTM system and design.Overall, the amount of self-reported data after Sprint 2 for data elements such as OffNominalReports and USSExchange data was worse than in the first sprint.NASA will be working with the USS implementers to improve the reporting rate in Sprint 3 and to emphasize the required nature of such reporting in the actual execution of TCL4.In this sprint, the major goal was the implementation and testing of a new mechanism for discovery.This discovery service proved it was capable of supporting USS-USS communications, strategic deconfliction, and off-nominal operations.In addition, NASA was able to collect operation data to determine improper implementations of the Conformance Monitoring service that is required of USSs.Finally, this sprint provided initial insight into the off-nominal reporting process.Overall, development on TCL4 concepts as implemented by USS is progressing well.Figure 1 .1Figure 1.UTM architecture.
Figure 2 .2Figure 2. Notional example of a Local USS Network or LUN.
Figure 3 .3Figure 3. Sequence diagram illustrating a USS registering with discovery.
Figure 4 .4Figure 4. Sequence diagram illustrating announcements to USSs from discovery.
Figure 5 .5Figure 5. Development process for TCL4 USSs..
Figure 6 .6Figure 6.Operational geographies used in testing, each has a referenceable label (not shown).
Figure 7 .7Figure 7. Sample of USS exchange data collected after event in JSON format.
Figure 8 .8Figure 8. Sample of off-nominal data collected after event in JSON format.
Figure 9 .9Figure 9. Breakdown of specific UTMMessage types sent by USSs during the simulation.
Figure 10 .10Figure 10.Breakdown of expected vs. unexpected responses during the simulation.
Table 1 . Sprint 2 industry participants1Call SignOrganizationRole in Sprint 2ARMPAirmapUSSAROSAiRXOS, A GE VentureUSSANRAANRA TechnologiesUSSAVISAvision RoboticsUSSONESOneSkyUSSROCKRockwell CollinsUSSSIMUSimulyzeUSSUBERUberUSS
Table 5 . Configuration table for various runs of "Fargo" scene.5Role LabelAlphaBetaGammaDeltaEpsilonZetaDeconflictedDeconflictedDeconflictedRole NominalNeilNominalNeilNevermindNinaDianaDianaDianasquare_markersquare_marker_{1,6}_{2,5}square_marker_{3,4}Geog d2_geo_blued2_geo_purpled2_geo_redalt: 0-150alt: 300-400alt: any, go aroundA NUSSARMPAVISONESAOLNB AOLNANRAARMPUBERSIMUAROSCAVISUBERROCKANRAONESConfigurations ConfigurationsD AVISAROSSIMUARMPNUSS
Table 6 . Summary of data collected after simulation from USSs.6Total Operations170Total Positions reported4585Total Operation Volumes across all Operations1368Total distinct UTM Messages sent between USSs209
Table 7 . Summary of off nominal operations and OffNominalReport data collected.7Operations with positions outside operation volumes32
Table 8 summarizes general information regarding the USS Exchange data collected.
Table 8 . Summary of USSExchange data collected after simulation from USSs.8USSs submitting valid USSExchange data4Total USSExchange instances included in analysis3656Number of unique servers targeted with data exchanges12
		
		
			

				


	
		Apache Software Foundation
		
			Apache
		
		
		
			2017. Nov 2018
		
	
	Apache ZooKeeper
	Apache 2017] Apache Software Foundation, "Apache ZooKeeper," https://zookeeper.apache.org/ , fetched Nov 2018.



	
		Practice for Application of Federal Aviation Administration (FAA) Federal Aviation Regulations Part 21 Requirements to Unmanned Aircraft Systems (UAS)
		
			Faa ; Kopardekar
		
		
			JosephParimal
		
		
			ThomasRios
		
		
			MarcusPrevot
		
		
			JaewooJohnson
		
		
			JohnEJung
		
		
			IiiRobinson
		
		10.1520/f2505
		
	
	
		NASA Ames Research Center. 16th AIAA Aviation Technology, Integration, and Operations Conference
		Washington, DC; Washington, DC; Washington, DC; Washington, DC
		
			ASTM International
			2018. May 2018. Oct 2018. Kopardekar 2016. Jun 2016. Oct 2018
		
	
	LAANC 2018] Federal Aviation Administration
	FAA 2018] Federal Aviation Administration, "Unmanned Aircraft System (UAS) Traffic Management (UTM), Concept of Operations v1.0," Washington, DC, May 2018. [FAA 2018b] Federal Aviation Administration, "FAA Aerospace Forecasts: Fiscal Years 2018-2038," https://www.faa.gov/data_research/aviation/aerospace_forecasts/media/FAA_Aerospace_Forec asts_FY_2018-2038.pdf . Washington, DC, retrieved Oct 2018. [Kopardekar 2016] Kopardekar, Parimal, Joseph Rios, Thomas Prevot, Marcus Johnson, Jaewoo Jung, John E. Robinson III, "Unmanned Aircraft System Traffic Management (UTM) Concept of Operations," NASA Ames Research Center. 16th AIAA Aviation Technology, Integration, and Operations Conference, Washington, DC, Jun 2016. [LAANC 2018] Federal Aviation Administration, "UAS Data Exchange," https://www.faa.gov/uas/programs_partnerships/uas_data_exchange/ , Washington, DC, retrieved Oct 2018.



	
		National Aeronautics and Space Administration (NASA)
		
			Nasa ; Nasa UtmApis
		
		
			;Rios
		
		
			Joseph;Rios
		
		
			Joseph
		
		10.1007/978-1-349-94186-5_816
		
	
	
		The Grants Register 2018
		Moffett Field, CA; Moffett Field, CA; Wing
		
			Palgrave Macmillan UK
			2018. Oct 2018. Oct 2018. Rios 2018. Jul 2018. Oct 2018. 2018
			
		
	
	National Aeronautics and Space Administration. version 1.0.1
	NASA 2018] National Aeronautics and Space Administration, "NASA UTM APIs," https://github.com/nasa/utm-apis , retrieved Oct 2018. [NASA 2018b] National Aeronautics and Space Administration, "NASA UTM Documents," https://utm.arc.nasa.gov/documents.shtml , retrieved Oct 2018. [Rios 2018] Rios, Joseph. "Strategic Deconfliction: System Requirements, Final Report," NASA Report, Moffett Field, CA, Jul 2018. [Rios 2018b] Rios, Joseph, et al., "UTM UAS Service Supplier Development: Sprint 1 Toward Technical Capability Level 4," NASA Technical Memorandum, Moffett Field, CA, Oct 2018. [Wing 2018] Project Wing, "InterUSS Platform(™): Overview, Governance, Requirements, Design & Implementation," version 1.0.1, https://github.com/wing-aviation/InterUSS-Platform/blob/master/assets/InterUSS%20Platform%2



	
		API Platform and Data Handler
		
			SanjayPatni
		
		10.1007/978-1-4842-2665-0_6
		%20Technical%20Architecture%20-%20v1.0.1.pdf
		
	
	
		Pro RESTful APIs
		
			Apress
			Oct 2018. Nov 2018
			
		
	
	-%20Technical%20Architecture%20-%20v1.0.1.pdf , retrieved Oct 2018. [Wing 2018b] Project Wing, "InterUSS Platform -Data Node Stateless API," https://app.swaggerhub.com/apis/InterUSS_Platform/data_node_api/ , retrieved Nov 2018.


				
			
		
	
