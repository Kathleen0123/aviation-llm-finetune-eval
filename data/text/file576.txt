
	
	
		
I. IntroductionThe long-range vision for the future Next Generation Air Transportation Systems (NGATS) includes objectives for operating as efficiently in low-visibility conditions as in high-visibility conditions. 1,2An aspect of attaining equivalent operational capability is in the Tower, where large economic and operational costs are incurred when weather conditions impair the tower controllers' visibility.These costs include but are not limited to creating bottlenecks in the national traffic flow management system.The benefits analysis for potential savings that could be realized from effective low-visibility tools for the tower has been estimated in the hundreds of millions of dollars per year. 3lthough various analysts may have estimated the benefits of an effective low-visibility tower tool, they rarely specified how such tools would be designed and operated.One approach proposes using augmented reality (AR) technology to achieve the desired functionality.Augmented differs from Virtual Reality (VR) insofar as AR allows users to view the 'real' world along with superimposed or composited computergenerated displays.The content of these displays is determined by the observer's point of view, usually by tracking head orientation and motion. 4,5][8][9] American Institute of Aeronautics and Astronautics
II. BackgroundTower controllers are required to gaze out of the windows of their cabs to visually observe relevant vehicles.Although a discussion of the tower controller methodology is beyond the scope of this paper, one essential difference between them and the other ATC domains is that the duties of tower controllers require them to look out of their cab windows at the natural, 3-D world.They must also scan the several 'headsdown' displays found in the tower cab.The concept for using computer graphics to 'augment' visual reality for Air Traffic Control Towers was proposed by the late Lloyd Hitchcock at the FAA Technical Center in the 1980s.No prototype construction was attempted at that time, and little was published, though many recall how Mr. Hitchcock speculated on several methods that could aid tower controllers.Some of these speculations included a head-tracked, head-mounted, see-through display.‡ In the 1970s and '80s there were several experiments with 3-D Cockpit Displays of Traffic Information (CDTI). 10,11There were also very successful demonstrations of flight-deck heads up display (HUD) technology for surface movement under low-visibility conditions, 12,13 and synthetic vision. 14ecently there has been increasing interest in using augmented reality technology to enable tower controllers to operate equivalently under Visual (VMC) and Instrument (IMC) Meteorological Conditions.Such tools may use head-mounted augmented-reality systems that innovatively fuse relevant data from tower systems (e.g., air traffic control and surface surveillance radar) and display appropriate information as an overlay on the tower controller's view of airborne and surface vehicles.A tower controller's vision must not be impaired, therefore the head-worn displays must not constitute a vision impairment, e.g. the device's housing must not block peripheral vision.The AR systems should effectively mitigate visibility problems for tower controllers, such as weather or other obstructions, such as architecture or vehicles, and synthesize data from other systems.Sensor fusion for tower controllers has come to signify (at least in 'gedanken' experiments) the presentation of situation-specific appropriate information.The displayed information may be synthesized and extracted from multiple data sources, as opposed to the current practice of scanning multiple screens, paper slips, etc., and filtering the essential information from clutter and data that may not be relevant.‡ Private communications from Stephen Ellis and Earl Stein.Unfortunately none of Mr. Hitchcock's writings on this subject appear to have survived.In 1998 NASA demonstrated that contemporary commercial 'web-based' technologies could be used to create inexpensive and portable 3-D ATM displays.The proof-of-concept prototype was called Situation Awareness Virtual Environment (SAVE).A screen shot of SAVE, in this case running under the Netscape browser on an SGI workstation, is illustrated in Figure 1.This prototype used Java, VRML, and browsers to create 3-D displays of both the terminal area and the positions of arriving and departing aircraft.The real-time air traffic control radar data were served to SAVE by NASA's Center TRACON Automation System (CTAS) software.Specifically, the CTAS 'Communication Manager' (CM) process acquired live ATC radar data and then served a filtered stream to SAVE.The SAVE software integrated the radar positions with the 3-D airport database, rendered in the VRML graphics standard.SAVE ran in most browsers that supported Java and VRML plug-in modules, and therefore was portable-by-design across different operating systems and hardware. 15ne innovative aspect of SAVE was its re-use of flight simulation 'out-the-window' display databases.These highly accurate 3-D visual databases of specific airports that meet the visual requirements recommended by the FAA as one of the attributes of flight simulators that merit 'Level-D' certification, the FAA's highest rating for flight simulation performance.Flight Safety International collaborated with NASA to adapt their visual databases so that the accuracy of the survey and other features would be retained, while details and features deemed unnecessary for ATC applications were deleted.A 60 Mb flight simulation visual database of Atlanta Hartsfield International Airport (encoded in a proprietary format) was filtered to produce a 1.25 Mb VRML model.This model became a principal 3-D display component for the SAVE engineering prototype.The exercise with the Atlanta Hartsfield database demonstrated the proof-of-concept of re-using flight simulation databases for (potentially) an entirely different application, e.g.real-time air traffic control instrumentation.There are visual databases for over 300 airports that are meet accuracy requirements for Level-D flight simulator certification.Each of these databases may be inexpensively filtered into highly accurate 3-D data sets that may be used in TOWER AR and VR systems.Although SAVE demonstrated the feasibility of creating 3-D radar displays with a modern software and network architecture, it retained a conventional computer-human interface, i.e. screen for output, keyboard and mouse for input.There was no head-mounted display capability in the initial SAVE prototype.Following SAVE, several AR and VR tower collaborations between ATM and human factors (HF) researchers were conducted at Dr. Stephen Ellis's Advanced Displays and Spatial Perception laboratory.This laboratory's interests focused on spatially calibrated position sensing and low latency, high update rate rendering of spatially stabilized, world referenced virtual objects. 16Recently their system demonstrated responses below most users detection levels for a variety of conditions. 17he resultant prototypes did not re-use much SAVE code, except for the interface to the CTAS Communication Manager (CM) module.This CTAS CM interface provided the human factors systems with access to both pre-recorded samples and live TRACON radar data.One prototype used live Dallas-Ft.Worth (DFW) Terminal Area radar data for remote real-time visualization of the DFW TRACON traffic.This North Texas traffic was remotely visualized in a VR display located at NASA Ames.Flight plan data provided type and airline information for the 3-D animated aircraft types.The DFW radar aircraft-position data provided 'key' frame information every 4.8 seconds, so more than 50 'fill' frames per second were rendered to create the 3-D animated VR display.These prototypes were never intended for operational use, though they provided proof-of-concept experience for later development.Another motivation for developing effective ARTT is to provide a bridge technology between the current tower system and mid-21 st Century 'Virtual Tower' facilities in the NGATS vision.Air Traffic Control Tower (ATCT) construction and staffing are extraordinarily expensive.The current NGATS longrange vision foresees 'Virtual Towers' facilities that will be less expensive to operate and maintain than the current system of 'brick and mortar' Tower facilities.The Virtual Towers would permit consolidation of resources, since there is no requirement to co-locate the future facilities on the same sites as the airports they control.A variety of 'Virtual Tower' concepts have been proposed, ranging from traditional VR to facilities in which photo-realistic real-time rendering systems create a 360-degree virtual tower view.Although this concept may take decades to perfect, there are strong financial, safety, and security incentives to develop this technology.One of the principal risk areas associated with Virtual Tower operation is the confidence level that the digital 'virtual world' contains all the necessary and sufficient visual cues that tower controllers currently use in the course of their duties.There is considerable uncertainty on the definition and extent to which a American Institute of Aeronautics and Astronautics Virtual Tower's virtual 'world' must resemble the referential real world, e.g., the airport and the behavior of its vehicles, environmental conditions, and activities.If an augmented reality tower tool became certified and operational in the next several decades, it is expected that the user community of tower controllers would report any discrepancies between the real world that they observe and the virtual world that was presented via the see-through AR displays.The ARTT technology could therefore be used to validate, verify, and certify the Virtual Towers' representations of reality.In this manner ARTT could be used to maintain verisimilitude quality.Tower AR systems may become a critical path item for 'virtual tower' R&D.These systems can become interim products sooner than purely VR systems, so the intermediate benefits of AR technology would accrue to the current, physically co-located tower facilities.The use of ARTT operationally would generate discrepancy reports from the controllers every time they noticed a difference between the computer-generated displays and the real world.Conversely, the inability of controllers to detect such discrepancies would become valuable data for the validation, verification and certification of the virtual worlds for use in future Virtual Tower facilities.Some of technologies that are critical to AR product development are still too immature for practical operational use, e.g., the lack of adequate light-weight, bright, commercially available, see-through HMD hardware.Apart from these technological obstacles, there are a variety of issues and ideas that will require investigation before an ARTT would be certified for operation.Rather than wait until all obstacles are removed before addressing these issues, we propose using the build-evaluate design methodologies that are commonly employed by modern software and hi-tech commercial enterprises.These build-evaluate cycles are components of several product development management philosophies, are variously described as 'user-centered design,' 'iterative prototyping,' 'build-evaluation cycles,' 'usability engineering,' or other terms of art.This approach differs greatly from studies conducted expressly in controlled laboratory settings, or from efforts that are limited to evaluating the usefulness a particular prototype.The usercentered design approach is often characterized by using a prototype to assist a subject-matter expert to understand a novel technology or idea.The evaluations and suggestions of these subject-matter experts are then used to influence the requirements, designs, and stages of development of successively refined prototypes.The engineering prototypes are therefore typically evocative, rather than definitive. 18,19
III. ARTT 1.0: Initial Prototype Development & EvaluationIn 2004 a version of the VR system used for human factors experiments was slightly modified and reused as an initial augmented reality tower tool prototype.Much of this prototype, illustrated in Figure 2, was made from integrating commercially available off-the-shelf components.The see-through headmounted display was a Sony Glasstron PLM-S700.§ The head-tracking technology was provided by the InterSense InertiaCube3 ** hardware (a three degree of freedom inertial sensor with a flux gate compass to control drift and accelerometers to determine the direction of the gravity vector), with AuSIM † †,20 motiontracking software. 21his prototype, called ARTT 1.0, also used the CTAS Communication Manager to acquire pre-recorded and live ATC radar data.The prototype used a FAA Northern California TRACON (NCT) data feed to track aircraft in the Moffett Field vicinity.This data stream was served by the FAA William J. Hughes Technical Center via secure network.A subset of CTAS software ingests the NCT radar information, reusing the same method developed for SAVE.The CTAS Communication Manager (CM) serves data to the ARTT software modules, including aircraft flight plan (e.g.aircraft type, equipage, flight route) and state (e.g.latitude, longitude, altitude, ground speed, vertical speed, heading).A CTAS Planview Graphical User Interface (PGUI) is used to provide a conventional 2-D view of NCT radar data.The data represented on the PGUI may be quickly compared with the tower's operational radar display.This feature is often useful in identifying differences and anomalies between the operational and research versions of the NCT data feeds.§   The initial ARTT prototype was not, of course, intended for operational use.The ARTT Field Study Safety Plan requires that the on-duty controller is unencumbered, while a second controller (who does not control traffic while evaluating ARTT) uses the prototype in a purely evaluation 'shadow' mode.Figure 3. illustrates the floor plan of Moffett Tower, including the relative positioning of the on-duty controllers, the experimenters, and the off-duty controller who is nominally 'shadow-controlling' and evaluating the ARTT 1.0 prototype.Though Moffett Field has a relatively small tower, note the variety of systems the controllers use: (clockwise from bottom, starting at the ladder) Typewriter (for reports); workstation reserved for air force administrative applications; Automated Surface Observing System (ASOS) Controller Equipment -Information Display Systems (ACE-IDS); Flight Data Input/Output (FDIO) subsystem; the Flight Data Console; Automatic Terminal Information Service (ATIS); the Ground Control Console; Remote Automated Radar Tracking System (ARTS) Color Display (RACD); the Local Control Console; the Supervisor Console.The ARTT 1.0 system ran on two laptops located in front of the Supervisor Console.The prototype served as both an instantiation and an evocative illustration of AR technology.The initial ARTT prototype was evaluated for usability, benefits, and insufficiencies.It was intended to be evocative, illustrating the potential of AR technology along with the limitations of current commercial off the shelf (COTS) AR components.The questionnaires in the initial study had sections covering AR Technology per se and other sections addressing the performance of the initial ARTT prototype.Other sections covered potential benefits of using ARTT for specific tower operations, and the potentials for integrating the other Tower systems with ARTT.American Institute of Aeronautics and AstronauticsThe controller evaluations for ARTT 1.0 influenced the requirements analysis and subsequent research objective and design decisions that led to the next engineering prototype, ARTT 2.0.The cadre identified several prototype deficiencies, such as low optical transmissivity of the head mounted display (HMD), unacceptable compensation for tower lighting conditions, inadequate symbology and data block information display, and unacceptable discomfort caused by wearing the HMD.The cadre was unanimous both in supporting ARTT technology and its potential, while at the same time finding the ARTT 1.0 prototype too uncomfortable, immature, and insufficient for practical use.Each controller completed a survey that included professional history, a brief optical examination, 140 Likert test questions, an evaluation of system maturity level, and post-session video interviews.As an example of how the controller evaluations were used in the design process, we present a subset of the evaluation data, most notably those items where the controllers showed a great deal of agreement with each other, as indicated by the standard deviation of evaluation scores.For instance, one set of questions dealt with the effect of ARTT technology on standard tower tasks and duties.This set was predicated by a usability question: "How useful would ARTT technology be in performing the following tasks?"Altogether there were sixty-four questions in this set.Results from a dozen questions in which the controller cadre took consistently strong positions are summarized in Figures 4. and    In the six usability questions illustrated in Figure 4. the cadre were instructed to use the prototype as an illustration of AR technology.The controllers were not judging the effectiveness of ARTT 1.0 in this section of the survey.They were asked to use the prototype to visualize a mature version of ARTT.The essential question for the controllers was: 'If ARTT was working properly, with all the bugs fixed and hardware limitations overcome, would this technology be useful, or would it simply be extraneous and provide little practical benefit?'Most controllers indicated that the AR technology could be useful for surface control and issuing ground clearances, particularly when visibility is impaired by IMC.They also felt that AR technology would be useful for a variety of tower duties, as well as issuing overflight control instructions, coordinating with general aviation aircraft, and (perhaps most importantly) addressing runway incursion issues.The controller cadre strongly agreed that AR technology could be useful for coordinating with a variety of traffic and vehicles.For instance, as illustrated in Figure 5, there was strong feeling among the controllers that ARTT would be useful under IMC weather, and when air and surface traffic is obscured by architectural obstructions.They also felt strongly that ARTT could be useful when coordinating with surface vehicles that were obscured by weather or architecture, and could generally benefit coordination with a variety of surface vehicles, particularly Crash & Fire Rescue Vehicles.The controllers also had strong and largely uniform opinions that ARTT technology would be useful in acquiring information on aircraft location and heading, along with other specific information on the aircrafts' flight data blocks.They also strongly agreed that ARTT technology would be useful for acquiring surface vehicle location and increasing situation awareness.In the summation questions, illustrated in Figure 6, the controller cadre indicated strong agreement on the immaturity and inadequacy of the as-built ARTT 1.0 prototype.This response was supported by many other questions in the Likert test survey.The controllers expanded on their lack of satisfaction in their video interviews, often detailing specific faults and recommendations for improvements.Special attention was paid to these responses when determining the specifications, objectives, and design of the follow-up prototype, which became ARTT 2.0.The evaluations indicated that the ARTT 1.0 computer generated displays were insufficient.In spite of the prototype's immaturity, the controllers also strongly felt that the AR technology provided the opportunities for new data block information presentation and formats.Perhaps most importantly, most of the controllers used their experience with the ARTT 1.0 prototype to stimulate their imaginations and brainstorm suggestions on how AR technology could be used to create new kinds of tower decision support tools.American Institute of Aeronautics and Astronautics Most of the controllers' serious complaints were directed at the Sony Glasstron 'see-through' HMD.The minimum requirement for an operational ARTT is that the display device must not impair the controllers' vision.The Glasstron HMD failed this test, and to date no display device has conclusively demonstrated that it meets the minimal ARTT display requirements.Most of the controllers found the Glasstron uncomfortable, some found it intermittently disorienting, and one became nauseous from using it.The HMD also made it difficult for the controllers to scan the airfield, since it required an unacceptable amount of manual adjustment to compensate for lighting conditions that could change from window to window, and was often difficult to read against bright back-lighting.The Glasstron optics have a 20% transmissivity, similar to dark sunglasses, so they could not be used at night.Everyone agreed that the Glasstron seriously impaired the controllers' vision, and that ARTT could not be considered for operational use unless the HMD was improved.They also agreed that it functioned well as a representation of immature AR technology, and were enthusiastic about this technology, providing it could mature and become reliable and usable.The cadre unanimously gave the highest ratings and support for the potential of ARTT technology to benefit Tower operations.This was only question (out of 140) in which all the controllers gave identical responses, and it was gratifying that they all strongly agreed that it is important to support continued ARTT research and development.IV. ARTT 2.0: Resultant Engineering Prototype NASA developed a second ARTT engineering prototype whose design was greatly influenced by ARTT initial field evaluation results.Particular emphasis was placed on practical display technology issues, since this was the highest priority of the controller cadre.The 1.0 prototype re-used software that was originally intended for human factors laboratory-based experiments.The 2.0 prototype completely discarded this 're-used' code and replaced it with new software that was designed specifically for ARTT applications.One of the first design decisions was to use open source software and packages whenever practical in an effort to reduce development costs and increase options for collaborations and technology transfer.Many of the suggestions made by the controllers during the evaluation of ARTT 1.0 involved speculations on possible decision support tools.Several of these tools required real-time 3-D animation techniques.In order to implement and experiment with such speculative tools and interfaces the ARTT 2.0 software architecture was designed to support a wide range of 3-D graphics functionalities.The software was written with Open Scene Graph, an open-source graphics software package.The introduction of the 3-D database to represent the airport background was a major departure from the ARTT 1.0 design.A 3-D visual database of Moffett Field and adjacent Ames Research Center, usually called 'Virtual Ames,' became a component of ARTT 2.0, just as the DFW visual database had been a component of SAVE in the previous decade.This visual database was developed with techniques used to build out-the-window displays for flight simulators.'Virtual Ames' was used to overlay the actual seethrough views of Moffett Field.As described above, the 300+ FAA-certified Level-D visual databases of the world's major airports may provide the basis for inexpensively adapting ARTT to any of these locations.As illustrated in Figure 7, the graphical representation of the airport overlays the actual objects that are seen from the Moffett Tower cab.Hangar One, a familiar landmark, is clearly visible in the background.The photo above (featuring Hangar One) was taken through the Lumus PD-10 ‡ ‡ see-through display.The 3-D CGI of Hangar One is in the foreground, overlaying the actual building.ARTT 2.0 uses head-tracking sensors to determine an observer's field-of-view, and superimposes 3-D simulated images over the actual views of the airfield.The trucks, tarmac, tower-cab window seam, and others features are not created by CGI; they are see-through optical images of the 'real' world.The ARTT 2.0 prototype, like its predecessor, uses NCT radar data as the primary data source for the display of aircraft position and flight data block information.The baseline flight data block is similar to the format used in the first prototype, though alternative formats can be easily composed.American Institute of Aeronautics and Astronautics  The image in Figure 8 is a detail from a photograph taken through an ARTT 2.0 'see-through' head mounted display (in this case, a LiteEye LE-500 § § ).The display shows a 2-degree diameter circle indicating the position of an actual aircraft (ASA301), which can be seen next to the 'A.'The flight data block indicates the aircraft is 4.42 nautical miles from the tower, and that it is flying at approximately 2100 ft.altitude.The foreground (bottom) is computer-generated imagery (CGI) of a 3-D visual database of Moffett Field, which covers the corresponding 'real' area.Note the relative coincidence of actual and CGI runways and other features.The display is optically transparent above the CGI horizon.In this photo the buildings, tree line, and hills on the horizon are optical images of the actual features; not CGI.The actual lights of flight ASA301 are visible inside the CGI red circle, to the left of the 'A' in the first line of the flight data block.In this case the width of the circle is two degrees.The first line of the flight data block identifies the aircraft, the second line displays the aircraft's distance from the tower, and the third line displays the aircraft's altitude.The prototype does not always capture the aircraft within a two-degree circle.Consistently accurate performance is degraded by projection surface orientation uncertainty, magnetic effects on the compass, and the sensor-eye relative orientation errors.The most glaring deficiencies in the ARTT prototypes involve performance of see-through display hardware.This is a problem that confronts almost all AR projects; a completely acceptable see-through HMD is not yet available.The principal problem with all existing AR systems is that they all (to varying degrees) impair the observer's vision.The FAA regulations reasonably prohibit tower controllers from wearing optical equipment that impairs vision.New optical technologies (such a light-guide optical elements 22 ) promise practical solutions in the near future, though it not possible to accurately and confidently predict the date when these solutions will be perfected, mass-produced, and commercially available.The current ARTT 2.0 activities include integration and evaluation of different display hardware technologies.American Institute of Aeronautics and Astronautics
V. Concluding RemarksAugmented Reality tools may improve air traffic control tower efficiency and safety during adverse visibility, and also contribute to development of Virtual Tower facilities.This paper presents motivations, an approach for researching usability requirements, and a basic design for future augmented reality tower tools.This design may be summarized as using head-tracking sensors to determine the controllers' field of view, and contextually overlaying that view with computer generated information derived from air traffic control systems.This paper does not present a finished design for a tool ready for implementation.There are still many problems that must be addressed by more research and technology maturity.The controllers' evaluations confirm that the prototypes are not acceptable for operational use.They also indicate enthusiasm for ARTT technology as an aid for tower operations, providing the technology matures sufficiently.Although many fundamental problems must be understood and solved, there is ample reason to believe that eventually an ARTT may become operational.There are many valid approaches that may move ARTT from an intriguing concept to a practical tool fit for operational use.The approach described in this paper focuses on iterative engineering prototype buildevaluation cycles.This approach is greatly influenced by contemporary management practices for mitigating design uncertainties.These methods have proven effective in developing requirements, specifications, and designs for a variety of cutting edge products.This is particularly true when the finished product is not completely defined and also requires technology that is not mature, available, practical or (as in the case of augmented reality tools for air traffic control towers) where the unresolved fundamental research issues challenge the development of satisfactory designs.Figure 1 .1Figure 1.Situation Awareness Virtual Environment (SAVE) used realtime ATC radar to represent aircraft as 'cubes' viewed over a 3-D display of the airport.
Figure 2 .2Figure 2. Initial Augmented Reality Tower Tool engineering prototype, ARTT 1.0.Unlike the operational radar display or the PGUI, an ARTT system presents the NCT date from the point of view of the controller, not from a top-down view.The head-motion detector determines the heading, pitch, and roll of the controller's view.The ARTT software performs 3-D clipping operations to superimpose the position of the aircraft on the see-through display.The baseline symbology used a red circle (typically 2-degrees in diameter) to indicate the location of the aircraft.A data block containing flight information (e.g., aircraft id, distance from tower, altitude) was positioned near each of these circles.In 2005 Moffett Field Aviation Management authorized ARTT development and field evaluation at Moffett Tower.A cadre of five Moffett Tower controllers were the subject matter experts who evaluated the initial ARTT prototype.They had an average of 13.6 years of tower experience (max: 20; std dev: 6.0), and an average of 4.6 years Moffett Tower experience (max: 10; std dev: 5.5).The controllers were encouraged to contribute ideas for future ARTT enhancements, symbology, decision support tools, and general observations for ARTT requirements analysis.The initial Moffett Tower ARTT field study was the first time AR technology was evaluated by a tower controller team in their own tower using real-time ATC radar data and observations of live air traffic.The initial ARTT prototype was not, of course, intended for operational use.The ARTT Field Study Safety Plan requires that the on-duty controller is unencumbered, while a second controller (who does not control traffic while evaluating ARTT) uses the prototype in a purely evaluation 'shadow' mode.Figure3.illustrates the floor plan of Moffett Tower, including the relative positioning of the on-duty controllers, the experimenters, and the off-duty controller who is nominally 'shadow-controlling' and evaluating the ARTT 1.0 prototype.Though Moffett Field has a relatively small tower, note the variety of systems the controllers use: (clockwise from bottom, starting at the ladder) Typewriter (for reports); workstation reserved for air force administrative applications; Automated Surface Observing System (ASOS) Controller Equipment -Information Display Systems (ACE-IDS); Flight Data Input/Output (FDIO) subsystem; the Flight Data Console; Automatic Terminal Information Service (ATIS); the Ground Control Console; Remote Automated Radar Tracking System (ARTS) Color Display (RACD); the Local Control Console; the Supervisor Console.The ARTT 1.0 system ran on two laptops located in front of the Supervisor Console.The prototype served as both an instantiation and an evocative illustration of AR technology.The initial ARTT prototype was evaluated for usability, benefits, and insufficiencies.It was intended to be evocative, illustrating the potential of AR technology along with the limitations of current commercial off the shelf (COTS) AR components.The questionnaires in the initial study had sections covering AR Technology per se and other sections addressing the performance of the initial ARTT prototype.Other sections covered potential benefits of using ARTT for specific tower operations, and the potentials for integrating the other Tower systems with ARTT.
5.
Figure 3 .3Figure 3. Floor plan of Moffett Air Traffic Control Tower, showing positions of operational controller (dark blue), off-duty controller evaluating ARTT (light blue), and researchers (grey).
Figure 4 .4Figure 4. Six Tasks & Duties: Controller responses to usability questions posed in the form "How useful would ARTT technology be in performing the following tasks?The range bars represent the standard deviation of the opinion scores (n=5).
Figure 5 .5Figure 5. Six more "Tasks & Duties" usability questions that also elicited strong responses and agreement among the controller cadre.
Figure 6 .6Figure 6.Six questions concerning the value of ARTT technology to acquire information items.Note that not all question in this section elicited such uniformly strong responses.
Figure 7 .7Figure 7. Augmented Reality Tower Tool (ARTT) version 2.0 uses head-tracking sensors to determine an observer's field-of-view and superimposes 3-D simulated images over the actual views of the airfield.
Figure 8 .8Figure 8. Photo was taken though an ARTT 2.0 'see-through' display at Moffett ATC Tower.The lights and optical image of the aircraft (ASA301) are framed by the CGI red circle and labeled by the adjacent data block.
Sony Corporation of America, 50 Madison Ave # 9, NYC, NY 10022.** InterSense Corporation, 36 Crosby Drive, Suite 150, Bedford, MA 01730, USA † † AuSIM, Inc., 3239 El Camino Real, Suite 205, Palo Alto, California 94306.The AuSIM software driver for head position sensors was the end product of a development sequence done in the Advanced Displays and Spatial perception lab.American Institute of Aeronautics and Astronautics
			‡ ‡ Lumus Ltd.,_2 Bergman St., Rabin Science Park, Rehovot 76705, Israel
			§ § Liteye Systems, Inc., 7330 S. Alton Way, Bldg.12, Suite C, Centennial, CO 80112
		
		

			
AcknowledgmentsARTT research and development is a collaborative effort between NASA and FAA, partially funded by a grant from the FAA's ATO -Ops Planning Systems Engineering Division.The authors give special thanks to Diana Liang and Richard Jehlen for their patient guidance and support.We give special thanks to Stephen Ellis, Bernard 'Dov' Adelstein, Michael Hill, David Encisco, Mathias Ma. James Murphy, Jinn-Hwei Cheng, Akbar Sultan, Joe Cisek, Randy Bolanos, Bobby Cates, Ahmad Khalil, Raman Azizian, Joe King, Gary Uyehara, Steve Elkins, John Kaneshige,Mike Logan, Eric Wendel, and Sudeep Singh Grover.We would like to particularly appreciative of the FAA William J. Hughes Technical Center.Mr Phil Zinno created the original networks that served ATC data to NASA, and these essential services are continued by the FAA TMA Program Office's Brian Ujvary and Aaron Maul.We also thank the management of Moffett Tower for allowing us to conduct research in their operational facility, Paul Sutter, Geary Tiffany, Roy Williams, TJ Forsythe, and Robert Remick, and the cadre of Moffett Field Tower controllers who participated in the evaluations: Will Golden, John Moore, Bill Smith, James Grippi, and Sam Andrade.
			

			

				


	
		Technology Pathways
		10.17226/11420
	
	
		Progress Report to the Next Generation Air Transportation System Integrated Plan
		
			2005. 2005
			National Academies Press
		
	
	2004. 2 Joint Development and Planning Office
	Joint Development and Planning Office, "Next Generation Air Transportation System: Integrated National Plan," 2004. 2 Joint Development and Planning Office, "2005 Progress Report to the Next Generation Air Transportation System Integrated Plan," 2005.



	
		Prepared for: Advanced Air Transportation Technology Program
		
			RShackelford
		
		
			PKarpe
		
		Number: NAS2-13767 Task Order Number: 43628-A00
	
	
		Low/Zero Visibility Tower Tools (L/ZVTT) Benefits Assessment
		Moffett Field, CA
		
			September, 1998
			94035
		
	
	Shackelford, R., and Karpe, P., "Low/Zero Visibility Tower Tools (L/ZVTT) Benefits Assessment," Prepared for: Advanced Air Transportation Technology Program, NASA Ames Research Center, Moffett Field, CA 94035 Under: Contract Number: NAS2-13767 Task Order Number: 43628-A00, September, 1998



	
		A Survey of Augmented Reality
		
			RonaldTAzuma
		
		10.1162/pres.1997.6.4.355
	
	
		Presence: Teleoperators and Virtual Environments
		Presence: Teleoperators & Virtual Environments
		1054-7460
		
			6
			4
			
			
			MIT Press - Journals
		
	
	Azuma, R. T. "A Survey of Augmented Reality," Presence: Teleoperators and Virtual Environments Vol. 6, No.



	
		Recent advances in augmented reality
		
			RAzuma
		
		
			YBaillot
		
		
			RBehringer
		
		
			SFeiner
		
		
			SJulier
		
		
			BMacintyre
		
		10.1109/38.963459
	
	
		IEEE Computer Graphics and Applications
		IEEE Comput. Grap. Appl.
		0272-1716
		
			21
			6
			
			Nov/Dec 2001
			Institute of Electrical and Electronics Engineers (IEEE)
		
	
	Azuma, R., Baillot, Y., Behringer, R., Feiner, S., Julier, S., and MacIntyre, B., "Recent Advances in Augmented Reality," IEEE Computer Graphics and Applications Vol. 21, No. 6, Nov/Dec 2001, pp. 34-47.



	
		Advanced human-computer interfaces for air traffic management and simulation
		
			RonaldAzuma
		
		
			MikeDaily
		
		
			JimmyKrozel
		
		10.2514/6.1996-3548
	
	
		Flight Simulation Technologies Conference
		San Diego, CA
		
			American Institute of Aeronautics and Astronautics
			July 1996
			
		
	
	Azuma, R., Daily, M., and Krozel, J., "Advanced Human-Computer Interfaces for Air Traffic Management and Simulation," Proceedings of 1996 AIAA Flight Simulation Technologies Conference, San Diego, CA, July 1996, pp. 656-666. American Institute of Aeronautics and Astronautics



	
		20 Virtual Reality und Augmented Reality
		
			NFürstenau
		
		
			SKaltenhäuser
		
		
			MSchmidt
		
		
			BWerther
		
		10.1515/9783110753325-021
	
	
		Mensch-Maschine-Interaktion
		Braunschweig
		
			De Gruyter
			2002
			
		
	
	Fürstenau, N., Kaltenhäuser,S., Schmidt,M., and Werther,B., "Virtual Tower: Virtual Reality Technologien und Multimodale Mensch-Maschine-Interaktion für das Flugverkehrsmanagement im Jahr 2015 zur Veröffentlichung," Braunschweig, DLR-Nachrichten, 2002.



	
		Augmented reality in a simulated tower environment: effect of field of view on aircraft detection
		
			JSchmidt-Ott
		
		
			SREllis
		
		
			BDAdelstein
		
		
			JKrozel
		
		
			RJReisman
		
		
			JGips
		
		NASA TM 2002-211853
		
			2002
		
	
	Schmidt-Ott, J., Ellis, S.R., Adelstein, B.D., Krozel, J., Reisman, R.J. and Gips, J., "Augmented reality in a simulated tower environment: effect of field of view on aircraft detection," NASA TM 2002-211853, 2002.



	
		Augmented reality for air traffic control towers
		
			RonaldReisman
		
		
			StephenEllis
		
		10.1145/965400.965426
		
	
	
		ACM SIGGRAPH 2003 Sketches & Applications
		San Diego, CA
		
			ACM
			2003
		
	
	cited 11 Sep 2006
	Reisman, R J., and. Ellis, S. R., "Augmented reality for air traffic control," Proceedings of the SIGGRAPH 2003 conference on Sketches & applications: in conjunction with the 30th annual conference on Computer graphics and interactive techniques, San Diego, CA, 2003, URL; http://www.siggraph.org/s2003/conference/sketches/07.html [cited 11 Sep 2006].



	
		Perspective Traffic Display Format and Airline Pilot Traffic Avoidance
		
			StephenREllis
		
		
			MichaelWMcgreevy
		
		
			RobertJHitchcock
		
		10.1177/001872088702900401
	
	
		Human Factors: The Journal of the Human Factors and Ergonomics Society
		Hum Factors
		0018-7208
		1547-8181
		
			29
			4
			
			1987
			SAGE Publications
		
	
	Ellis, S.R., McGreevy, M.W., and Hitchcock, R.J. "Perspective traffic display format and airline pilot traffic avoidance," Human Factors, No. 29, 1987, pp. 371-382.



	
		A Cockpit Display Designed to Enable Limited Flight Deck Separation Responsibility
		
			WalterWJohnson
		
		
			VernolBattiste
		
		
			SheilaHollandBochow
		
		10.4271/1999-01-5567
	
	
		SAE Technical Paper Series
		Anaheim, CA.
		
			SAE International
			1999
			12
		
	
	Johnson, W.W., Battiste, V., and Bochow, S.H., "A cockpit display designed to enable limited flight deck separation responsibility," Proceedings of the 1999 World Aviation Conference, Anaheim, CA., 1999. 12



	
		Taxiway Navigation and Situation Awareness (T-NASA) System: Problem, Design Philosophy, and Description of an Integrated Display Suite for Low-Visibility Airport Surface Operations
		
			DavidCFoyle
		
		
			AnthonyDAndre
		
		
			RobertSMccann
		
		
			ElizabethMWenzel
		
		
			DurandRBegault
		
		
			VernolBattiste
		
		10.4271/965551
	
	
		SAE Technical Paper Series
		
			SAE International
			1996
			
		
	
	Foyle, D.C., Andre, A.D., McCann, R.S., Wenzel, E., Begault, D., and Battiste, V., "Taxiway Navigation and Situation Awareness (T-NASA) System: Problem, design philosophy and description of an integrated display suite for low-visibility airport surface operations," SAE Transactions: Journal of Aerospace, No. 105, 1996, pp. 1411-1418.



	
		Research Station at Cambridge and somewhat later at the Wantage Research Laboratories of the Atomic Energy Research Establishment. By the mid- or late 1950s national research programs on food irradiation were also underway in Belgium, Canada, France, The Netherlands, Poland, the Soviet Union, and the Federal Republic of Germany. This early history of food irradiation has been reviewed by Goldblith (9), Goresline (10), and Josephson (11). In 1960 the first books on food irradiation appeared, written by Desrosiers and Rosenstock in the United States (12) and Kuprianoff and Lang in Germany (13). A first international meeting devoted to discussion of wholesomeness and legisla­ tive aspects of food irradiation was held in Brussels in 1961 (14). In the United Kingdom the report of a government working party on irradiation of food (15) summarized and evaluated the studies done until 1964. The first commercial use of food irradiation occurred in 1957 in the Federal Republic of Germany, when a spice manufacturer in Stuttgart began to improve the hygienic quality of his products by irradiating them with electrons using a Van de Graaff generator (16). The machine had to be dismantled in 1959 when a new food law prohibited the treatment of foods with ionizing radiation, and the company turned to fumigation with ethylene oxide instead. In Canada irradiation of potatoes for inhibition of sprouting was allowed in 1960 and a private company, Newfield Products Ltd., began irradiating potatoes at Mont St. Hilaire, near Montreal, in September 1965. The plant used a 60Co source and was designed to process some 15,000 t of potatoes a month. It closed after only one season, when the company ran into financial difficulties (17). In spite of these setbacks, interest in food irradiation grew worldwide. At the first International Symposium of Food Irradiation, held in Karlsruhe, Germany, and organized by the International Atomic Energy Agency (IAEA), representa­ tives from 28 countries reviewed the progress made in research laboratories (18). However, health authorities in these countries still hesitated to grant permissions for marketing irradiated foods. At that time only three countries— Canada, the United States, and the Soviet Union— had given clearance for human consump­ tion of a total of five irradiated foods, all treated with low radiation doses. The food industry had not yet made use of the permissions. Irradiated foods were still not marketed anywhere. Questions about the safety for human consumption of irradiated foods were still hotly debated and this was recognized as the major obstacle to commercial utilization of the new process. As a result of this recognition the International Project in the Field of Food Irradiation (IFIP) was created in 1970, with the specific aim of sponsoring a worldwide research program on the wholesomeness of irradiated foods. Under the sponsorship of the IAEA in Vienna, the Food and Agriculture Organization (FAO) in Rome, and the Organization for Economic Cooperation and Development (OECD) in Paris, 19 countries joined their re­ sources, with this number later growing to 24 (see Table 1). The World Health
		
			BLHooey
		
		
			DCFoyle
		
		
			ADAndre
		
		10.1201/9781482273168-16
		
	
	
		Safety of Irradiated Foods
		Ottawa, Canada
		
			CRC Press
			September 2002. 2004
			
		
	
	Synthetic Vision Would Give Pilots Clear Skies All the Time. cited 11 Sep 2006
	Hooey, B. L., Foyle, D. C., and Andre, A. D., "A human-centered methodology for the design, evaluation, and integration of cockpit displays," Proceedings of the NATO RTO SCI and SET Symposium on Enhanced and Synthetic Vision Systems, September 2002, Ottawa, Canada. 14 NASA Aviation Safety Program, "Synthetic Vision Would Give Pilots Clear Skies All the Time," 2004, URL: http://www.nasa.gov/centers/langley/news/factsheets/SynthVision.html [cited 11 Sep 2006]. 15



	
		Situation Awareness Tower Tool
		
			RReisman
		
		
			AFarouk
		
		
			1998. Sep 2006
		
	
	URL: http:icwwws
	Reisman, R,, and Farouk, A., "Situation Awareness Tower Tool, 1998," URL: http:ic- wwws.arc.nasa.gov/projects/SAVE [cited 11 Sep 2006].



	
		Discrimination of Changes of Latency during Voluntary Hand Movement of Virtual Objects
		
			StephenREllis
		
		
			MarkJYoung
		
		
			BernardDAdelstein
		
		
			SherylMEhrlich
		
		10.1177/154193129904302203
	
	
		Proceedings of the Human Factors and Ergonomics Society Annual Meeting
		Proceedings of the Human Factors and Ergonomics Society Annual Meeting
		2169-5067
		1071-1813
		
			43
			22
			
			1999
			SAGE Publications
		
	
	16 Ellis, S. R. , Young, M. J. , Ehrlich, S. M., and Adelstein, B. D. "Discrimination of changes of latency during voluntary hand movement of virtual objects," Proceedings of the Human Factors and Ergonomics Society, 1999, pp. 1182-1186.



	
		Generalizeability of Latency Detection in a Variety of Virtual Environments
		
			StephenREllis
		
		
			KaterinaMania
		
		
			BernardDAdelstein
		
		
			MichaelIHill
		
		10.1177/154193120404802306
	
	
		Proceedings of the Human Factors and Ergonomics Society Annual Meeting
		Proceedings of the Human Factors and Ergonomics Society Annual Meeting
		2169-5067
		1071-1813
		
			48
			23
			
			2004
			SAGE Publications
		
	
	Ellis S. R., Mania K., Adelstein, B. D., Hill, M., "Generalizeability of latency detection in a variety of virtual environments," Proceedings of the Human Factors and Ergonomics Society, 2004, pp. 1836-1841



	
		Cost-Justifying Usability
		
			RandolphGBias
		
		
			DJMayhew
		
		10.1016/b978-012095811-5/50022-5
	
	
		Cost-Justifying Usability
		Boston
		
			Elsevier
			1994
			
		
	
	Bias, R. G. and Mayhew, D. J., Cost-Justifying Usability. Harcourt Brace & Co., Boston, 1994



	
		A Practical Guide to Usability Testing
		
			JSDumas
		
		
			JRedish
		
		
			1993
			Ablex, Norwood, NJ 20
		
	
	Dumas, J. S., and Redish, J., A Practical Guide to Usability Testing, 1993, Ablex, Norwood, NJ 20



	
		Achieving minimum latency in virtual environment applications
		
			BDAdelstein
		
		
			MHill
		
		
			SREllis
		
	
	
		Proceedings of the 2004 Image Society Meeting
		the 2004 Image Society Meeting
		
			2004
		
	
	Adelstein, B. D., Hill, M., Ellis S. R., "Achieving minimum latency in virtual environment applications," Proceedings of the 2004 Image Society Meeting, 2004.



	
		<title>Improved temporal response in virtual environments through system hardware and software reorganization</title>
		
			RichardHJacoby
		
		
			BernardDAdelstein
		
		
			StephenREllis
		
		10.1117/12.237447
	
	
		SPIE Proceedings
		
			SPIE
			February 1996
			
		
	
	Jacoby, R. H., Adelstein, B. D., Ellis, S. R. "Improved temporal response in virtual environments through system hardware and software reorganization," Proceedings of the SPIE 2653, Stereoscopic displays and virtual reality systems III, February 1996, pp. 271-284.



	
		P-21: Extremely Compact High-Performance HMDs Based on Substrate-Guided Optical Element
		
			YaakovAmitai
		
		10.1889/1.1830976
	
	
		SID Symposium Digest of Technical Papers
		SID Symposium Digest
		0097-966X
		
			35
			1
			310
			May 2004
			Wiley
		
	
	Amitai, Y., "Extremely Compact High-Performance HMDs Based on Substrate-Guided Optical Element," SID Symposium Digest of Technical Papers, Vol. 35, No. 1, May 2004, pp. 310-313.


				
			
		
	
