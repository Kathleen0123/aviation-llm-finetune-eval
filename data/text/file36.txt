
	
	
		
I. Introductionillions of small Unmanned Aircraft Systems (sUAS) are predicted to fly in U.S. airspace within the next decade. 1These sUAS will ultimately conduct a variety of public safety, commercial, and hobbyist operations and are likely to do so in close proximity to each other and while flying over or near population centers.Currently there is no established infrastructure that will allow for and safely manage the kinds of such operations envisioned by the UAS community stakeholders.NASA is collaborating with the FAA and UAS industry stakeholders to develop a research platform for a UAS Traffic Management (UTM) system and use it to determine how an operational UTM system can enable access for sUAS into the low-altitude airspace in a safe, efficient, and fair manner. 2With significant input from UAS community partners from industry, government, and academia, NASA has progressively developed and tested this UTM Research Platform (URP) since 2014. 3,4n June 2017, NASA and its partners completed a campaign of flight tests hosted by six of the FAA-designated UAS Test Site Operators.This UTM Technical Capability Level 2 (TCL 2) National Campaign was comprised of flight tests of selected capabilities of the concept of operations (ConOps) of UTM using the URP, which had changed significantly since the TCL 2 flight tests that occurred in October, 2016 3 and the TCL 1 National Campaign that occurred in April, 2016. 4 By engaging various members of the UAS community in development and operational roles, this campaign provided initial validation of different TCL 2 aspects of the UTM concept including various enabling technologies and operational scenarios.Additionally, measures of performance were defined and calculated from the flight data to establish quantitative bases for comparing flight test activities and to provide potential metrics that might be routinely monitored in future operational UTM systems.This paper provides a brief overview of the UTM concept.The details related to the planning, execution, and initial analysis of the second UTM National Campaign are presented.These details include a discussion of the overall architecture of the National Campaign (including the software architecture), the participating organizations, the flow of data during operations, the various sUAS flown, the types of missions flown, and measures of performance calculated.Also discussed is how this particular test activity contributes to the strategic UTM plan and informs future testing.This information illustrates how this research will enable expanded, real-world UAS operations in the near future.
M
II. BackgroundThe objective of NASA's UTM Project is to determine how to enable routine access to low-altitude airspace for sUAS in a safe, efficient, and fair manner.The UTM platform will provide basic services such as flight planning, flight monitoring, hazardous weather and wind avoidance, and separation assurance.Other potential services include airspace design, terrain and vertical obstruction warnings, congestion management, and contingency planning.In the UTM concept, most of these services will be provided by a number of commercial UAS Service Suppliers (USS) rather than by a single provider such as the FAA (see the UTM Architecture section for more details).NASA instantiated this new architecture for the first time with a number of partners across six FAA UAS Test Sites during the TCL 2 National Campaign.NASA contracted with six FAA UAS Test Sites to meet NASA objectives and demonstrate, evaluate, and refine functional designs, technology prototypes, and the UTM ConOps developed under the UTM Project.The Test Sites partnered with government, industry, and academia to complete the flight tests.The TCL 2 National Campaign evaluated many objectives of common interest to NASA, the Test Sites, and the partners at the sites such as beyond-visual-line-of-sight (BVLOS) operations, altitude stratified operations, and dynamic replanning (see Section IV for a list of objectives).TCL 2 is the second of four increasingly complex TCLs that support the entire range of sUAS from remotely piloted vehicles to command-directed sUAS and more autonomous sUAS.The TCL complexity is based on the following four metrics, which account for the risks associated with operations: (1) population density; (2) the amount of people and property on the ground; (3) the number of manned aircraft in close proximity to the sUAS operations; and (4) the density of the UAS operations.UTM will continue to evolve to maintain the desired level of safety and operational efficiency to account for increased levels of complexity.TCL 2 supports beyond-visual-lineof-sight (BVLOS) and low-density operations.It supports operations over sparsely populated land and operations where there are few manned aircraft with close proximity to the area of operation.The following two subsections describe the UTM architecture and the Test Site operations.
A. UTM ArchitectureFigure 1 illustrates the overarching UTM architecture.This architecture is a significantly updated version of the one described by Kopardekar et al. 2 and reflects newly proposed divisions of responsibilities between the Air Navigation Service Provider (ANSP) and industry.The URP software is hosted by NASA and consists of a Flight Information Management System (FIMS) research prototype and a UAS Service Supplier (USS) research prototype with situation displays and iOS apps.The URP can be assumed to contain truth data in relation to constraints in the airspace, messages related to UTM operation, and other relevant data.The architecture, presented in Fig. 1, delineates the functions provided by the ANSP and UTM operators/stakeholders.Within this context, the ANSPs provide traditional air traffic management (ATM) services for operations within the National Airspace System (NAS).UTM is separate yet complementary in which the UTM operators and stakeholders conduct and provide support for sUAS operations independent of the ANSP's purview, but not in isolation of it.The FIMS is a central, cloud-based component that acts both as a bridge to the NAS and as a broker of information between stakeholders.Connections to the FIMS are allowed from USSs that meet minimum requirements related to functionality, quality of service, and liability.These USSs then support missions by UAS operators.Connections and communications are internet-based and built on industry standards and protocols.American Institute of Aeronautics and Astronautics
B. Test Site Operating Authority and Operational AreasThe Test Sites operated under the authority given to them through various certificates of authorization (COAs) from the FAA in the ranges specified in those COAs.The Test Sites are located in six states and provide a diverse set of test environments.These Test Sites are Griffiss International Airport in New York, Northern Plains Unmanned Aircraft Systems Test Site (NP UAS TS) in North Dakota, the Nevada Institute for Autonomous Systems (NIAS), Lone Star UAS Center (LSUASC) in Texas, University of Alaska at Fairbanks (UAF), and Virginia Tech Mid-Atlantic Aviation Partnership (MAAP).The range locations are described in Table 1.American Institute of Aeronautics and Astronautics✓ ✓ ✓ ✓ ✓ ✓ ND ✓ ✓ ✓ ✓ ✓ NV ✓ ✓ ✓ ✓ ✓ ✓ NY ✓ ✓ TX ✓ VA ✓ ✓ ✓✓ American Institute of Aeronautics and Astronautics
IV. Flight Operation Features and Objectives
A. Flight Operation FeaturesFlight testing exercised the following features, with the Test Sites ensuring that tools and processes were in place to efficiently execute them: altitude stratified operations, BVLOS operations, altitude-stratified BVLOS operations, dynamic (en route) replanning, response to alerts from the UTM System, and implementation of contingencies (e.g.sudden need for return to base (RTB)).Five of the six features were exercised at every site; dynamic replanning was not exercised at AK and ND.
B. Flight Operation ObjectivesFlight objectives were developed by NASA to test technologies and scenarios that will help enable the TCL 2 capabilities.The detailed flight objectives of interest were to:1. Conduct UTM Operations with a TCL 2-compatible USS that was not developed by NASA 2. Conduct UTM Operations to test/determine information requirements between the components of the UTM system 3. Test USS and human operator reactions to ANSP constraints and directives 4. Test/determine weather service information requirements 5. Test surveillance services 6.Test and evaluate scheduling and planning capabilities 7. Evaluate best practices for ground-based sense and avoid 8. Evaluate geofencing and conformance monitoring capabilities 9. Gather data to develop communication and navigation (C&N) guidance to industry to ensure that 1)Unmanned Aircraft (UA) are under operational control of the pilot, and 2) UA remain within a defined area 10.Evaluate human factors requirements related to data creation and display 11.Demonstrate a BVLOS package delivery while other aircraft are operating nearby.
V. MethodThe flight tests of the TCL 2 National Campaign occurred during 19 flight test days over a four-week period (from May 15 th through June 9 th ).Each test site began its activities with several days of limited (i.e., "Shakedown") ground and flight test activities to gradually exercise the capabilities and processes that would be needed for the comprehensive flight test activities that they would execute by the conclusion of their National Campaign support.The first two subsections below list the test site partners and present examples of the type of scenarios tested by the sites.Throughout the shakedown and final testing activities at the Test Sites, NASA employed several methods of data collection.These data collection methods are described in the five subsections that follow.
A. Test Sites with List of Vehicles, Operators, and USSNASA was interested in testing the UTM system using different vehicle platform types and at least one USS implementation other than the NASA USS.Accordingly, a variety of vehicle types and USSs were used during the campaign.Table 3 lists the Test Sites and the vehicle types flown, the operators flying the aircraft, and the USS being used.American Institute of Aeronautics and Astronautics   The flight scenarios conducted during the demonstration were developed to address test objectives through the performance of operations that mirrored real world use cases.The use cases that were incorporated into scenarios highlighted aspects and challenges unique to each test site and its operators.The objectives presented in Section IV were met through scenarios that included the following use cases: mapping; search and rescue; pipeline survey/inspection; videography; package deliveries to stranded hikers, miners, and flood victims; law enforcement American Institute of Aeronautics and Astronautics situations; response to mine disaster; unauthorized airspace intrusion; HAZMAT response; aerial survey following storm damage; runway/airfield inspection; bridge inspection following flood; Part 77 obstruction inspection; rail line inspection; UAS-to-UAS encounter sets; conformance monitoring test sets; public safety responses to capsized boat and storm damage with non-cooperative intruder operations; reported lost child; agricultural survey; and radar survey.Many of the flight scenarios that were conducted included multiple simultaneous operations that involved interacting operations performing activities in line with the use cases outlined above.This approach not only provided an opportunity to emulate real-world operations, but it also afforded the ability to meet multiple test objectives simultaneously.Figure 3 presents an example based on post-processed data that shows four different operations that were performed in support of a test site's flight scenario.In this example, the operation volumes (i.e., four-dimensional volumes specifying the airspace in which the operations will occur) that were submitted for each operation are shown in red.A mapping mission was performed by a single UA in close proximity to another operation that was being performed in support of a search and rescue mission.Meanwhile, two vehicles were performing a coordinated BVLOS pipeline inspection in which they were in close proximity laterally but were safely separated vertically through altitude-stratified operation volumes.Each of these operations was conducted while connected to the UTM data collection architecture such that the performance of the flight scenario could be monitored as it unfolded.In this particular example, objectives that were met through the performance of the scenario were that: a partner-developed USS (i.e., non-NASA) was used to support the scheduling and planning of the multiple concurrent operations, conformance monitoring was provided via the USS throughout the entirety of each flight, information flows and data exchanges between various UTM system components were tested and evaluated, and data were gathered to support C&N guidance to industry particularly in the altitude stratified BVLOS flights that were performed.NASA researchers also accompanied the flight crews to observe and evaluate human factors issues related to human-systems interactions and display interfaces to inform future guidelines and recommendations.
C. Data CollectionData collected during the UTM TCL 2 National Campaign were analyzed to produce a variety of measures of performance (MOPs) that characterized how the overall UTM system behaved in the test environment.The forms of data collection are described in the following subsections.
Human Factors Data CollectionDuring the National Campaign, human factors researchers were deployed to each of the six Test Sites for data collection and observation purposes.One observer was sent to each of the Test Sites for the duration of the shakedown testing while two were deployed to each of the Test Sites for the final, comprehensive flight test events.Prior to deployment, the necessary tools and apparatus were scoped and prepared, appropriate training was conducted, and input items were designed in order to ensure that there was standardization in data collection methods across all Test Sites.During operations, team members at the Test Sites observed operators, recorded American Institute of Aeronautics and Astronautics actions, took notes on pertinent situations, administered questionnaires, and conducted debrief discussions with operators.A remote human factors team was also situated at NASA Ames observing operations on remote displays, recording data on system interactions for follow up, and supporting the deployed team.
Digital Data CollectionDuring test activities UAS operators utilizing the NASA USS submitted various digital UAS flight data directly to NASA via the NASA USS prototype.Such data flows among UAS operators and USS operators are a key element of the overall UTM ConOps.Similarly, non-NASA USS operators submitted various digital UAS flight data and USS operation data directly to NASA via the NASA FIMS prototype which mimics a typical USS-to-FIMS data flow as envisioned in the UTM ConOps.Additionally, in a minor departure from the data flows envisioned in the UTM ConOps, the non-NASA USSs relayed UAS operator data to NASA through a NASA data analytics aggregator and provider referred to as the "Dapper".The Dapper's role in the URP was to facilitate data flows from the non-NASA USSs to NASA that would not otherwise be present in a typical USS-to-FIMS dataflow in the UTM ConOps; it was an artifact of NASA's flight test research efforts and therefore might not exist in future operational UTM systems.In addition to the digital data flows among the UAS Operators, non-NASA USS Operators, and NASA via the NASA USS, FIMS, and Dapper, the UAS Operators collected specific digital flight data, processed them into digital files per a format specified by a NASA data management plan, and sent them to NASA after the completion of the test activities.
UAS Operator Self-Reported Experiential DataUAS operators at the Test Sites provided contextual information about off-nominal situations that they encountered during testing through a website-based form provided by NASA.This form was derived from basic concepts implemented in the Aviation Safety Reporting System (ASRS). 5
D. Data ProcessingOver the timeframe of the TCL 2 National Campaign, a total of 1,762 operation plans were submitted in real-time through the digital data flows (described above) between the USSs, FIMS, and Dapper.This total set of operation plan submissions included ground tests, simulated operations, shakedown or "practice" operations, and submissions from USS users that were not directly involved in flight test activities in addition to operation plans directly associated with actual aircraft flight test activities.Therefore, it was necessary to downselect the number of operations that would receive further processing and be included in the calculations of the MOPs.Overall, five levels of data processing were applied to the overall dataset.The subsets of operations corresponding to each level of processing are described in the next subsection.
E. Data SubsetsAs mentioned above, the data were categorized into subsets that received different levels of processing.These data subsets are described below and used throughout this section to identify which set was used when calculating the statistics presented in this section.
The Full DatasetThe Full Dataset includes all 1,762 operation plans submitted to the USSs connected to the FIMs over the timeframe of the TCL 2 National Campaign plus six non-cooperative or intruder flights (i.e., flights intentionally flown without UTM submitted operations plans) included in the data the Test Sites provided to NASA per the data management plan.
The User-Filtered DatasetThe User-Filtered Dataset is a subset of the Full Dataset that excludes the six intruder flights and the operation plans submitted from USS users that were not directly involved in flight test activities.The total number of operation plans in this data subset is 1,488.American Institute of Aeronautics and Astronautics
The Manually Processed DatasetThe Manually Processed Dataset is a subset of the User-Filtered Dataset that excludes operation plans that submitted invalid aircraft identification data, operations that did not submit position reports, and operations that submitted position reports at locations other than the Test Sites.Operations excluded from the Manually Processed Dataset set due to a lack of position reports include operations that were rejected or aborted before activation as well as operations where an aircraft flew but were unable to submit a position report due to navigation or communication issues.Each operation from this subset was manually validated and categorized (by data quality and operation type) by examining submission inputs from the USS user, visualizations of the position data, information in the final test reports submitted to NASA by the Test Sites, and notes from the human factors researchers deployed to the Test Sites.The total number of operation plans in this data subset is 611.
The Data Management Plan (DMP) DatasetThis dataset includes operations with detailed vehicle data that the Test Sites processed and submitted to NASA in the form of data files that met the DMP specification.The DMP Dataset includes 135 operations (including the six intruder flights) and was run through automated validation checks and ingested into a common database with the data submitted directly to the FIMS and Dapper.All of the 129 non-intruder operations in this dataset are in the User-Filtered Dataset.
The Filtered DMP DatasetThe Filtered DMP Dataset includes the six intruder flights and the intersection of operations from the Manually Processed Dataset and the DMP Dataset.The total number of operations in this data subset is 133 including the six intruder flights.Because the Test Sites provided detailed data for these operations and they were manually processed, the operations in this data subset are currently considered to be the best suited for further study.Of these 133 operations, 127 were classified as actual aircraft flights with acceptable data quality.
VI. ResultsUTM TCL 2 National Campaign data collection and analysis were focused on producing an array of measures of performance (MOP) that characterize how the overall UTM system behaved as implemented in the overall test environment.Some of these measures-such as number of submitted operation plans; number of accepted operation plans; number of rejected operation plans; number of rogue operations; number of nonconformance operations; time and distance flown with UTM System; number of off-nominal operational-situation contextual reports; and time spent in activated, nonconforming, and rogue states-primarily provide meta-data about the test campaign that can be used to compare it to forthcoming test campaigns.
A. Number of Submitted Operation PlansThe Number of Submitted Operation Plans MOP provides a partial indication of the scale of the testing conducted throughout the TCL 2 National Campaign (both in terms of the number of operations planned and executed and the loading on system-level UTM components such as the FIMS).As mentioned above, 1,762 operation plans were submitted to the USSs connected to the FIMS over the 26-day time frame of the TCL 2 National Campaign.However, the Full Dataset of submissions included submissions from USS users that were not directly involved in flight test activities, and therefore the 1,762 operation plan figure is only a useful indicator of loading of systemlevel UTM components.Alternatively, the User-Filtered Dataset indicates that 1,488 operations were submitted by users participating directly in the TCL 2 National Campaign, and the Manually Processed Dataset provides a more accurate indication of the number of operations that were executed with some degree of success as an actual flight, simulated flight, or ground test.Figure 4 depicts the number of operation plans (per vehicle type) from the Manually Processed Dataset that were submitted by each test site.American Institute of Aeronautics and Astronautics
B. Number of Rejected Operation PlansThe Number of Rejected Operation Plans MOP provides a partial indication of the effectiveness of operation planning by the test participants.With few exceptions (e.g., cases where participants may have intentionally submitted a plan that would not be accepted) test participants tried to avoid submitting operation plans that would be rejected by their USS (due to a conflict with an existing operation plan, for example).Thus, this measure can be examined from test to test to track changes in the effectiveness of operation planning.Also, looking forward to operational UTM systems, it is envisioned that this or a similar measure could be tracked over time by USSs to identify evolving issues with their systems, their users' systems, or their operating environment.Position reports cannot be submitted for an operation plan that gets rejected and therefore all rejected operation plans were excluded from the Manually Processed Dataset.However, a database query for operation rejection messages sent to the operations in the User-Filtered Dataset identified a total of 68 operations that were rejected.That total represents 4.6% of the User Filtered Dataset, but it is currently unknown whether these rejected operations were failed attempts to submit plans for the operations that were ultimately accepted and executed (i.e., the operations in the Manually Processed Dataset).Until further analysis can be conducted to show that the rejected operations were linked to the 611 accepted operations in the Manually Processed Dataset it can be said that up to 10.0% of the attempted submissions for the operations in the Manually Processed Dataset were initially rejected.
C. Number of Accepted Operation PlansThe Number of Accepted Operations Plans MOP (much like the Number of Submitted Operation Plans MOP) provides a partial indication of the scale of the testing conducted.Additionally, it provides partial indication of the effectiveness of operation planning by the test participants.By subtracting the number of rejected operations from the User-Filtered Dataset, it can be said that up to 1,420 operation plans (i.e., 95.4% of the User-Filtered Dataset) from USS users involved in the testing at the Test Sites were accepted by the USS to which they were submitted (although a portion of those operations were not ultimately executed as an actual aircraft flight, simulated aircraft flight, or ground test).American Institute of Aeronautics and Astronautics
D. Time and Distance Flown with UTM SystemThe Time and Distance Flown with UTM System MOP provides partial indications of the overall scale of the testing conducted and the UAS operator preferred mission scale for each vehicle type and can be examined from test to test to track changes in these attributes.Moreover, looking forward to operational UTM systems, it is envisioned that this or a similar measure could be applied to operating fleets, aircraft models, operating environments, or even individual operators to characterize the distribution of the scale of their preferred UTM applications.For example, a USS that operates in a region could report this MOP to aircraft manufacturers in the region so that they could understand the scale of their local customers' use cases and focus on selling or producing aircraft suited for those mission scales.Figures 5 and6 illustrate the distribution for each vehicle type of the flight times and twodimensional flight distances, respectively of the 244 operation plans from the Manually Processed Dataset that were classified as actual flights with acceptable data quality.With sufficient quantities of data, illustrations such as these could be used to characterize the distributions of operation durations and distances flown in various operational contexts.
E. Number of Nonconformance OperationsThe Number of Nonconformance Operations MOP provides partial indications of 1) the ability of UTM users to effectively plan UTM operations and 2) aircraft ability to conform to those plans.A nonconformance event is an instance in which a UAS fails to comply with its approved and activated UTM operation plan.Types of nonconformance events include lateral and vertical violations (i.e., violations of lateral or vertical boundaries of the plan's conformance geographies), temporal violations (use of an approved volume, but at an unapproved time), and informational violations (failure to provide routine position reports).During most operations, the UAS operators put significant effort towards avoiding nonconformance events (except for a few cases where an operation objective called for intentional nonconformance events) because such events often conflicted with the objectives of the operations.Thus, this measure can be examined from test to test to help track changes in the effectiveness of operation planning and vehicle performance (provided that the desire to avoid nonconformance events does not change significantly from test to test).Moreover, looking forward to operational UTM systems, it is envisioned that this or a similar measure could be applied to operating fleets, aircraft models, operating environments, or even individual operators to monitor the burden that they place on the UTM system (because nonconformance events may require manual interventions by the aircraft operators, neighboring operations, and USS operators).During the TCL 2 National Campaign, the methods for monitoring nonconformance varied from USS to USS.Two of the USSs (including the NASA USS) utilized similar state machine logic that included "Nonconforming" and "Rogue" states to monitor and react to nonconformance events.These two USSs handled 100% of the UTM operations at four of the six test sites and were, therefore, the focus of calculation for this MOP (calculating nonconformance events for operations submitted to the other USSs will be performed in future work.)Database queries for the messages that the two USSs mentioned above sent to nonconforming and rogue operations in the User-Filtered Dataset identified a total of 309 operations submitted to these 2 USSs that had a nonconformance event.Among these operations, 253 are included in the Manually Processed Dataset and 92 of those were classified as actual aircraft flights with acceptable data quality.American Institute of Aeronautics and Astronautics
F. Number of Rogue OperationsThe Number of Rogue Operations MOP (much like the Number of Nonconformance Operations MOP) provides partial indications of: 1) the ability of UTM users to effectively plan UTM operations and 2) aircraft ability to conform to those plans.Rogue operations are a subset of operations that experience a nonconformance state.A nonconformance event leading to an operation being classified as a rogue operation is a more serious event (i.e., it triggers more substantial system responses) than one that simply leads to an operation being temporarily classified as nonconforming.Thus, additional effort is put into avoiding nonconformance events leading to a rogue classification (except in test cases where a rogue nonconformance event serves a test objective).Using an approach similar to the one used to calculate the number of nonconformance events, it was determined that there were 226 operations that reached the rogue state in the User Filtered Dataset.Among these operations, 183 are included in the Manually Processed Dataset and 59 of those were classified as actual flights with acceptable data quality.
G. Time Spent in the Activated, Nonconforming, and Rogue StatesThe Time Spent in the Activated, Nonconforming, and Rogue States MOP is a variation of the Number of Nonconformance Operations MOP that provides partial indications of: 1) the ability of UTM users to effectively plan UTM operations and 2) the vehicle's ability to conform to those plans.Consequently, it too is a potential measure for tracking user and vehicle abilities in future UTM tests and operational UTM systems.This MOP is calculated through querying the same state transition messages that are queried for the Number of Nonconformance Events and Number of Rogue Operations MOPs in order to determine the relative amount of time UTM operations spend in the activated, nonconforming, and rogue states.These states coincide with the in-flight portion of the operations whereas the accepted and closed states coincide with the pre-flight and post-flight portions of the operations, respectively.Figure 7 shows (by vehicle type) the average percentage of time that operations in the Filtered DMP Dataset spent in each state.
H. Number of Off-Nominal Operational-Situation Contextual ReportsThe Number of Off-Nominal Operational-Situation Contextual Reports MOP provides an indication of the number of off-nominal events that the test participants felt were worthy of documenting.The number of such reports submitted to NASA was driven not only by the number of off-nominal events that occurred, but also by the test participant awareness of the significance of the situations when they occurred and whether the test participants knew how to report them.As such, this measure can be used from test to test to help track changes in the frequency of reportable off-nominal events and test participant awareness of such events and how to report them.During the TCL 2 National Campaign, 15 Off-Nominal Operational-Situation Contextual Reports were correctly submitted to NASA from test participants.
I. Human FactorsHuman factors data were collected by researchers at each test site through observation, surveys, and debrief discussions.Through that effort it was found that while flight crew participants were highly qualified and experienced, their awareness and understanding of UTM was sometimes limited due to the fact that they were often not involved in USS development or in test-plan/scenario design.This lack of involvement affected the way that flight crews interacted with UTM.In line with previous observations, the need for situation awareness was apparent to the participants.Information to provide that awareness was obtained from a variety of displays and interfaces.Display design and usability influenced what information operators looked at or listened to, which affected how well the operational situation was understood.Over the course of the flight tests, participants increasingly understood the need to be aware of other vehicles.However, the information that some participants felt they needed about other operations did not always match the information they were willing to share about their own; though most participants agreed that contributing to the overall situation awareness of others was valuable.With regards to response time to a UTM notification, observers noted that it depended heavily on a team's structure, communication efficiency, and procedures.A more comprehensive report of the human factors data collection effort and the results will be provided in a forthcoming publication.
J. Test Site and Partner RecommendationsAs part of the effort to validate UTM concepts exercised during this campaign, the Test Sites and their partners were asked to give recommendations on four elements of the testing.The following are some of their suggestions.First, for USS-to-USS Communication, there was agreement that such communication is needed to deconflict flight plans.Also, there is a need for a USS Discovery service that can allow operators to discover USS's as well as USS's to discover each other and subscribe to each other's operations information.Second, for UAS Operator Workload, the expectation that a pilot would manually message during an emergency procedure is not feasible because the pilot workload would be too high.Third, for Usage of Operational Areas, it was suggested that multiple UAS should be allowed to launch/operate/recover in the same airspace.Also, for priority missions, the UTM system should have an understanding of restricted/special use areas (constraint exceptions).Fourth, for User Interface, improving situational awareness is important.For example, displaying neighboring UTM operations would be very useful in planning phases.In fact, it would be useful for a UTM client to allow queries and visualization of any associated operation volumes, constraints, or other UTM aircraft in the event of alerts or negative UTM responses.Adding additional information into the geospatial display, such as weather and regulatory information, is also useful.Some of these suggestions have led to additions and improvements to NASA's URP that will be tested in the future set of flight tests for the third technical capability level (TCL 3).
VII. SummaryThe UTM effort at NASA aims to enable access to low-altitude airspace for small UAS.This goal is being pursued partly through partnerships that NASA has formed.The flight tests described in the paper made use of an architecture that was developed by NASA in partnership with the FAA to safely coordinate such operations.The coordinated efforts of the NASA UTM group, the FAA UAS Test Sites, and industry partners during the UTM TCL 2 National Campaign produced 1,488 flight operation submissions to a total of six unique UTM USS implementations over a total of six geographically diverse test sites.Also, a portion of these flights were observed by ground surveillance systems and airborne surveillance systems whose observations were integrated into UTM.These accomplishments served as an initial validation of the potential flexibility and scalability of the UTM concept and architecture.Additionally, measures of performance were defined and calculated from the flight data to establish American Institute of Aeronautics and Astronautics quantitative bases for comparing flight test activities and to introduce potential metrics that might be routinely monitored in future operational UTM systems.Moreover, multiple organizations (including NASA) made tangible progress on the development and refinement of their implementations of software, hardware, and processes for operating sUAS in accordance with the UTM ConOps.Finally, the recommendations from the Test Sites and their partners during the UTM TCL 2 National Campaign will shape key aspects of flight tests for TCL 3 and beyond and factor into continued discussions between NASA, the FAA, industry, and academia on the technologies and concepts needed to safely, efficiently, and fairly manage sUAS traffic in the low-altitude airspace.
VIII. Future WorkAs of this writing, joint NASA-FAA-industry-academia teams are examining the data collected during the UTM TCL 2 National Campaign and preparations are underway for the flight testing of UTM TCL 3 in 2018.The MOPs presented in this paper will be calculated with TCL 3 data and compared with the measures calculated with TCL 2 Campaign data.Additionally, other MOPs of interest such as the effectiveness of flight planning, scheduling and planning, airspace conformance monitoring, conflict alert, pilot reporting, non-cooperative intruder deconfliction, and ground surveillance will be investigated.Moreover, future work may include more detailed analysis of specific operations in the TCL 2 National Campaign data subsets.For instance, further analysis may be applied to data from operation plans that were previously excluded from the Manually Processed Dataset (particularly, those that were identified as rejected or rogue).As mentioned above, operations without submitted position reports were excluded from detailed analysis, but the reasons that they lack position reports are varied and potentially interesting in terms of operations planning, vehicle communications, data management, and flight procedure execution.Figure 1 .1Figure 1.UTM ArchitectureFor the TCL 2 National Campaign, the Test Site facilities and their partners could either connect to the NASA USS research prototype or develop their own USS to connect to the FIMS research prototype and develop custom clients to connect UAS operators to their USS.The FIMS research prototype was developed by NASA and was available to the Test Site facilities.
Each of the six Test Sites was located in a different location, providing a diversity of environments in which to operate and a realistic backdrop for the use cases that each site developed.With the addition of partnerships that the Test Sites established in accordance with the testing objectives, a variety of flight scenarios were flown during the National Campaign testing window that tested different aspects of the UTM architecture and addressed a number of research areas relevant to the RTTs established by the FAA, NASA, and industry.Figure2presents displays of live operations as they occurred at each of the Test Sites.
Figure 2 .2Figure 2. Sample Test Site scenarios (top left to right: Alaska, Nevada, New York; bottom left to right: North Dakota, Texas, Virginia).
Figure 3 .3Figure 3. Example of multi-mission flight scenario that incorporated multiple use cases and addressed multiple test objectives.
Figure 4 .4Figure 4. Number of operation plans from the Manually Processed Dataset submitted by each test site.
Figure 5 .5Figure 5. Distribution of flight times of operation plans from the Manually Processed Dataset classified as actual flights with acceptable data quality.
Figure 6 .6Figure 6.Distribution of two-dimensional flight distances of operation plans from the Manually Processed Dataset classified as actual flights with acceptable data quality.
Figure 7 .7Figure 7. Average percentage of time (by vehicle type) that operations in the Filtered DMP Dataset spent in the activated, nonconforming, and rogue states.
American Institute of Aeronautics and AstronauticsNomenclatureANSP =Air Navigation Service ProviderATM=Air Traffic ManagementBVLOS =Beyond Visual Line of SightCOA=Certificate of AuthorizationConOps =Concept of OperationsC&N=Communication and NavigationDapper =Data aggregation and analysis providerFIMS =Flight Information Management SystemiOS=Apple Inc. mobile operating systemMOP =Measure of PerformanceNAS=National Airspace SystemRTB=Return to BaseRTT=Research Transition TeamSAA=Sense and AvoidsUAS =Small Unmanned Aircraft SystemTCL=Technical Capability LevelUA=Unmanned AircraftUAS=Unmanned Aircraft SystemURP=UTM Research PlatformUSS=UAS Service SuppliersUTM =UAS Traffic Management
Table 1 . Test Site Locations Test Site Range Location Comments1AKFour locations: the first three areThe test area is sub-arctic with scrub and trees. UAF location is anlocated at the Poker Flat Researchurban area.Range, and the fourth at the AlaskaFairbanks (UAF) campus.ND11 miles south of Grand Forks, NDFarmland with an above-ground powerline.and 1.5 miles east of Thompson, NDNVReno-Stead AirportMuch of the range was used for the TCL 2 Demonstration in October2016. The range was extended north to accommodate flights up toseveral miles from the GCSs.NYGriffiss International AirportLies within Griffiss Class D airspace. Includes an area of about 220acres where airborne UAS can gather to avoid manned traffic.TXLaguna Test Range in PortCoastal range including Charles R. Johnson Airfield. Flights wereMansfield, TXconducted over both ground and water (i.e., the Gulf of Mexico).VAKentland Farm AgriculturalOwned by Virginia Tech. 1,800 acres in size, bordered on the SouthResearch Center (Blacksburg, VA)and West by the New River. Includes an asphalt airstrip.
III. High-Level Purpose of TCL 2 National CampaignNASA contracted with six FAA UAS Test Sites to demonstrate, evaluate, and refine the functional designs,technology prototypes, and UTM ConOps developed under the UTM Project.A. MotivationThe goals motivating the TCL 2 National Campaign were as follows:1. Flight test TCL 2 scenarios across a wide range of operating environments.2. Flight test TCL 2 scenarios utilizing the FIMS-USS architecture for UTM.3. Flight test TCL 2 scenarios with a wide range of UAS platforms.4. Build upon the results of the NASA-FAA Research Transition Team (RTT) Data Exchange andInformation Architecture Working Group Demonstration (which occurred in November, 2016) and validatefurther the scalability of the UTM concept and architecture.B. Research Areas of InterestNASA requested that each Test Site focus on one or more of the following areas: 1. UAS Service Suppliertechnologies and procedures; 2. Geofencing technologies/conformance monitoring; 3. Ground-basedsurveillance/sense and avoid; 4. Airborne sense and avoid; 5. Communication, navigation, surveillance; and 6.Human factors related to UTM data creation and display. These research areas are related to technologies that enableTCL 2 UTM capabilities. The research areas that each Test Sites chose to focus on are listed in Table 2 andcollectively provided full coverage of the areas requested by NASA.
Table 2 . Test Site Research Areas Test Sites USS Technology Geofence Technology Ground- based Sense & Avoid2Airborne SenseCommunication,Human& AvoidNavigation,FactorsSurveillance
Table 3 . Aircraft and USSs participating in National Campaign Test Site Vehicle Type Operator USS3AK1 single rotor helicopter, 3 quadcopter, 2ACUASISimulyzeoctocopterND1 hybrid delta-wing, 4 fixed wing, 2Botlink, Isight RPV Services, SkySkopes,Simulyzehexacopter, 1 simulatedUniversity of North Dakota, UnmannedApplications Institute International (UAI)NV4 fixed wing, 2 quadcopters, 1Amazon, Carbon Autonomous, DroneAirMap,hexacopter, 1 octocopterAmerica, AmazonAmazonNY1 quadcopter, 1 hexacopter, 1NUAIRNASAoctocopter, 1 fixed wing hybridTX2 quadcopter, 2 fixed wingLSUASCNASAVA1 fixed wing, 2 quadcopterGoogle (Project Wing), Intel, VirginiaTech
		
		

			
AcknowledgmentsThomas Prevot (formerly of the NASA Ames Research Center) managed the NASA UTM project throughout the TCL 2 National Campaign and was instrumental in the planning and execution of the campaign.Additionally, the authors would like to thank to the following individuals at NASA for their contributions to the UTM TCL 2 National Campaign: Abby Tabor, Abraham Ishihara, Ashley Gomez, Bassam Musaffar, Charlene Cayabyab, Charles Drew, Christine Clark, Conrad Gabriel, Cynthia Wolter, Daniel Mulfinger, David R. Smith, Darryl Waller, Edgar Torres, Faisal Omar, Frank Aguilera, George Lawton, Gwendolyn Wahl, Hemil Modi, Irene Smith, J. D. Harrington, Jaewoo Jung, Joseph Mercer, Joseph Silva, Kenji Kato, Leo Wang, Louis Glaab, Lynne Martin, Madhavi Balijepalle, Marcus Johnson, Minh Do, Nancy Bienert, Parimal Kopardekar, Patrick McGuirk, Priya Venkatesan, Punam Verma, Quang Dao, Ronald Johnson, Rosalia Toberman, Sreeja Nag,Vijay Baskaran, Vimmy Gujral, and William Moede.Thanks are also extended to the many dedicated individuals at the FAA UAS Test Sites and the organizations who partnered with them.Funding for this work was provided by the Safe Autonomous System Operations Project of the NASA Aeronautics Research Mission Directorate's Airspace Operations and Safety Program.
			

			

				


	
		FAA/NWS aviation route forecast /ARF/ development
		
			TMitchell
		
		10.2514/6.1982-13
		US DOT FAA TC17-0002
	
	
		20th Aerospace Sciences Meeting
		
			American Institute of Aeronautics and Astronautics
			2017 to 2037. 2017
		
	
	Federal Aviation Administration (FAA), FAA Aerospace Forecast: Fiscal Years 2017 to 2037, US DOT FAA TC17-0002, 2017.



	
		Unmanned Aircraft System Traffic Management (UTM) Concept of Operations
		
			PKopardekar
		
		
			JRios
		
		
			TPrevot
		
		
			MJohnson
		
		
			JJung
		
		
			JERobinson
		
	
	
		AIAA Aviation Technology, Integration, and Operations Conference
		Washington, DC
		
			AIAA
			June 2016
			
		
	
	Kopardekar, P., Rios, J., Prevot, T., Johnson, M., Jung, J., and Robinson, J. E., "Unmanned Aircraft System Traffic Management (UTM) Concept of Operations," AIAA Aviation Technology, Integration, and Operations Conference, AIAA, Washington, DC, 13-17 June 2016.



	
		Flight Test Evaluation of an Unmanned Aircraft Systems Traffic Management Concept for Multiple Beyond Visual Line of Sight Operations
		
			MJohnson
		
		
			JJung
		
		
			JRios
		
		
			JMercer
		
		
			JHomola
		
		
			TPrevot
		
		
			DMulfinger
		
		
			PKopardekar
		
	
	
		12 th ATM R&D Seminar
		Seattle, WA
		
			June 2017
			
		
	
	Johnson, M., Jung, J., Rios, J., Mercer, J., Homola, J., Prevot, T., Mulfinger, D., and Kopardekar, P., "Flight Test Evaluation of an Unmanned Aircraft Systems Traffic Management Concept for Multiple Beyond Visual Line of Sight Operations," 12 th ATM R&D Seminar, Seattle, WA, 26-30 June 2017.



	
		NASA UAS traffic management national campaign: Operations across Six UAS Test Sites
		
			JosephRios
		
		
			DanielMulfinger
		
		
			JeffHomola
		
		
			PriyaVenkatesan
		
		10.1109/dasc.2016.7778080
	
	
		2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)
		Sacramento, CA
		
			IEEE
			29 Sep. 2016. 2001
			60
			25
		
	
	IEEE
	Rios, J., Mulfinger, D., Homola, J., and Venkatesan, P., "NASA UAS Traffic Management National Campaign," 35 th Digital Systems Avionics Systems Conference (DASC), IEEE, Sacramento, CA, 25-29 Sep. 2016. 5 National Aeronautics and Space Administration (NASA), "ASRS: The Case for Confidential Incident Reporting Systems," NASA ASRS Pub. 60, 2001.


				
			
		
	
