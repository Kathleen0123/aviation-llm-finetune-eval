
	
	
		
IntroductionThe management of arrival traffic has become one of the most challenging problems in the nation's air traffic control (ATC) system.Increased traffic demand and limited airspace and runway capacity have made delays and congestion common occurrences.In addition, controllers have a limited set of tools to assist them in performing various control tasks and for coping with increases in traffic demand (Davis, Erzberger, & Bergeron, 1989).NASA-Ames Research Center, in partnership with the Federal Aviation Administration, is developing the Center TRACON Automation System (CTAS), a set of automation tools designed to assist in the safe and efficient sequencing and scheduling of arrival traffic.The process for incorporating advanced technologies into complex aviation systems is as important as the final product itself.This paper describes the development and assessment process that has been applied to the development of CTAS.A brief overview of CTAS is provided, followed by a high-level description of the development and assessment process.Examples are provided of the type of issues that are addressed and data collection methods that are used during the course of development of the CTAS tools.
CTASCTAS is an integrated set of automation tools designed to provide decision-making assistance to both Terminal Radar Control (TRACON) and Air Route Traffic Control Center (Center) controllers via planning functions and clearance advisories.CTAS consists of three sets of tools: the Traffic Management Advisor (TMA) which provides optimized sequences and schedules for arrival traffic, the Descent Advisor (DA) which provides optimized descent profile advisories to meet the TMA schedules, and the Final Approach Spacing Tool (FAST) which provides advisories to TRACON controllers for efficient sequencing and handling of traffic within the TRACON airspace.
Development and Assessment ProcessCTAS research and development is accomplished in the Advanced Automation Laboratory at NASA Ames.One key aspect of the laboratory development and assessment process is the participation of both retired controllers as well as a system development team, comprised of current controllers from around the country.Simulations with controllers help to provide a meaningful set of baseline functions prior to releasing the software to the ATC field sites.Prior to release, CTAS functionality is also tested at the FAA Technical Center.A second key aspect of the development process is early field assessments at operational ATC facilities.TMA is currently installed for development and assessment at the Denver Center and TRACON, the Denver International Airport Air Traffic Control Tower, Ft.Worth Center, and Dallas / Ft.Worth TRACON.FAST is installed in the Electronic Target Generation (ETG) training room at Dallas/Ft.Worth TRACON, and aspects of DA have been tested in an operational environment at the Denver Center during limited assessments.Early field testing for CTAS has been deemed necessary by the FAA for streamlining development and bringing system functions to a level of stability and usefulness.Early field testing provides the opportunity to understand the implications for system design in an operational context; that is, the interdependencies between the physical environment, operational task domain, and work activities (Harwood & Sanford, 1994;Harwood, 1993).The richness and complexity of these context-dependent factors and the relationships between them are not accessible through design guidelines or standards.If field testing is delayed until late stages of development, solutions to design problems are likely to be technology driven with development and evaluation relying on context-free guidelines for human-computer interaction.The CTAS development and assessment process is geared for system refinement and to enhance our understanding of the potential impact of CTAS on traffic management problem-solving, inter-facility coordination, and traffic handling.CTAS assessments take a principle-driven approach, drawing on principles and methods from human factors engineering, cognitive engineering, and usability engineering.CTAS assessments occur in a progressive fashion, beginning with human-computer interface assessments in the laboratory, followed by usability and suitability assessments in the field (Sanford et al., 1993).Usability assessments verify that TMCs and controllers are not impeded by the technology from accessing the data they need for making various ATC decisions.Examples of usability issues include color discrimination, screen layout, the ease with which data can be extracted, and the understanding of labels and abbreviations.Suitability assessments focus on the match between the design and the users' task.A system is suitable to the extent that the design features and functions support the users' decision-making, planning, and problem-solving activities.Suitability assessments address information content and representations, decision-aiding algorithms and functions.Both usability and suitability assessments focus on specific aspects of the users' experience with CTAS in the operational work context.A variety of different methods are used during development and assessment, and the overall process is tailored for the uniqueness of each of the CTAS tools.The methods and approaches that have been applied to TMA, DA, and FAST are discussed below.Data from studies conducted in simulations and field assessments illustrate how the different processes can help reveal system constraints, enhance our understanding of the user's needs, and provide insight into the impact of new technology on existing operational practices.
TMAOverview TMA provides optimized schedules and sequences for managing arrival traffic.An interactive graphical humancomputer interface provides graphical representations of the traffic flow and allows Traffic Management Coordinators (TMCs) to manipulate the traffic schedules and sequences.Some data collection and recording tasks are also automated by TMA.TMA is designed for use by TMCs within Center and TRACON facilities.Traffic managers do not control aircraft directly.Instead they manage the flow of traffic by monitoring the demand of arrival traffic into the Center and TRACON areas.TMCs coordinate with TRACON, Center and Tower personnel to make decisions about balancing the traffic demand so that capacity in the Center and TRACON areas is not exceeded.Information about the arrival traffic flow is used by TMCs when making three key traffic management decisions: 1) managing the spacing of the arrival flow to avoid exceeding airspace and airport capacity; 2) distributing the load from one area to another; 3) assigning departure times for aircraft departing airports within the Center's airspace.Currently, in the field, information about the traffic situation is accessed from several sources, such as a plan view display, an arrival sequencing tool, aircraft situation displays, weather displays, operational personnel and flight strips.Frequently, there are variations within what are considered typical traffic flows: the location of one heavy aircraft can substantially modify the scheduled flow of traffic, as can poor weather, equipment outages and emergencies.Given the extent of coordination required within and between facilities, the variety of sources of information accessed, and the dynamic and often variable state of the traffic flow, it is important to examine the context in which a traffic management tool like TMA will be used.Early field testing is crucial to ensure the operational utility of TMA and its effective integration into the Traffic Management Unit (TMU).TMA development and assessment has relied more heavily upon field exposure than the other CTAS tools.While traditional system development and acquisition processes delay field testing until later stages of production, early field exposure of traffic management automation is imperative due to the complexities of the operational environment.Field exposure is also important because traffic management activities are not easily simulated.First, the dynamic nature of traffic management makes it difficult to foresee and simulate the variety of traffic situations which arise in the operational environment.Second, it is difficult to adequately simulate the coordination activities that comprise a large part of the TMCÃ•s responsibilities.Simulations are used to address specific development issues such as scheduling algorithm accuracy or isolated human-computer interface features.However, they cannot provide a realistic context in which to fully assess a traffic management automation tool.For this reason, progressive field assessments are integral to the TMA development process.
Methods and ApproachesInitial TMA field tests focus on usability issues.Since issues such as color discrimination, text readability and display contrast effects are affected by operational viewing distance, workplace illumination, and workplace layout, it is important to assess the tool in the environment for which it is designed.Scenario driven surveys are used to formally assess these issues.Here, TMCs rate usability assessments in the context of a prerecorded traffic scenario.The survey is completed in the traffic management unit.Usability issues are further addressed during more operationally oriented assessments where TMCs actually use TMA to make decisions.Usability tests have been performed at the various development sites, since environmental conditions vary between facilities.Subsequent field tests have focused on assessing the operational suitability of TMA.Emphasis is placed on assessing how well the system supports operational decision making.These assessments also enable discoveries of unexpected uses of the TMA features, as well as assessing issues of interface usability and user acceptance.Shadowing (Harwood and Sanford, 1993) and contextualized interviews (Whiteside, Bennet & Holtzblatt, 1988) are used to assess the suitability of TMA for decision-making and problem solving.Shadowing provides an effective means for discovering unexpected uses of TMA features and for assessing issues of interface usability, operational suitability, and user acceptance.Shadowing involves a TMC using TMA to make traffic management decisions, mirroring the activities at the operational traffic management position.The shadowing TMC has access to all other sources of information in the Traffic Management Unit except for the operational traffic management system.One observer observes and queries the shadowing TMC, and the TMC's ongoing commentary is tape recorded for later analysis.Another observer watches the operational TMC.Here, traffic management activities and decisions are observed in a more passive mode to avoid disrupting operations.Debriefing interviews are conducted immediately following the shadowing session to confirm researcher observations made during the session and to further investigate interface usability and operational suitability issues that may have arisen during the session.The focus of the TMA development and assessment process has been on identifying design deficiencies, discovering unexpected feature uses, understanding how the tool is used for various activities, and defining operational requirements.Analyses have been tailored accordingly.Comparing decision making data collected at the operational and shadowed TMA positions provides a method for determining whether TMA can be used to support decision making tasks within operational time constraints.Additionally, the contextualized interview conducted during shadowing exercises provides information about how individual features are used to support decision-making activities.These issues are further assessed through subjective ratings of feature usefulness and during debriefing interviews.
BenefitsContent analyses of observations and interviews, coupled with subjective ratings, provide insight into design deficiencies and discrepancies and enhance our understanding of TMA.System requirements evolve from these insights.For example, information collected through field assessments allowed the identification of two tasks that are candidates for full automation: manual traffic counts and delay recording.A prototype version of TMA containing these automated features has been assessed by TMCs.In the case of these features, assessments focused on the possibility that situational awareness might be reduced.Results indicate that the automation of these counting tasks did not reduce situational awareness.Progressive assessments provide useful information about the introduction of automation into complex operational environments.
DA
OverviewDA is designed to assist Center controllers in sequencing and spacing arrival aircraft for delivery over the meter fixes at specified times.DA clearance advisories are based on highly accurate, fuel efficient trajectory predictions.Cruise speed, turn, and descent profile with top of descent advisories are displayed to controllers to help them meet the optimized schedule produced by TMA.It also provides conflict prediction and resolution for aircraft in all phases of flight (Green, den Braven & Williams, 1993).DA development is unique, as it is the only CTAS tool that requires changes in ATC procedures and phraseology.Since DA tests affect pilots in addition to controllers, airline participation in field testing is essential for DA development.The development of new procedures and phraseology iterates through progressive field tests to ensure that both ATC and airline requirements are met.Early field testing of DA is beneficial to this effort because it allows development to be conducted in controlled test conditions, where modifications to procedures and phraseology can be implemented and tested with a minimal amount of disruption.Additionally, it allows controllers to evaluate and provide feedback about DA advisories and interface features based on the performance of these features under operational traffic conditions.DA development is being performed with progressive field tests coupled with simulations.Although both DA and TMA employ a series of progressive field tests, the approaches taken in their development are different.TMA development uses the most complete prototype system available for evaluation in the field by TMCs.In contrast, DA presents a limited subset of features to controllers for evaluation.While DA will provide all of the advisories mentioned above once it is fully developed and implemented, field tests are designed to introduce DA features in an evolutionary manner.An initial test, conducted in September, 1994, provided controllers with top of descent and descent speed advisories.These advisories were provided to controllers without a human-computer interface.An upcoming test will provide these advisories as well as cruise speed and path stretch advisories on an auxiliary controller interface.In later tests, advisories will be provided on the controllerÃ•s existing display and conflict detection and conflict resolution advisories may be introduced.As the previous level of functions are refined and validated, additional functions will be added.The tests will progress from providing advisories to a single aircraft to providing advisories to all aircraft in Center airspace.
Methods and ApproachSimulations are used to assess and validate functions prior to their introduction to controllers during field tests.Center controllers participate in simulations and determine when the system is ready for field evaluation.They also provide input regarding issues that cannot be assessed in the field due to hardware and software constraints.These include the use of color coding in displays and the display of enhanced graphical cues, such as turn arcs and spacing displays.Observations are collected while controllers use DA during field tests.This data provides information about controller strategies for DA feature and advisory use and about interface suitability given operational time constraints and traffic conditions.Although formal contextual interviews are not conducted in an effort to reduce the impact of test procedures on facilities operations, controllers frequently communicate their observations about advisories and traffic situations.These enrich the observational data.Audio recordings of controller / pilot communications are also collected.The observational data complements the audio recordings as well as trajectory recordings by providing contextual information about the corresponding traffic condition.Debriefing interviews are conducted immediately following test sessions.These structured interviews are used to confirm information recorded about the traffic situation and to discuss any unusual traffic events that might have affected test conditions.Information about issues such as the acceptability of the DA features that were used, the suitability of the controller interface, and any problems with procedures or phraseology are addressed.Subjective ratings may also be collected.Additionally, controllers provide input about the desirability and potential of specific DA capabilities being considered for future development.
BenefitsThese data collection methods have been used to elicit information that affects future DA development and the associated procedures and phraseology.For example, controllers have confirmed that the use of pilot discretionary descents, which were issued to flight management system (FMS) equipped aircraft during a preliminary field test to facilitate trajectory validation, are not acceptable under normal operational conditions.While developers did not intend to extend this procedure past the initial test, this input was valuable while working with the airlines to develop procedures for future tests and operations.Controllers provided guidance regarding phraseology development by specifying the need to use more standard phraseology under heavier traffic conditions.Pilots also provided information about these issues (Palmer, Goka, Cashion, Feary, Smith & Graham, 1995).The use of field observations and debriefings will continue to contribute to the development of a DA tool that meets operational requirements and addresses user acceptance, especially when field assessment data is coupled with simulation data.
FAST
OverviewFAST is designed for use by TRACON sector controllers.It generates proposed sequences, schedules, and runway assignments for use within TRACON airspace.It is designed to assist TRACON controllers in efficiently managing and controlling arrival traffic by displaying arrival sequence numbers, runway assignment, and speed and heading advisories.The control of traffic in the TRACON is highly tactical because of the limited amount of TRACON airspace and the number of aircraft that may be contained within it (Davis, Krzeczowski & Bergh, 1994).Controllers have a restricted amount of time to develop strategies for delivering aircraft from the meter fixes to the runways.Likewise, they have limited time to evaluate advisories under operational time constraints.FAST development has not employed the early field testing used in TMA and DA development.Because of the more strategic activities and longer planning horizon involved in Center activities, especially in traffic management, it is possible to perform prototype evaluations under operational conditions.In contrast, FAST development has focused heavily on simulations prior to field exposure.Extensive laboratory simulations have been conducted with TRACON controllers throughout the early stages of the development process.Once the controllers participating in these simulations determined that elements of FAST were ready for presentation to additional facility personnel, FAST was placed in the Electronic Target Generation (ETG) Room at the Dallas/Ft.Worth TRACON.Controllers at the facility will participate in FAST simulations to determine if FAST development has progressed to a level that may be tested on the operational floor.Once this phase of development is complete, FAST will be assessed on the operational floor.
Methods and ApproachSimulations are conducted to elicit controller opinions about the suitability and acceptability of FAST advisories, as well as the usability of the FAST human-computer interface.Controllers participate in simulations using FAST advisories, and evaluate whether the resulting traffic flow benefits the individual controllers and the overall traffic flow.Observations and contextual interviews are used during the simulation to assess the effectiveness of advisories under specific traffic conditions.Additionally, other usability issues such as the ability to extract data and make data inputs are assessed under operationally representative simulation conditions.Debriefing interviews are used to identify controller strategies.Specific operational issues such as aircraft sequencing, runway assignment, aircraft speeds and traffic flow patterns that are used under different airport configurations are addressed.Measures of workload are also collected, and workload issues are discussed.Additionally, a rating of system acceptability called the Controller Acceptance Rating Scale (CARS) is being developed.CARS is a modification of the Cooper-Harper Scale for pilot assessment of the handling qualities of aircraft.CARS is currently being validated at NASA-Ames.When combined, these methods provide an understanding of controller strategies and workload as they apply to FAST development.
BenefitsSimulations provide a controlled setting in which controllers can evaluate the effect of advisories and interface features on controller workload and traffic flow .They also provide an opportunity for controllers and developers to work together to integrate existing controller strategies with FAST runway optimization strategies.Concurrent with the TRACON controller evaluations of FAST, laboratory simulations are also conducted with retired controllers to evaluate issues such as controller workload and the human-computer interface.Results from these simulations demonstrating reduced controller workload with the use of FAST advisories (Lee, Pawlak, Sanford & Slattery, 1995) are incorporated into the development and assessment of FAST.Controllers influence the development process through their feedback based on simulations.For example, they determined that the monochrome display that is used operationally today is not conducive to the introduction of the complete set of FAST advisories (Davis et al., 1994).This issue fed into the decision to provide a subset of FAST advisories (i.e., sequence numbers and runway assignments) during the initial evaluation of FAST in the Dallas/Ft.Worth ETG training room.Early controller involvement has enhanced the development of the FAST automation tool as well as guided an implementation strategy for how FAST will be introduced in the field.		
		
			
SummaryThe CTAS development and assessment process recognizes that ATC activities are not homogenous among different controller groups.The process is thereby tailored for each tool in an effort to specifically address the operational requirements of each controller group.CTAS uses iterative prototyping in combination with simulation and field activities early in the development process.System prototyping and assessment began prior to the specification of requirements thus providing detailed and informed input to the FAA's requirement definition process for CTAS.Lessons learned from the FAA's Advanced Automation System program support the type of process that is being used for CTAS development and assessment (Small, 1994).As described in this paper, simulations with field personnel coupled with field assessments conducted early during development help highlight system constraints, enhance our understanding of the user's needs, and provide insight into the impact of new technology on existing operational practices.When validation of automation rests on reconciling technological possibilities with work needs (Whiteside, Bennet, and Holtzblatt, 1988), the user's experience with the tool in the context of an operational domain assumes a critical role.			
			

				


	
		Design and evaluation of an air traffic control Final Approach Spacing Tool
		
			ThomasJDavis
		
		
			HeinzErzberger
		
		
			StevenMGreen
		
		
			WilliamNedell
		
		10.2514/3.20721
	
	
		Journal of Guidance, Control, and Dynamics
		Journal of Guidance, Control, and Dynamics
		0731-5090
		1533-3884
		
			14
			4
			
			1989
			American Institute of Aeronautics and Astronautics (AIAA)
			Moffett Field, CA
		
	
	Davis, T.J., Erzberger, H, & Bergeron, H.B. (1989). Design of a final approach spacing tool for TRACON air traffic control (NASA Technical Memorandum 102229). Moffett Field, CA: National Aeronautics and Space Administration.



	
		THE FINAL APPROACH SPACING TOOL
		
			TJDavis
		
		
			KJKrzeczowski
		
		
			CBergh
		
		10.1016/b978-0-08-042238-1.50015-x
	
	
		Automatic Control in Aerospace 1994 (Aerospace Control '94)
		
			DBSchaechter
		
		
			KRLorell
		
		Sunnyvale, California
		
			Elsevier
			1994
			
		
	
	Davis, T.J., Krzeczowski, K.J., & Bergh, C. (1994). The final approach spacing tool. In D.B. Schaechter & K.R. Lorell (Eds.), 13th IFAC Symposium on Automatic Control in Aerospace -Aerospace Control Ã”94 , (pp. 70 - 76). Sunnyvale, California: Lockheed Missiles & Space Company, Inc.



	
		Initial field evaluation of pilot procedures for flying CTAS descent clearances
		
			EPalmer
		
		
			TGoka
		
		
			PCashion
		
		
			MFeary
		
		
			NSmith
		
		
			HGraham
		
	
	
		Proceedings of the Eighth International Symposium on Aviation Psychology
		the Eighth International Symposium on Aviation PsychologyColumbus, OH
		
			The Ohio State University Press
			1995
		
	
	To appear in
	Palmer, E., Goka, T., Cashion, P., Feary, M., Smith, N. & Graham, H. (1995). Initial field evaluation of pilot procedures for flying CTAS descent clearances. To appear in Proceedings of the Eighth International Symposium on Aviation Psychology , Columbus, OH: The Ohio State University Press.



	
		Development and evaluation of a profile negotiation process for integrating aircraft and air traffic control automation (NASA Technical Memorandum 4360)
		
			SMGreen
		
		
			WDen Braven
		
		
			DHWilliams
		
		
			1993
			National Aeronautics and Space Administration
			Moffett Field, CA
		
	
	Green, S.M., den Braven, W., & Williams, D.H. (1993). Development and evaluation of a profile negotiation process for integrating aircraft and air traffic control automation (NASA Technical Memorandum 4360). Moffett Field, CA: National Aeronautics and Space Administration.



	
		Defining Human-Centered System Issues for Verifying and Validating Air Traffic Control Systems
		
			KellyHarwood
		
		10.1007/978-3-662-02933-6_6
	
	
		Verification and Validation of Complex Systems: Human Factors Issues
		
			JWise
		
		
			VDHopkin
		
		
			PStager
		
		Berlin
		
			Springer Berlin Heidelberg
			1993
			
		
	
	Verification and Validation of Complex and Integrated Human Machine Systems
	Harwood, K. (1993). Defining human-centered system issues for verifying and validating air traffic control systems. In J. Wise, V.D. Hopkin, and P. Stager (Eds.), Verification and Validation of Complex and Integrated Human Machine Systems , Berlin: Springer-Verlag.



	
		Human Factors Certification of Advanced Aviation Technologies
		
			KHarwood
		
		
			BDSanford
		
		J. Wise, V.D. Hopkin, and D.J. Garland
		
			1994
			Embry-Riddle Aeronautical Univ. Press
			Daytona Beach, FL
		
	
	Evaluation in context: ATC automation in the field
	Harwood, K., & Sanford, B.D. (1994). Evaluation in context: ATC automation in the field. In J. Wise, V.D. Hopkin, and D.J. Garland (Eds.), Human Factors Certification of Advanced Aviation Technologies , Daytona Beach, FL: Embry-Riddle Aeronautical Univ. Press.



	
		Improved navigational technology and air traffic control: A description of controller coordination and workload
		
			KKLee
		
		
			WSPawlak
		
		
			BDSanford
		
		
			RASlattery
		
	
	
		Proceedings of the Eighth International Symposium on Aviation Psychology
		the Eighth International Symposium on Aviation PsychologyColumbus, OH
		
			The Ohio State University Press
			1995
		
	
	To appear in
	Lee, K.K., Pawlak, W.S., Sanford, B.D., & Slattery, R.A. (1995). Improved navigational technology and air traffic control: A description of controller coordination and workload. To appear in Proceedings of the Eighth International Symposium on Aviation Psychology , Columbus, OH: The Ohio State University Press.



	
		
			BDSanford
		
		
			KHarwood
		
		
			SNowlin
		
		
			HBergeron
		
		
			HHeinrichs
		
		
			GWells
		
		
			MHart
		
		Center TRACON automation system: Development and evaluation in the field. 38th Annual Air Traffic Control Association Conference Proceedings
		
			1993. October, 1993
		
	
	Sanford, B.D., Harwood, K., Nowlin, S., Bergeron, H., Heinrichs, H., Wells, G., & Hart, M. (1993). Center TRACON automation system: Development and evaluation in the field. 38th Annual Air Traffic Control Association Conference Proceedings , October, 1993.



	
		MITRE progress report No. 2
		
			DWSmall
		
		10.2172/5963005
		No. MP 94W0000088
	
	
		Lessons Learned: Human Factors in the AAS Procurement
		McLean, VA
		
			Office of Scientific and Technical Information (OSTI)
			1994
		
	
	Report
	Small, D.W. (1994). Lessons Learned: Human Factors in the AAS Procurement (Report No. MP 94W0000088). McLean, VA: Mitre.



	
		Usability Engineering: Our Experience and Evolution
		
			JohnWhiteside
		
		
			JohnBennett
		
		
			KarenHoltzblatt
		
		10.1016/b978-0-444-70536-5.50041-5
	
	
		Handbook of Human-Computer Interaction
		
			MHelander
		
		North Holland)
		
			Elsevier
			1988
			
		
	
	Handbook of Human-Computer Interaction
	Whiteside, J., Bennet, J., and Holtzblatt, K. (1988). Usability engineering: Our experience and evolution. In M. Helander (Ed.), Handbook of Human-Computer Interaction . Elsevier Science Publishers BV (North Holland): New York. (pp. 791-817).


				
			
		
	
