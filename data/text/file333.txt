
	
	
		
List of Figures
List of Tables
AbstractCharacterization of the performance of Air Traffic Management Exploration (ATM-X) TestBed integration environment has been investigated and documented for one system configuration for progressively increasing traffic.Several statistical parameters were used to assess the performance of the TestBed distributed system such as mean, standard deviation, skewness, and kurtosis of latency, and update rate for aircraft state messages that are transmitted through the simulated system under investigation.It is necessary to assess the performance characteristics of distributed systems in terms of the indicated statistical parameters mentioned above.It is critical to verify the system performance with respect to a researcher's required system performance.Computer host specifications are documented in terms of Central Processing Unit (CPU) clock speed and core count.Transmission Control Protocol/ Internet Protocol (TCP/IP) message protocol was used for data transmission.The system network topology also contributes to the latency and update rate variations from the one imposed by the data source.The motivation for selecting the TestBed infrastructure as the focus of this study can be attributed to the number of services and capabilities it provides that help simplify the process of preparing and conducting a simulation.These capabilities include an easy to use GUI for simulation configuration, access to TestBed library by the end-user of other simulation software components, a modular adapter paradigm that allows simple connectivity of external software to TestBed, connectivity with other simulation laboratories, and a Software Development Kit (SDK) for quicker development.Two types of traffic generators, Air Traffic Generator (ATG) and Multi Aircraft Control System (MACS) were used to generate messages that were injected into the TestBed distributed environment.Eight different air traffic scenarios with progressively increasing loads were generated for each air traffic simulator.The corresponding air traffic loads between the two simulators had an identical number of aircraft per scenario, but different flight plans.It was observed that the performance of MACS degraded for air traffic scenarios containing more than 200 aircraft (37.5 KB/s nominal throughput).However, ATG performed adequately under all tested air traffic loads up to 1200 aircraft (225.KB/s nominal throughput).The tests show that MACS exhibits better latency performance with smaller aircraft loads when compared to ATG.The tests also show that the TestBed infrastructure successfully transmits 1200 aircraft without significant degradation of its performance.From the latency trends for both MACS and ATG, it is clear that as aircraft load increases, the latency in the system increases as well as its standard deviation.Likewise, the trends for the update data rate for both MACS and ATG show that as the aircraft load increases, so does the standard deviation and mean of the update rates which can be attributed to the performance of MACS and ATG applications.The analysis of the results of this study have proven that the overall system performance is dependent on the individual performance of each system component that is connected to TestBed, which subsequently propagates into the system.All TestBed characterization tests were conducted in SimLabs at NASA Ames Research Center in November 2019.This study addresses the need for a baseline TestBed characterization, and the results will serve as a reference for more complex simulation systems.
IntroductionThe Air Traffic Management Exploration (ATM-X) TestBed integration infrastructure was developed by the Aviation Systems Division at NASA Ames Research Center.Characterization of its performance will require multiple performance metrics and a consistent method of testing with multiple data generators.It should be emphasized that the performance of the overall system is dependent on the individual performance of connected components to Testbed.Multi-purpose Interface (MPI) Flight State messages will be transmitted through the TestBed infrastructure to the Data Logger via MACS or ATG.Each message includes the timestamp of when the message was created, the timestamp of when the message is received by TestBed, and the time when the Data Logger records the time stamp.These three components of the MPI Flight State Message will be the primary pieces of data used to analyze the performance of TestBed.Table 18 lists the acronyms and their meanings used in this technical document.
Test ObjectivesThe primary objectives required to characterize the performance of TestBed are: The objectives outlined above are achieved by performing 30-minute simulations for a variety of different aircraft loading scenarios with both ATG and MACS as data sources.The testing environment and procedure is kept consistent to minimize hardware-based dependencies that can affect the results.
System ArchitectureTo characterize the performance of TestBed accurately, it is important to understand the infrastructure of the data generators: MACS and ATG.MACS, developed at Airspace Operation Laboratory (AOL) at NASA Ames Research Center, comes in both Windows and Linux flavors that utilize the Java Virtual Environment.While ATG, developed in-house at SimLabs also at NASA Ames Research Center, is distributed as a Linux software.For the purpose of this study, the Windows version of MACS was used because it is the most popular version used in everyday ATM simulations at the SimLabs facility.The release versions of the software used in this study can be found in Table 1.
TestBed InfrastructureThe TestBed infrastructure used in this characterization study provides a communication middleware, Apache ActiveMQ message broker, for interactions among various system clients integrated into the system.TestBed is pluggable such that different middleware such as Data Distribution Service (DDS) or Neural Autonomic Transport System (NATS) can be used instead of ActiveMQ.For the performance characterization of TestBed, MACS and ATG adapters were developed to interface with the TestBed data bus.It should be noted that the timestamps are not generated within the ActiveMQ Broker itself, but rather by the corresponding adapters just before the data is transmitted to the TestBed data bus.
MACS Data SourceMACS takes a user generated scenario file as an input and runs a simulation based on the information encapsulated within the scenario file.MACS can be set up to run with many different features, but for the purpose of TestBed characterization, MACS was run using the developer mode.The Developer instance of MACS differs from the traditional setup that has MACS run on multiple computers with a MACS observer, MACS pilot, and MACS controller.The Developer instance was chosen, as it would require the use of one computer, and simplified the running procedure without having to study the dependencies that other computers running different components of MACS would have on the performance of TestBed.MACS can publish various messages at fixed rates for specific aircraft.A rate of 1Hz was chosen for this study.It should be noted that MACS has the ability to generate internal logs and adjust the dispatch rate of messages according to aircraft load.These features were turned off to ensure consistent testing conditions for all aircraft loads.The timestamps generated within the source of MACS are of moderate fidelity.These timestamps are communicated to TestBed through the Aeronautical Data Link and Radar Simulator (ADRS) and its corresponding adapter.It should be noted that the Windows system that runs MACS was not perfectly synchronized with the Linux systems that host the ADRS/MACS Adapter despite measures taken to ensure synchronization.Therefore, it is possible in low latency situations that a negative latency can occur due to the use of asynchronous systems.Testing of the asynchronous lag between the two systems yielded a lag of 0.5 milliseconds by the Windows system.The system architecture when MACS was used as a target generator can be seen in Figure 1.
ATG Data SourceLike MACS, ATG takes a user generated scenario file as an input to simulate air traffic.ATG is invoked from the command line on a single machine which launches a Graphical User Interface (GUI) to start the scenario.ATG can publish messages at various rates such as 1Hz or 4Hz.For the sake of testing under similar conditions as MACS, the 1Hz dispatch rate was chosen for ATG messages.ATG publishes data with timestamps that are of higher fidelity than MACS; however, the ATG adapter polls the time with a lower fidelity than ATG itself.This often results in negative latencies in a low latency system.Note that negative latencies are not physically possible, but a result of comparing numbers of differing fidelity.ATG connects with TestBed through an adapter that is visualized in the ATG system architecture as shown in Figure 2.
Testing EnvironmentAs software is always changing, it is important to note that these tests only capture a snapshot of software at a point in time.The software versions used in this study are provided in addition to the details of scenario creation for each target generator.To ensure the validity of comparing results among simulations, a testing procedure was rigidly followed and provided for transparency.
Software VersionsSoftware versions for the operating systems, simulators, and ActiveMQ broker are provided in Table 1.
Scenario CreationEach of the simulators has unique scenario files that are used to drive the simulation.A discussion of what each scenario file consists of will be detailed to understand the nature of the input data into the system and its potential impact on TestBed performance.
MACSMACS scenario files encompass all the aircraft in the simulation with each aircraft identified by a unique callsign.Information about the aircraft's entry time into the simulation, exit time from the simulation, and route it will travel are just a few of the fields input for each aircraft.Other information including the aircraft's initial state data is provided for each aircraft.This brings the total number of fields to be read into MACS to 51.For analyzing TestBed performance, the aircraft scenarios had different aircraft loads that were loaded into the scenario at different time intervals.The eight aircraft loads studied in MACS were 10, 25, 50, 75, 100, 200, 300, and 400.Aircraft were loaded in as batches as shown in Table 2.The aircraft loads are also quantified in terms of KB/s in Table 11.30 N/A N/A N/A N/A N/A 10 8 33 N/A N/A N/A N/A N/A 10 8 36 N/A N/A N/A N/A N/A 10 8 39 N/A N/A N/A N/A N/A 10 8 42 N/A N/A N/A N/A N/A 10 8 45 N/A N/A N/A N/A N/A 10 8 48 N/A N/A N/A N/A N/A 10 8 51 N/A N/A N/A N/A N/A 10 8 54 N/A N/A N/A N/A N/A 10 8 57 N/A N/A N/A N/A N/A 10 8 60 N/A N/A N/A N/A N/A N/A 8 63 N/A N/A N/A N/A N/A N/A 8 66 N/A N/A N/A N/A N/A N/A 8 69 N/A N/A N/A N/A N/A N/A 8 72 N/A N/A N/A N/A N/A N/A 6 75 N/A N/A N/A N/A N/A N/A 8 78 N/A N/A N/A N/A N/A N/A 8 81 N/A N/A N/A N/A N/A N/A 7 84 N/A N/A N/A N/A N/A N/A 6 87 N/A N/A N/A N/A N/A N/A 7 90 N/A N/A N/A N/A N/A N/A 7 93 N/A N/A N/A N/A N/A N/A 6 10 96 N/A N/A N/A N/A N/A N/A 7 10 99 N/A N/A N/A N/A N/A N/A 7 10 102 N/A N/A N/A N/A N/A N/A 7 10 105 N/A N/A N/A N/A N/A N/A 5 10 108 N/A N/A N/A N/A N/A N/A 6 10 111 N/A N/A N/A N/A N/A N/A 7 10 114 N/A N/A N/A N/A N/A N/A 7 10 117 N/A N/A N/A N/A N/A N/A 7 10
ATGLike MACS, ATG scenarios require unique call signs for all the aircraft in the scenario in its input file.The input file consists of each callsign, its start time and its route data.The scenario file for ATG is far less detailed than the MACS scenario input file and does not include state data directly modifiable within the input file.Rather ATG uses predefined routes to propagate the aircraft throughout the simulation.Aircraft loads of 10, 25, 50, 75, 100, 200, 300, and 400 were chosen to accurately compare the behavior of the TestBed infrastructure with two different data sources under ideal loads and conditions.Like MACS, the aircraft in ATG are loaded in as batches.Note that there is an initial wait time of 30 seconds at the beginning of each ATG scenario.Table 3 shows the aircraft loading behavior for each scenario used for ATG.The aircraft loads are also quantified in terms of KB/s in Table 17.57 N/A N/A N/A N/A N/A N/A 51 60 60 N/A N/A N/A N/A N/A N/A N/A 91
Distributed SystemsThe systems used to perform the characterization testing were located at the Distributed Simulation and Research Lab (DSRL) and Simulation Development Lab (SDL) located at NASA Ames Research Center.The network topology plays a role in the performance of TestBed as the systems are isolated on their network and as such, there is less network overhead compared to if testing were to be done incorporating machines in a different facility.As such, this data should be taken to represent the best-case scenario for the performance of TestBed.The relevant specifications and setup of the systems used are shown below in Table 4 andTable 5.
MACS
ProcedureConsistent testing procedures for both MACS and ATG were rigidly followed.In addition to the procedure outlined below, each system was made sure to be not in use by another user, so that no other applications could negatively impact performance.
MACSFor MACS, the following protocol was followed:1
ATGFor ATG, the following protocol was followed:1
System Time SynchronizationNetwork Time Protocol (NTP) was used for clock synchronization among all computer systems.NTP provides Coordinated Universal Time (UTC), which includes leap second adjustments.The NTP uses a hierarchical, semi-layered system of levels of clock sources.Each level of this hierarchy is termed a stratum and is assigned a layer number starting with 0 (zero) at the top.The stratum level defines its distance from the reference clock and exists to prevent cyclical dependencies in the hierarchy.It is important to note that the stratum is not an indication of quality or reliability.All computers used in the characterization of TestBed were synchronized to a Stratum 2 time-server.Procedure for the synchronization between machines involved the use of the Timesvr program, which would run on a system that acted as the time server.Another program, Tquery client, would be run on another system to measure the offset with the time server machine.Tquery has parameters that allow the adjustment of the frequency and number of query requests made to the machine used as a time server.The Windows machine running MACS was synchronized with the Linux machines with the use of the Stripchart program.This program was used to query a Linux machine with the proper time tracking software installed and then synchronize to it.A script was used to modify the frequency and number of queries made to the Linux machine.
Results and DiscussionIn total there were 56 simulations ran and analyzed for different configurations.The final analysis was conducted using 16 data sets, 8 of the data sets were from MACS and the other 8 were from ATG.These 16 data sets were chosen based upon the newest working adapter versions of the software at the time of testing and for configurations that would best represent an impartial view of the performance of TestBed.Of these 16 data sets, a smaller subset was chosen for characterization.Analyzing these 16 data sets, scenarios from ATG and MACS with 10, 50, 200, and 400 aircraft were most representative of the data taken.These four scenarios in MACS and ATG are used for analysis in this study of the characterization of the TestBed software.To calculate the desired performance metrics for the purpose of this study, an application was developed to process the raw data from the logger files for every target aircraft in every scenario.It should be noted that the figures in this study were generated based upon the calculated performance metrics below.
Definition of Performance Metrics
LatencyLatency was measured in two different contexts: latency for the time received and latency for the time recorded.Latency for a time received is defined as the difference between the time created by the source and the time received by TestBed.The latency for time recorded is defined as the difference between the time created by the source and the time recorded by the Data Logger.This metric was taken with respect to each aircraft for each scenario.Note that these metrics will be referred to as quantities throughout this study: latency received, and latency recorded.In addition, the related figures will contain latency data on the left axis, and standard deviation data on the right axis.
Update RateThe update rate was measured as the difference between each successive message for the time created by the source, the time received by TestBed, and the time recorded by the Data Logger for each aircraft within a specific scenario.Note that update rates for the time created, received, and recorded will be referred to as quantities: update rate time-created, update rate time-received, and update rate time-recorded.In addition, the related figures will contain update rate data on the left axis, and standard deviation data on the right axis.
Advanced Performance MetricsMore advanced performance metrics were used to describe the behavior of the latency and update rate for each aircraft.A histogram was generated for each aircraft to visualize the behavior of the latency and update rates throughout each scenario.Performance metrics such as the mean, standard deviation, skewness, and kurtosis were used to perform statistical analysis on the data.The mean, ́ , measures the simple average of all the data in a given sample size.The mathematical equation used to calculate the mean is given in Equation 1, where the n is the number of samples, and x is the value of the individual quantity, i, in the sample.𝑥𝑥 ´ = ∑ 𝑥𝑥 𝑖𝑖 𝑛𝑛 𝑖𝑖=0 (Equation 1)Standard deviation, σ, measures the deviation from the mean that the sampled data exhibits.The mathematical equation that is used to describe the standard deviation is given in Equation 2. 2) Skewness, μ 3 , is a measure of the asymmetry of the sampled data with respect to the mean.Data that is perfectly symmetrical will exhibit a skewness of 0. Curves can demonstrate both positive and negative skewness that demonstrate a data leans a specific way with respect to the mean.The equation used to represent the skewness of the sampled data is given in Equation 3. 3) Kurtosis, μ 4 , analyzes the tails of the sampled data's distribution.Data with high kurtosis signifies many outliers of the sampled data with respect to the mean.On the contrary, data with low kurtosis signifies that most of the sampled data falls near the mean.Note that excess kurtosis is scaled to the value of 3. The equation used to calculate excess kurtosis is given by Equation 4. 4)σ = � 1 𝑛𝑛-1 ∑ (𝑥𝑥 𝑖𝑖 -𝑥𝑥 ´) 𝑛𝑛 𝑖𝑖=0 2 (Equationμ 3 = 1 𝑛𝑛𝜎𝜎 3 ∑ (𝑥𝑥 𝑖𝑖 -𝑥𝑥 ´) 𝑛𝑛 𝑖𝑖=0 3 (Equationμ 4 = 1 𝑛𝑛𝜎𝜎 4 ∑ (𝑥𝑥 𝑖𝑖 -𝑥𝑥 ´) 𝑛𝑛 𝑖𝑖=0 4 (Equation
ThroughputThe throughput is measured as the number of bytes in data passed in one second in the scenario.The size of the MPI Flight State Message and the number of messages passed in one second is critical in determining the number of bytes sent through the "wire".Note that the size of the message is 192 bytes.
Probability Density FunctionThe histograms generated from the latency data for each aircraft were generated by considering only the data within plus or minus three times the standard deviation.Even width bins were generated at intervals of half the standard deviation and the corresponding data was placed into one of these six bins.The amount of data placed in each bin was normalized against the total data that was sampled within the given range of plus or minus three times the standard deviation.This normalized weight for each bin represents the percentage of data that falls within each bin.It should be noted that the sum of each the weights should equal one in a probability density function.The accuracy parameter in the histograms demonstrates how close to one the area under the curve is using the sampled data.
MACSThe results for the MACS scenarios chosen for presentation consist of 10, 50, 200, and 400 aircraft scenarios.The aircraft presented for analysis are AAL185, TCF5995, JBU296, UAL1022, and AAL168 in Figures 3-28.These aircraft are chosen to demonstrate the behavior of target callsign that is loaded into the scenario at significantly different times.The comprehensive performance metrics calculated for latency are provided in Table 6 andTable 7. From Table 6 it can be seen that as the aircraft load increases, there does not seem to be any clear impact on the mean for latency received.Values for the mean are small and in the range of 1 to 100 microseconds.The standard deviation values are consistently between 10 and 300 microseconds under all loads.The values for skewness and kurtosis are all positive and large.From Table 7 it can be seen that as the aircraft load increases, there is a consistent increase in the mean for latency recorded.Values for the mean latency received range from 30 to 410 milliseconds.The standard deviation values range between 15 and 160 milliseconds under all loads.The values for skewness are all positive while the values for kurtosis are all negative.The negative kurtosis represents that the tails of the data distribution are more extended than that of the normal distribution (which kurtosis is considered 0).The data is positively skewed for all the results, which signifies that the data is focused on the negative side of the mean.Hence, the tails are longer on the positive side of the mean.Tables 8-10 present the results for the mean and standard deviation for the update rates in MACS for the time-created, time-received, and time-recorded.
Latency of aircraft in 10AC scenario (AAL185, TCF5995)Figure 3. Target Callsign AAL185: Latency for MACS 10AC Scenario.The latency characteristics of aircraft callsign AAL185 are seen in Figure 3.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to 8 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is negligible at 500 nanoseconds.While the mean latency for time-recorded is 33.456 milliseconds.Latency for time-recorded appears to dip at the 500-1000 second mark in the simulation.Note that at 750 seconds it appears that the latency becomes negative.The overall behavior of the latency recorded can be described as jagged.The latency characteristics of aircraft callsign TCF5995 are seen in Figure 4.This aircraft is the last aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to 8 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.0229 milliseconds.While the mean latency for timerecorded is 39.804 milliseconds.Like AAL185, latency for time-recorded appears to dip at the 500-1000 second mark in the simulation.Note that at 750 seconds it appears that another dip occurs similar to AAL185.The overall behavior of the latency recorded can be described as jagged.
Latency of aircraft in 50AC scenario (AAL185, TCF5995, UAL1022)Figure 5. Target Callsign AAL185: Latency for MACS 50AC Scenario.The latency characteristics of aircraft callsign AAL185 are seen in Figure 5.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to slightly under 40 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is negligible at 500 nanoseconds.While the mean latency for time-recorded averages 61.852 milliseconds.Latency for time-recorded appears to drop at multiple points throughout the simulation.The most notable drops of 20 milliseconds in latency occur at the 200 and 500 second marks respectively.The overall behavior of the latency recorded can be described as jagged, with sections of noisy peaks and values.The latency characteristics of aircraft callsign TCF5995 is seen in Figure 6.This aircraft is one of the later aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to slightly under 40 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.0658 milliseconds.While the mean latency for time-recorded averages 85.930 milliseconds.This is a larger mean latency for both the time-received and time-recorded compared to the AAL185.Latency for time-recorded appears to drop 20 milliseconds at multiple points throughout the simulation.On a larger scale, it is more difficult to see the drops in Latency as shown in Figure 5 at the 200 and 500 second marks of the simulation; however, they are still present.It appears that once the aircraft load decreases after the 750 second mark, the latency drops below the mean.The overall behavior of the latency recorded can be described as jagged, although less pronounced than the 10 aircraft simulation.The latency characteristics of aircraft callsign UAL1022 is seen in Figure 7.This aircraft is one of the last aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to slightly under 40 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.0282 milliseconds.While the mean latency for time-recorded averages 86.424 milliseconds.The latency for time-recorded appears to drop 20 milliseconds at multiple points throughout the simulation.Dips in latency are present at the beginning of the simulation at the 200 and 500 seconds marks.This is similar to the behavior of AAL185 and TCF5995 for the same simulation.Like TCF5995, it appears that once the aircraft load decreases after the 750 second mark, the latency seems to drop below the mean.There are occasional dips in latency once the aircraft load is decreased, most notably at 1000, 1250, 1500, and 1700 seconds.The overall behavior of the latency recorded can be described as jagged, although less pronounced than the 10 aircraft simulation.
Latency of aircraft in 200AC scenario (AAL185, UAL1022, JBU296)Figure 8. Target Callsign AAL185: Latency for MACS 200AC Scenario.The latency characteristics of aircraft callsign AAL185 is seen in Figure 8.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load begins to decrease slightly to 150 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is 500 nanoseconds.While the mean latency for time-recorded is 127.12 milliseconds.The latency for time-recorded appears to drop at multiple points throughout the simulation and occurs more frequently than the dips seen in the 50 aircraft scenario.The frequency also sees larger dips and spikes on the magnitude of 100 milliseconds compared to 20 milliseconds in the 50 aircraft simulation.Similar to the 50 aircraft load behavior, the latency appears to decrease as load decreases.It should also be noted that as aircraft loading increases at the beginning of the simulation, the latency ramps up significantly before leveling off when the full load is loaded into the scenario.The overall behavior of the latency recorded can be described as jagged, with sections of extended peaks and values.The latency characteristics of aircraft callsign UAL1022 is seen in Figure 9.This aircraft is in the first quarter of aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases over time to around 150 aircraft starting at 750 seconds pass in the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.0888 milliseconds.While the mean latency for time-recorded is 115.92 milliseconds.This latency for time-recorded appears to drop at multiple points throughout the simulation and occurs more frequently than the dips seen in the 50 aircraft scenario.The time-recorded also sees larger dips and spikes on the magnitude of 100 milliseconds compared to 20 milliseconds into 50 aircraft simulation.At approximately 700 seconds, the latency decreases by over 100 milliseconds as aircraft load decreases.Note that as the aircraft load decreases the latency values also begin to decrease.It should also be noted that as aircraft loading increases at the beginning of the simulation, the latency ramps up significantly before leveling off when the full load is loaded into the scenario.Since this aircraft enters around when there is a load of approximately 40 aircraft, the ramping up of latency is less prominent than AAL185.The overall behavior of the latency recorded can be described as noisy under full load and jagged with noisy peaks and values with a lower load.The latency characteristics of aircraft callsign JBU296 is seen in Figure 10.This aircraft is one of the last aircraft loaded into the simulation and exists until close to 800 seconds into the simulation.Load decreases slightly at 300 seconds, but dramatically decreases at 700 seconds to 165 aircraft as denoted by the dotted orange line.The mean latency for time-received is 0.0599 milliseconds.While the mean latency for time-recorded is 222.82 milliseconds.The latency for time-recorded appears to drop at multiple points throughout the simulation.Dips in latency are present at 300 and 400 seconds with a magnitude of nearly 100 milliseconds.Like UAL1022, it appears that once the aircraft load decreases after the 750 second mark, the latency seems to drop below the mean.Note that there is no ramping up like AAL185 and UAL1022 as the aircraft is loaded in after latency behavior has stabilized.The overall behavior of the latency recorded can be described as noisy.
Latency of aircraft in 400AC scenario (AAL185, JBU296, AAL168)The latency characteristics of aircraft callsign AAL185 is seen in Figure 11.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation ends.Load decreases noticeably at 750 seconds to just above 300 aircraft as denoted by the dotted orange line.The mean latency for time-received is 800 nanoseconds.While the mean latency for time-recorded is 261.65 milliseconds.The latency for time-recorded appears to drop at multiple points throughout the simulation.Dips in latency are present throughout the simulation with a magnitude of nearly 200 milliseconds Note the ramping up behavior of the latency recorded in the first 100 seconds of the scenario.This behavior occurs as the aircraft load is increasing.When the aircraft load stabilizes, the latency recorded no longer displays this ramping behavior.The overall behavior of the latency recorded can be described as noisy.The latency characteristics of aircraft callsign JBU296 is seen in Figure 12.This aircraft is one of the first half of aircraft loaded into the simulation and exists for 800 seconds into the simulation.Load decreases noticeably at 750 seconds to just above 300 aircraft as denoted by the dotted orange line.The mean latency for time-received is 0.0566 milliseconds.While the mean latency for time-recorded is 407.31 milliseconds.The latency for time-recorded appears to drop at multiple points throughout the simulation.Dips in latency are present throughout the simulation with a magnitude of nearly 200 milliseconds Note the ramping up behavior of the latency recorded in the first few seconds of the aircraft lifespan.This behavior occurs as the aircraft load is increasing.When the aircraft load stabilizes, the latency recorded no longer displays this ramping behavior.Note that the ramping behavior for JBU296 is not as dramatic as AAL185 since the aircraft is loaded in later in the simulation.The overall behavior of the latency recorded can be described as noisy.The latency characteristics of aircraft callsign AAL168 is seen in Figure 13.This aircraft is one of the last aircraft loaded into the simulation and exists for 800 seconds into the simulation.Load decreases noticeably at 750 seconds to just above 350 aircraft as denoted by the dotted orange line.The mean latency for time-received is 0.0 milliseconds.While the mean latency for timerecorded is 383.99 milliseconds.The latency for time-recorded appears to drop at multiple points throughout the simulation.Dips in latency are present throughout the simulation with a magnitude of nearly 300 milliseconds Note the ramping up behavior of the latency recorded in the first few seconds of the aircraft lifespan.This behavior occurs as the aircraft load is increasing.When the aircraft load stabilizes, the latency recorded no longer displays this ramping behavior.Note that the ramping behavior for AAL168 is not as dramatic as AAL185 and JBU296 since the aircraft is  loaded in later in the simulation than the other two aircraft.The overall behavior of the latency recorded can be described as noisy.The update rate characteristics of aircraft callsign AAL185 is seen in Figures 14a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to 8 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are a few spikes in update rate created at 1100, 1400, and 1600 seconds in the simulation as seen in Figure 14a.These spikes can be seen in 14b at the same times.However, the time-recorded update rates in 14c do not seem to have any clear relationship to the spikes seen in Figures 14a-b.Rather, noise around the mean of 1 second is consistent and small through The update rate characteristics of aircraft callsign TCF5995 is seen in Figures 15a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to 8 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 15a.Figure 15b shows corresponding spikes in the update rate received data.This is similar behavior to that of AAL185.However, unlike AAL185, some spikes are more frequent in the update rate for timecreated and the time-received plots in TCF5005.However, the time-recorded update rates in 15c do not seem to have any clear relationship to the spikes seen in Figures 15a-b.Rather, noise around the mean of 1 second is consistent and small throughout the simulation.
Update rate of aircraft in 10AC scenario (AAL185, TCF5995)
Update rate of aircraft in 50AC scenario (AAL185, TCF5995, and UAL1022)
Figure 16a (Top), 16b (Middle), 16c (Bottom). Target Callsign AAL185: Update Rates for Time-Created, Time-Received, and Time-Recorded for MACS 50AC Scenario.The update rate characteristics of aircraft callsign AAL185 is seen in Figures 16a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to just under 40 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 16a.Figure 16b shows corresponding spikes in the update rate received data.However, the timerecorded update rates in 16c do not seem to have any clear relationship to the spikes seen in Figures 16a-b.Rather, noise around the mean of 1 second is consistent and has a larger deviation than the deviation seen in the 10 aircraft simulation.
Figure 17a (Top), 17b (Middle), 17c (Bottom). TCF5995 Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 50AC Scenario.The update rate characteristics of aircraft callsign TCF5995 is seen in Figures 17a-c.This aircraft is one of the last aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to just under 40 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 17a.Figure 17b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 17a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 17b.However, the timerecorded update rates in 17c do not seem to have any clear relationship to the spikes seen in Figures 17a-b.Rather, noise around the mean of 1 second is small with a few large spikes at 200, 750, 1250, and 1300 seconds into the simulation.The update rate characteristics of aircraft callsign UAL1022 is seen in Figures 18a-c.This aircraft is one of the final aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to just under 40 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 18a.Figure 18b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 18a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 18b.However, the timerecorded update rates in 18c do not seem to have any clear relationship to the spikes seen in Figures 18a-b.Rather, noise around the mean of 1 second is small with a few large spikes at 200, 750, 1250, and 1300 seconds into the simulation.Note that the behavior of UAL1022 closely mirrors the behavior of TCF5995.However, neither of these aircraft seem to resemble the behavior of AAL185.
Update rate of aircraft in 200AC scenario (AAL185, UAL1022, and JBU296)Figure 19a (Top),19b (Middle),19c (Bottom).Target Callsign AAL185: Update Rates for Respectively,for MACS 200AC Scenario.The update rate characteristics of aircraft callsign AAL185 is seen in Figures 19a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to just around 150 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 19a.Figure 19b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 19a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 19b.However, the timerecorded update rates in 19c do not seem to have any clear relationship to the spikes seen in Figures 19a-b.Rather, noise around the mean of 1 second is moderate with large spikes that are more frequent before the 750 second mark in the simulation.Note that the behavior of AAL185 in this scenario shows higher spikes and noise than the 10 and 50 aircraft simulations.The update rate characteristics of aircraft callsign UAL1022 is seen in Figures 20a-c.This aircraft is in the first quarter of the aircraft loaded into the simulation and exists until the simulation is stopped.Load decreases to just around 150 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 20a.Figure 20b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 20a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 20b.However, the timerecorded update rates in 20c do not seem to have any clear relationship to the spikes seen in Figures 20a-b.Rather, noise around the mean of 1 second is small with large spikes that are more frequent between the 750 and 1250 second mark in the simulation.The behavior of the update rate for time-recorded is less noisy than that of AAL185.The update rate characteristics of aircraft callsign JBU296 is seen in Figures 21a-c.This aircraft is one of the last aircraft loaded into the simulation and exists until around the 800 second mark.Load decreases to just around 150 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 21a.Figure 21b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 21a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 21b.However, the timerecorded update rates in 21c do not seem to have any clear relationship to the spikes seen in Figures 21a-b.Rather, noise around the mean of 1 second is small with moderate spikes throughout the aircraft lifespan.The update rate characteristics of aircraft callsign AAL185 is seen in Figures 22a-c.This aircraft is in one of the first aircraft loaded into the simulation and exists until the simulation ends.Load decreases to just above 300 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 22a.Figure 22b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 22a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 22b.However, the time-recorded update rates in 22c do not seem to have any clear relationship to the spikes seen in Figures 22a-b.Rather, noise around the mean of 1 second is large with minimal spikes throughout the aircraft lifespan.The update rate characteristics of aircraft callsign JBU296 is seen in Figures 23a-c.This aircraft is in the first half of aircraft loaded into the simulation and exists until around the 800 second mark.Load decreases to just above 300 aircraft after 750 seconds pass in the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 23a.Figure 23b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 23a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 23b.However, the timerecorded update rates in 23c do not seem to have any clear relationship to the spikes seen in Figures 23a-b.Rather, noise around the mean of 1 second is moderate with notable spikes throughout the aircraft lifespan.The update rate characteristics of aircraft callsign AAL168 is seen in Figures 24a-c.This aircraft is in the first half of aircraft loaded into the simulation and exists until around the 800 second mark.Load decreases to just above 350 aircraft as AAL168 leaves the scenario as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 23a.Figure 23b shows corresponding spikes in the update rate received data.Note that spikes that are larger in magnitude in the update rate for time-created in 23a have corresponding large magnitude spikes in update rate for the time-received plot in Figure 23b.However, the timerecorded update rates in 23c do not seem to have any clear relationship to the spikes seen in Figures 23a-b.Rather, noise around the mean of 1 second is large with minimal spikes throughout the aircraft lifespan.
Update rate of aircraft in 400AC scenario (AAL185, JBU296, and AAL168)
Comparison of aircraft latency across different scenarios: 10AC, 50AC, 200AC, 400AC of AAL185Note that for Figures 25-28 that the Probability Density Functions (PDF) have been adjusted to account for data within plus or minus three times the standard deviation, whereas the advanced performance metrics are calculated for the entire dataset that may fall outside the range plotted.Also note, the accuracy parameters is how close to one the area under the curve is for the given range of data.The generated PDF for the latency of the received and recorded data for AAL185 in the 10 aircraft simulation is given in Figures 25a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 25a.While the data for latency recorded demonstrates a standard deviation of 16.047 milliseconds, kurtosis of -2.416, and skewness of 0.4991.The generated PDF for the latency of the received and recorded data for AAL185 in the 50 aircraft simulation is given in Figures 26a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 26a.While the data for latency recorded demonstrates a standard deviation of 21.577 milliseconds, kurtosis of -2.443, and skewness of 0.4975.The generated PDF for the latency of the received and recorded data for AAL185 in the 200 aircraft simulation is given in Figures 27a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 27a.While the data for latency recorded demonstrates a standard deviation of 47.778 milliseconds, kurtosis of -1.916, and skewness of 0.5636.
Figure 28a (Top), 28b (Bottom). Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 400AC Scenario.The generated PDF for the latency of the received and recorded data for AAL185 in the 400 aircraft simulation is given in Figures 28a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 28a.While the data for latency recorded demonstrates a standard deviation of 107.09 milliseconds, kurtosis of -2.535, and skewness of 0.4721.
Measure of maximum system throughput and accumulated error for 10AC, 50AC, 200AC, 400AC scenariosThe throughput rates shown in Table 11 show that as aircraft scenario increases, the average throughput increases.This simple observation makes sense because as the aircraft load increases, so does the amount of data being sent per second.It is interesting to note that there are some instances where no messages are sent through in one second, while there is an extraordinary amount of data sent through at other times.Interestingly, the average throughput does not necessarily equal the amount of aircraft in the scenario times the size of the message, rather it is slightly smaller than expected.Further loading of MACS was not deemed as necessary as it became apparent that loads above 300 aircraft seemed to stretch MACS to its effective limit.
Latency Trends of Mean and Standard Deviation for Varying Aircraft Load in MACS
Figure 29a (Left), 29b (Right). Mean Latency and Standard Deviation for AAL185 in MACS.Figure 29a shows the behavior of the mean and standard deviation for the latency received for aircraft AAL185 at loads of 10, 50, 200, and 400 aircraft.It is apparent that as aircraft load increases, so does the standard deviation.However, the mean latency remains constant at a mere 100 nanoseconds.Figure 29b shows the behavior of the mean and standard deviation for the latency recorded for aircraft AAL185 at loads of 10, 50, 200, and 400 aircraft.Unlike the trend for the latency received, the latency recorded shows that as aircraft load increases the standard deviation and mean both increase.Note that the mean and standard deviation latency values are higher for the latency recorded compared to the latency received.From Table 12 it can be seen that as the aircraft load increases, there is a consistent increase in the mean and standard deviation for latency received.Values for the mean latency received range from -0.4 to 31 milliseconds.Standard deviation ranges between 0.4 and 3.3 milliseconds under all loads.The values for skewness are mostly positive while the values for kurtosis are split between positive and negative.The negative kurtosis represents that the tails of the data distribution are more extended than that of the normal distribution (which kurtosis is considered 0).Positive kurtosis represents that the tails of the data distribution are less extended than that of a normal distribution.The data is positively skewed for all but one of the results, which signifies that the data is focused on the negative side of the mean.Hence, the tails are longer on the positive side of the mean.From Table 13 it can be seen that as the aircraft load increases, there is a consistent increase in the mean and standard deviation for latency recorded.Values for the mean latency recorded range from 1.2 to 255 milliseconds.Standard deviation ranges between 1.3 and 14 milliseconds under all loads.The values for skewness are all positive while the values for kurtosis are mostly negative.The negative kurtosis represents that the tails of the data distribution are more extended than that of the normal distribution (which kurtosis is considered 0).Positive kurtosis represents that the tails of the data distribution are less extended than that of a normal distribution.The data is positively skewed for all the results, which signifies that the data is focused on the negative side of the mean.Hence, the tails are longer on the positive side of the mean.Tables 14-16 present the mean and standard deviation for the update rates, time-created, time-received, and time-recorded for ATG.
Latency of aircraft in 10AC scenario: (TBED002, TBED010)Figure 31.Target Callsign TBED002: Latency for ATG 10AC Scenario.The latency characteristics of aircraft callsign TBED002 is seen in Figure 31.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is -0.326 milliseconds.While the mean latency for time-recorded is 2.9875 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable during the first 600 seconds of the simulation before it begins to settle.At the beginning of the simulation, there is a notable ramping down for the latency recorded and latency received that lasts for a few seconds.The overall latency behavior can be described as noisy with occasional peaks.The latency characteristics of aircraft callsign TBED010 is seen in Figure 32.This aircraft is the last aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for timereceived is 0.7653 milliseconds.While the mean latency for time-recorded is 9.0407 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation with larger spikes in the first 750 seconds.At the beginning of the simulation, there is a notable ramping down for the latency recorded and latency received that lasts for a few seconds.The latency for both time-received and time-recorded for TBED010 is higher than TBED002.The overall latency behavior can be described as noisy with occasional peaks.
Latency of aircraft in 50AC scenario: (TBED002, TBED010, TBED050)Figure 33.Target Callsign TBED002: Latency for ATG 50AC Scenario.The latency characteristics of aircraft callsign TBED002 is seen in Figure 33.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.3427 milliseconds.While the mean latency for time-recorded is 6.9266 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the simulation, there is a notable ramping down for the latency recorded and latency received that lasts for a few seconds.The mean latency received and mean latency recorded for TBED002 is higher than the same callsign in the 10 aircraft simulation.The overall latency behavior can be described as noisy.The latency characteristics of aircraft callsign TBED010 is seen in Figure 34.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.6824 milliseconds.While the mean latency for time-recorded is 12.631 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the simulation, there is a notable ramping down for the latency recorded and latency received that lasts for a few seconds.The mean latency received and mean latency recorded for TBED002 is higher than the same callsign in the 10 aircraft simulation.The overall latency behavior can be described as noisy.The latency characteristics of aircraft callsign TBED050 is seen in Figure 37.This aircraft is one of the first quarter of aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is 4.8861 milliseconds.While the mean latency for time-recorded is 49.112 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the aircraft lifespan, there is a minor ramping up that occurs.This is opposite the behavior seen by TBED002 in the same simulation.The overall latency behavior can be described as noisy with occasional valleys.The latency characteristics of aircraft callsign TBED200 is seen in Figure 38.This aircraft is the last aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for timereceived is 17.151 milliseconds.While the mean latency for time-recorded is 132.42 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the aircraft lifespan, there is a minor ramping down that occurs.This ramping down is different than TBED002 of the same simulation which shows a ramping up behavior.Note that the mean latency received and mean latency recorded is higher for TBED200 than TBED002, and TBED050.The overall latency behavior can be described as noisy with occasional valleys.
Latency of aircraft in 400AC scenario: (TBED002, TBED200, TBED400)Figure 39.Target Callsign TBED002: Latency for ATG 400AC Scenario.The latency characteristics of aircraft callsign TBED002 is seen in Figure 39.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is 2.4207 milliseconds.While the mean latency for time-recorded is 34.766 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the aircraft lifespan, there is a ramping up behavior shown up until about 100 seconds into the scenario.Note that the mean latency received and mean latency recorded is higher for TBED002 in the 400 aircraft simulation compared to the 10, 50, and 200 aircraft simulations.The overall latency behavior can be described as noisy with occasional valleys.The latency characteristics of aircraft callsign TBED200 is seen in Figure 40.This aircraft is one of the first half of the aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is 17.923 milliseconds.While the mean latency for time-recorded is 146.13 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.There is no ramping up or down of latency that is notable at the beginning of the scenario.This is in contrast to the other aircraft call signs in the other ATG simulations.The overall latency behavior can be described as noisy.1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 42a.Figure 42b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 42c do not seem to have any clear relationship to the spikes seen in Figures 42a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.The update rate characteristics of aircraft callsign TBED010 is seen in Figures 43a-c.This aircraft is the last aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 43a.Figure 43b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 43c do not seem to have any clear relationship to the spikes seen in Figures 43a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.The update rate characteristics of aircraft callsign TBED010 is seen in Figures 45a-c.This aircraft is in the first quarter of the aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 45a.Figure 45b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 45c do not seem to have any clear relationship to the spikes seen in Figures 45a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the noise is more prominent for TBED010 in this simulation than the 10 aircraft simulation.The update rate characteristics of aircraft callsign TBED050 is seen in Figures 48a-c.This aircraft is in the first quarter of the aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 48a.Figure 48b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 48c do not seem to have any clear relationship to the spikes seen in Figures 48a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the noise is more prominent for TBED050 in this simulation than the 50 aircraft simulation.The update rate characteristics of aircraft callsign TBED002 is seen in Figures 50a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 50a.Figure 50b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 50c do not seem to have any clear relationship to the spikes seen in Figures 50a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the noise is more prominent for TBED002 in this simulation than the 10, 50, and 200 aircraft simulations.The update rate characteristics of aircraft callsign TBED200 is seen in Figures 51a-c.This aircraft is one of the middle aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 51a.Figure 51b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 51c do not seem to have any clear relationship to the spikes seen in Figures 51a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the noise is more prominent for TBED200 in this simulation than the 51 aircraft simulation.
Comparison of aircraft latency across different scenarios: 10, 50, 200, 400 AC of TBED002Figure 53a (Top),53b (Bottom).Target Callsign TBED002: PDF for Latency Received and Latency Recorded, Respectively, for ATG 10AC Scenario.The generated PDF for the latency of the received and recorded data for TBED002 in the 10 aircraft simulation is given in Figures 53a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 53a.The latency received demonstrates a standard deviation of 0.4050 milliseconds, kurtosis of 1193.9, and skewness of -19.39.While the data for latency recorded demonstrates a standard deviation of 1.4062 milliseconds, kurtosis of 21.450, and skewness of 2.2029.Note that the PDF has been adjusted to account for data within plus or minus three times the standard deviation, whereas the advanced performance metrics are calculated for the entire dataset that may fall outside the range plotted.Also note, the accuracy parameter is how close to one the area under the curve is for the given range of data.The generated PDF for the latency of the received and recorded data for TBED002 in the 50 aircraft simulation is given in Figures 54a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 54a.The latency received demonstrates a standard deviation of 0.3427 milliseconds, kurtosis of 407.8, and skewness of 13.784.While the data for latency recorded demonstrates a standard deviation of 1.3338 milliseconds, kurtosis of -2.238, and skewness of 0.6497.Note that the PDF has been adjusted to account for data within plus or minus three times the standard deviation, whereas the advanced performance metrics are calculated for the entire dataset that may fall outside the range plotted.Also note, the accuracy parameter is how close to one the area under the curve is for the given range of data.The generated PDF for the latency of the received and recorded data for TBED002 in the 200 aircraft simulation is given in Figures 55a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 55a.The latency received demonstrates a standard deviation of 0.3518 milliseconds, kurtosis of 84.384, and skewness of 4.6432.While the data for latency recorded demonstrates a standard deviation of 2.8596 milliseconds, kurtosis of -2.387, and skewness of 0.6738.Note that the PDF has been adjusted to account for data within plus or minus three times the standard deviation, whereas the advanced performance metrics are calculated for the entire dataset that may fall outside the range plotted.Also note, the accuracy parameter is how close to one the area under the curve is for the given range of data.The generated PDF for the latency of the received and recorded data for TBED400 in the 400 aircraft simulation is given in Figures 56a-b.The data for latency received is concentrated within plus/minus 0.25 times the standard deviation as seen in Figure 56a.The latency received demonstrates a standard deviation of 0.5701 milliseconds, kurtosis of -2.279, and skewness of 0.5919.While the data for latency recorded demonstrates a standard deviation of 4.4186 milliseconds, kurtosis of -2.361, and skewness of 0.7016.Note that the PDF has been adjusted to account for data within plus or minus three times the standard deviation, whereas the advanced performance metrics are calculated for the entire dataset that may fall outside the range plotted.Also note, the accuracy parameter is how close to one the area under the curve is for the given range of data.
Measure of system throughput for 10AC, 50AC, 200AC, 400AC, and breaking point scenariosThe throughput rates shown in Table 17 show that as aircraft scenario increases, the average throughput increases.This simple observation makes sense because as the aircraft load increases, so does the amount of data being sent per second.It is interesting to note that there is an instance where no messages are sent through in one second, while there is an extraordinary amount of data sent through at other times.Interestingly, the average throughput does not necessarily equal the amount of aircraft in the scenario times the size of the message, rather it is slightly smaller than expected.The breaking point of ATG was tested to be about 1300 aircraft.As such, the 1200 aircraft simulation was chosen to analyze the maximum throughput the system could handle before crashing.This value was found to be 224.999KB/s.Figure 57a shows the behavior of the mean and standard deviation for the latency received for aircraft TBED002 at loads of 10, 50, 200, and 400 aircraft.It is apparent that as aircraft load increases, so does the mean latency received and the standard deviation.Figure 57b shows the behavior of the mean and standard deviation for the latency recorded for aircraft TBED002 at loads of 10, 50, 200 and 400 aircraft.Like the trends for the latency received, the latency recorded also shows that as aircraft load increases the standard deviation and mean increases.Note that the mean and standard deviation latency values are higher for the latency recorded compared to the latency received.between approximately 0 milliseconds and 25 milliseconds and a mean between 999 milliseconds and 1001 milliseconds.The update rate for time-recorded for MACS had standard deviations between approximately 6 milliseconds and 114 milliseconds with a mean between 999 milliseconds and 1001 milliseconds.The standard deviation for ATG was between approximately 1 millisecond and 28 milliseconds with a mean between 999 milliseconds and 1001 milliseconds.It is clear from looking at the standard deviations presented, that ATG was able to enforce its update rate with more consistency when compared to MACS when tested in this study.The data analysis demonstrated that the TestBed performance could support simulations with aircraft loads exceeding the size of 1200 targets.Future characterization tests using different target generators that can support higher air traffic loads are required to find the maximum throughput capacity of the TestBed infrastructure.Overall, the TestBed infrastructure has successfully proven that it can sustain heavy aircraft loads with its extensive services and capabilities that simplify the process of conducting a simulation.Figure 1 .1Figure 1.High Level TestBed System Architecture with MACS......................................................... 8 Figure 2. High Level TestBed System Architecture with ATG............................................................ 9 Figure 3. Target Callsign AAL185: Latency for MACS 10AC Scenario........................................... 20 Figure 4. Target Callsign TCF5995: Latency for MACS 10AC Scenario......................................... 21 Figure 5. Target Callsign AAL185: Latency for MACS 50AC Scenario........................................... 21 Figure 6.Target Callsign TCF5995: Latency for MACS 50AC Scenario......................................... 22 Figure 7. Target Callsign UAL1022: Latency for MACS 50AC Scenario......................................... 22 Figure 8. Target Callsign AAL185: Latency for MACS 200AC Scenario......................................... 23 Figure 9. Target Callsign UAL1022: Latency for MACS 200AC Scenario...................................... 23 Figure 10.Target Callsign JBU296: Latency for MACS 200AC Scenario....................................... 24 Figure 11.Target Callsign AAL185: Latency for MACS 400AC Scenario....................................... 24 Figure 12.Target Callsign JBU296: Latency for 400AC MACS Scenario...................................... 25 Figure 13.Target Callsign AAL168: Latency for 400AC MACS Scenario...................................... 25 Figure 14a (Top), 14b (Middle), 14c (Bottom).Target Callsign AAL185: Update Rates for Time-Created, Time-Received, and Time-Recorded for MACS 10AC Scenario..................................... 26 Figure 15a (Top), 15b (Middle), 15c (Bottom).Target Callsign TCF5995: Update Rates for Time-Created, Time-Received, and Time-Recorded for MACS 10AC Scenario..................................... 27 Figure 16a (Top), 16b (Middle), 16c (Bottom).Target Callsign AAL185: Update Rates for Time-Created, Time-Received, and Time-Recorded for MACS 50AC Scenario..................................... 28 Figure 17a (Top), 17b (Middle), 17c (Bottom).TCF5995 Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 50AC Scenario...................................... 29 Figure 18a (Top), 18b (Middle), 18c (Bottom).Target Callsign UAL1022: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 50AC Scenario........... 30 Figure 19a (Top), 19b (Middle), 19c (Bottom).Target Callsign AAL185: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 200AC Scenario......... 31 Figure 20a (Top), 20b (Middle), 20c (Bottom).Target Callsign UAL1022: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 200AC Scenario......... 32 Figure 21a (Top), 21b (Middle), 21c (Bottom).Target Callsign JBU296: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 200AC Scenario......... 33 Figure 22a (Top), 22b (Middle), 22c (Bottom).Target Callsign AAL185: Update Rates for Time-Created, Time-Recorded, and Time-Received, Respectively, for MACS 400AC Scenario......... 34 Figure 23a (Top), 23b (Middle), 23c (Bottom).Target Callsign JBU296: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 400AC Scenario......... 35 Figure 24a (Top), 24b (Middle), 24c (Bottom).Target Callsign AAL168: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 400AC Scenario......... 36 Figure 25a (Top), 25b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 10AC Scenario........................................................................... 37 Figure 26a (Top), 26b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 50AC Scenario........................................................................... 37 Figure 27a (Top), 27b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 200AC Scenario......................................................................... 38 Figure 28a (Top), 28b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 400AC Scenario......................................................................... 38 Figure 29a (Left), 29b (Right).Mean Latency and Standard Deviation for AAL185 in MACS..... 39 Figure 30a (Top), 30b (Middle), 30c (Bottom).Mean Update Rates and Standard Deviation for Target Callsign AAL185 in MACS......................................................................................................... 40 Figure 31.Target Callsign TBED002: Latency for ATG 10AC Scenario......................................... 45
Figure 1 .1Figure 1.High Level TestBed System Architecture with MACS.
Figure 2 .2Figure 2. High Level TestBed System Architecture with ATG.
Figure 4 .4Figure 4. Target Callsign TCF5995: Latency for MACS 10AC Scenario.
Figure 6 .6Figure 6.Target Callsign TCF5995: Latency for MACS 50AC Scenario.
Figure 7 .7Figure 7. Target Callsign UAL1022: Latency for MACS 50AC Scenario.
Figure 9 .9Figure 9. Target Callsign UAL1022: Latency for MACS 200AC Scenario.
Figure 10 .10Figure 10.Target Callsign JBU296: Latency for MACS 200AC Scenario.
Figure 11 .11Figure 11.Target Callsign AAL185: Latency for MACS 400AC Scenario.
Figure 12 .12Figure 12.Target Callsign JBU296: Latency for 400AC MACS Scenario.
Figure 13 .13Figure 13.Target Callsign AAL168: Latency for 400AC MACS Scenario.
Figure 14a (14aFigure 14a (Top), 14b (Middle), 14c (Bottom).Target Callsign AAL185: Update Rates for Time-Created, Time-Received, and Time-Recorded for MACS 10AC Scenario.
Figure 15a (15aFigure 15a (Top), 15b (Middle), 15c (Bottom).Target Callsign TCF5995: Update Rates for Time-Created, Time-Received, and Time-Recorded for MACS 10AC Scenario.
Figure 18a (18aFigure 18a (Top), 18b (Middle), 18c (Bottom).Target Callsign UAL1022: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 50AC Scenario.
Figure 20a (20aFigure 20a (Top), 20b (Middle), 20c (Bottom).Target Callsign UAL1022: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 200AC Scenario.
Figure 21a (21aFigure 21a (Top), 21b (Middle), 21c (Bottom).Target Callsign JBU296: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 200AC Scenario.
Figure 22a (22aFigure 22a (Top), 22b (Middle), 22c (Bottom).Target Callsign AAL185: Update Rates for Time-Created, Time-Recorded, and Time-Received, Respectively, for MACS 400AC Scenario.
Figure 23a (23aFigure 23a (Top), 23b (Middle), 23c (Bottom).Target Callsign JBU296: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 400AC Scenario.
Figure 24a (24aFigure 24a (Top), 24b (Middle), 24c (Bottom).Target Callsign AAL168: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for MACS 400AC Scenario.
Figure 25a (25aFigure 25a (Top), 25b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 10AC Scenario.
Figure 26a (26aFigure 26a (Top), 26b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 50AC Scenario.
Figure 27a (27aFigure 27a (Top), 27b (Bottom).Target Callsign AAL185: PDF for Latency Received and Recorded, Respectively, for MACS 200AC Scenario.
Figure 32 .32Figure 32.Target Callsign TBED010: Latency for ATG 10AC Scenario.
Figure 34 .34Figure 34.Target Callsign TBED010: Latency for ATG 50AC Scenario.
Figure 37 .37Figure 37. Target Callsign TBED050: Latency for ATG 200AC Scenario.
Figure 38 .38Figure 38.Target Callsign TBED200: Latency for ATG 200AC Scenario.
Figure 40 .40Figure 40.Target Callsign TBED200: Latency for ATG 400AC Scenario.
Figure 43a (43aFigure 43a (Top), 43b (Middle), 43c (Bottom).Target Callsign TBED010: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for ATG 10AC Scenario.
Figure 45a (45aFigure 45a (Top), 45b (Middle), 45c (Bottom).Target Callsign TBED010: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for ATG 50AC Scenario.
Figure 48a (48aFigure 48a (Top), 48b (Middle), 48c (Bottom).Target Callsign TBED050: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for ATG 200AC Scenario.
Figure 50a (50aFigure 50a (Top), 50b (Middle), 50c (Bottom).Target Callsign TBED002: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for ATG 400AC Scenario.
Figure 51a (51aFigure 51a (Top), 51b (Middle), 51c (Bottom).Target Callsign TBED200: Update Rates for Time-Created, Time-Received, and Time-Recorded, Respectively, for ATG 400AC Scenario.
Figure 54a (54aFigure 54a (Top), 54b (Bottom).Target Callsign TBED002: PDF for Latency Received and Latency Recorded, Respectively, for ATG 50AC Scenario.
Figure 55a (55aFigure 55a (Top), 55b (Bottom).Target Callsign TBED002: PDF for Latency Received and Recorded, Respectively, for ATG 200AC Scenario.
Figure 56a (56aFigure 56a(Top), 56b (Bottom).Target Callsign TBED002: PDF for Latency Received and Latency Recorded, Respectively, for ATG 400AC Scenario.



















Table 1 .1Relevant Software Versions..................................................................................................
Table 2 . Aircraft Start Time Intervals for MACS Scenarios2. ........................................................
Table 3 . Aircraft Start Time Intervals for ATG Scenarios3. ...........................................................
Table 4 . Distributed System Setup with MACS4. .............................................................................
Table 5 . Distributed System Setup with ATG5. ................................................................................
Table 6 . MACS Advanced Performance Metrics Latency Received6. ........................................
Table 7 . MACS Advanced Performance Metrics Latency Recorded7. .......................................
Table 8 . MACS Update Rate for Time-Created8. ..............................................................................
Table 9 . MACS Update Rate for Time-Received9. ............................................................................
Table 10 . MACS Update Rate for Time-Recorded10. .........................................................................
Table 11 .11MACS Throughput...............................................................................................................
Table 12 . ATG Advanced Performance Metrics Latency Received12. .........................................
Table 13 . ATG Advanced Performance Metrics Latency Recorded13. ........................................
Table 14 . ATG Update Rate for Time-Created14. ...............................................................................
Table 15 . ATG Update Rate for Time-Received15. .............................................................................
Table 16 . ATG Update Rate for Time-Recorded16. ............................................................................
Table 17 .17ATG Throughput..................................................................................................................
Table 18 .18Documentation Nomenclature.........................................................................................
Table 1 . Relevant Software Versions. Software Version Use1CentOS 77.5.1804-7.6.1810TestBed Infrastructure, ATGWindows 7Version 6.1, Build 7601MACSJava 64-bit1.8.0.040-1.8.0.191ATG, MACSApache ActiveMQ5.15.7TestBed infrastructureGradle4.10.2Build TestBed SoftwareMACSAOL 2018, Developer ModeMACSATG6.4.2ATG
Table 2 . Aircraft Start Time Intervals for MACS Scenarios. Start Sim Time (second s) 10 AC (No. of new aircraft) 25 AC (No. of new aircraft) 50 AC (No. of new aircraft) 75 AC (No. of new aircraft) 100 AC (No. of new aircraft) 200 AC (No. of new aircraft) 300 AC (No. of new aircraft) 400 AC (No. of new aircraft)20251010101081032510101010810625101010108109251010101081012251010101081015N/AN/AN/A10101081018N/AN/AN/A51010810
Table 3 . Aircraft Start Time Intervals for ATG Scenarios. Start Sim Time (seconds) 10 AC 25 AC 50 AC 75 AC 100 AC 200 AC 300 AC 400 AC330101010101010101033N/A1010101010101036N/A510101010101039N/AN/A10101010101042N/AN/A10103030303045N/AN/AN/AN/A30303030
Table 4 . Distributed System Setup with MACS.4SystemCPU PhysicalThreads PerCPUClockUseOSCoresCoreSpeed Maxuasst9413.4GHzActiveMQCentOSBroker7.6.1810vastst9823.5GHzMACSCentOSAdapter,7.5.1804ADRSvastst17413.0GHzLoggerCentOSAdapter,7.6.1810ConnectComponentbetweenMACSandLoggeruasmacs1423.47GHzMACSWindows 7.6.1Build 7601
Table 5 . Distributed System Setup with ATG.5SystemCPU PhysicalThreads PerCPUClockUseOSCoresCoreSpeeduasst9413.4GHzActiveMQCentOSBroker7.6.1810vastst9823.5GHzATG,ATGCentOSAdapter7.5.1804vastst17413.0GHzLoggerCentOSAdapter,7.6.1810ConnectComponentbetween ATGand Logger
Table 6 . MACS Advanced Performance Metrics Latency Received.6ScenarioCallsignMean (ms)StandardSkewnessKurtosisLoadDeviation(ms)10 ACAAL1850.0010.0242.495e65.322e9TCF59950.0230.1989290.0492.336e650 ACAAL1850.0010.0233.007e65.486e9TCF59950.0660.24848.1581306.768UAL10220.0280.028533.3942.274e4200 ACAAL1850.0010.0242.946e65.322e9UAL10220.0890.28516.412465.876JBU2960.0600.23764.9391800.272400 ACAAL1850.0010.0291.275e61.534e9JBU2960.0570.23177.2782179.131AAL1680.0000.000InfinityInfinity
Table 7 . MACS Advanced Performance Metrics Latency Recorded.7ScenarioCallsignMean (ms)StandardSkewnessKurtosisLoadDeviation(ms)10 ACAAL18533.45616.0470.499-2.417TCF599539.80516.0000.504-2.45950 ACAAL18561.85321.5770.497-2.444TCF599585.93017.4610.639-2.239UAL102286.42517.4050.640-2.241200 ACAAL185127.12147.7780.564-1.917UAL1022115.92155.4210.576-2.255JBU296222.83036.2860.679-2.408400 ACAAL185261.651107.0970.472-2.536JBU296407.31271.4960.632-2.424AAL168383.996155.5020.464-2.556
Table 8 . MACS Update Rate for Time-Created.8Scenario LoadCallsignMean (ms)Standard Deviation(ms)10 ACAAL1851000.0000.160TCF5995999.9980.413
Table 9 . MACS Update Rate for Time-Received.9Scenario LoadCallsignMean (ms)Standard Deviation(ms)10 ACAAL1851000.000.170TCF5995999.9980.47250ACAAL1851000.0000.217TCF5995999.9990.647UAL1022999.9990.631200ACAAL1851000.0502.079UAL10221000.3329.414JBU2961000.1203.393400ACAAL1851001.67741.004JBU2961001.33936.629AAL168999.9801.191
Table 10 . MACS Update Rate for Time-Recorded.10Scenario LoadCallsignMean (ms)Standard Deviation(ms)10 ACAAL185999.9776.608TCF5995999.9855.30650ACAAL185999.95920.885TCF5995999.98115.775UAL1022999.98115.766200ACAAL1851000.02139.265UAL10221000.32428.511JBU296999.98921.307400ACAAL1851001.614114.535JBU2961001.48292.805AAL168999.955170.450
Table 11 . MACS Throughput.11Scenario Load Max ThroughputMin ThroughputAverageNominal(KB/s)(KB/s)Throughput (KB/s)Throughput (KB/s)10 AC3.7500.1881.6451.87550 AC18.7500.0007.7629.375200 AC57.5621.87531.94837.500400 AC83.0920.00070.10975.000
Table 13 . ATG Advanced Performance Metrics Latency Recorded.13ScenarioCallsignMean LatencyStandardSkewnessKurtosisLoadRecorded (ms)Deviation Latency RecordedLatency RecordedLatency Recorded(ms)10 ACTBED0022.9881.4062.20321.451TBED0109.0412.2500.724-1.11950 ACTBED0026.9271.33413.784407.802TBED0101.2631.8516.06794.366TBED05037.4933.0840.792-2.255200 ACTBED00219.7632.8600.674-2.388TBED05049.1134.7380.762-2.289TBED200132.4269.1130.820-2.386400 ACTBED00234.7664.4190.702-2.362TBED200146.1389.7500.826-2.216TBED400254.45813.8940.854-2.184
Table 14 . ATG Update Rate for Time-Created.14Scenario LoadCallsignMean (ms)Standard Deviation(ms)10 ACTBED0021000.0000.107TBED0101000.0000.10850ACTBED0021000.0010.208TBED0101000.0010.209TBED0501000.0000.217200ACTBED0021000.0030.900TBED0501000.0020.923TBED2001000.0001.016400ACTBED0021000.57123.857TBED2001000.57524.025TBED4001000.0011.686
Table 15 . ATG Update Rate for Time-Received.15Scenario LoadCallsignMean (ms)Standard Deviation(ms)10 ACTBED002999.9930.389TBED010999.9860.72450ACTBED002999.9950.374TBED010999.9930.698TBED050999.9941.152200ACTBED002999.9971.133TBED0501000.0011.971TBED200999.9974.026
Table 16 . ATG Update Rate for Time-Recorded.16Scenario LoadCallsignMean (ms)Standard Deviation(ms)10 ACTBED002999.9771.077TBED010999.9681.71950ACTBED002999.9881.354TBED010999.9841.812TBED050999.9883.300200ACTBED002999.9994.147TBED0501000.0066.687TBED200999.99312.278400ACTBED0021000.57524.657TBED2001000.57027.328TBED400999.99418.876
Table 17 . ATG Throughput.17ScenarioMax ThroughputMin ThroughputAverageNominalLoad(KB/s)(KB/s)Throughput (KB/s)Throughput (KB/s)10 AC3.7491.8751.8761.87550 AC13.6871.8759.3469.375200 AC 44.2501.68737.17937.500400 AC 77.6240.00074.05175.0001200 AC 224.9997.373209.519225.000
.11 Latency Trends of Mean and Standard Deviation for Varying Aircraft Load in ATG Figure57a (Left), 57b (Right).Mean Latency and Standard Deviation for Target Callsign TBED002 in ATG.
Table 18 . Documentation Nomenclature.18AcronymNameAALAmerican AirlinesACAircraftADRSAeronautical Data Link and RadarSimulatorAOLAirspace Operations LaboratoryATGAir Traffic GeneratorCPUCentral Processing UnitDSRLDistributed Simulation and Research LabDDSData Distribution ServiceGUIGraphical User InterfaceIPInternet ProtocolJBUJetBlue Airways.KBKilobyteLVCLive Virtual ConstructiveMACSMulti Aircraft Control SystemMPIMulti-Purpose InterfaceNASNational Airspace SystemNASANationalAeronauticsandSpaceAdministrationNATSNeural Autonomic Transport SystemNTPNetwork Time ProtocolPDFProbability Density FunctionSDKSoftware Development Kit
			Scientific and technical findings that are preliminary or of specialized interest, e.g., quick release reports, working
		
		

			
AcknowledgmentsThis test and the data analysis were funded by NASA's Unmanned Aircraft Systems (UAS) Integration in the National Airspace System (NAS) project contract number 80ARC018D0008 which is gratefully acknowledged.The authors would like to acknowledge Jeff Hernandez for assisting the second author with setting up the TestBed environment for testing, and Charles Walter for explaining MACS behavior for high air traffic loads.The authors want to thank the TestBed team, Alan Lee, Chok Fung Lai, Phu Huynh, and Jimmy Nguyen for their help to understand finer details of the TestBed infrastructure.
			

			
Update Rate Trends of Mean and Standard Deviation for Varying Aircraft Load in MACSFigure 30a (Top),30b (Middle),30c (Bottom).Mean Update Rates and Standard Deviation for Target Callsign AAL185 in MACS.Figures 30a-c show the behaviors of the mean and standard deviation for the update rate created, received, and recorded for aircraft target AAL185, respectively, at loads of 10, 50, 200, and 400 aircraft.It is apparent from all figures that as aircraft load increases, so does the standard deviation and mean update rate created.It should be noted that the mean and standard deviation values are larger for the update rate recorded versus the update rate created and received.
ATGLike MACS, ATG scenarios chosen for analysis were 10, 50, 200 and 400 aircraft.The aircraft presented for analysis are TBED002, TBED010, TBED050, TBED200, and TBED400.These aircraft are chosen to demonstrate the behavior of target call signs that are loaded into the scenario at significantly different times.The latency characteristics of aircraft callsign TBED050 is seen in Figure 35.This aircraft is the last aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for timereceived is 4.7474 milliseconds.While the mean latency for time-recorded is 37.493 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the simulation, there is a notable ramping down for the latency recorded and latency received that lasts for a few seconds.The mean latency received and mean latency recorded for TBED050 is higher than the same callsign in the 10 aircraft simulation.Note that the mean latency received and mean latency recorded is higher for TBED050 than TBED010, and TBED002.The overall latency behavior can be described as noisy with occasional valleys.
Latency of aircraft in 200AC scenario: (TBED002, TBED050, TBED200)Figure 36.Target Callsign TBED002: Latency for ATG 200AC Scenario.The latency characteristics of aircraft callsign TBED002 is seen in Figure 36.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for time-received is 0.5539 milliseconds.While the mean latency for time-recorded is 19.762 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.At the beginning of the simulation, there is a notable ramping up for the latency recorded and latency received that lasts for a few seconds.This ramping behavior is the opposite of what was seen for TBED002 in loads of 10 and 50 aircraft which displayed behavior of ramping down at the beginning of the simulation.The mean latency received and mean latency recorded for TBED002 is higher than the same callsign in the 10 and 50 aircraft simulations.The overall latency behavior can be described as noisy with occasional valleys.The latency characteristics of aircraft callsign TBED400 is seen in Figure 41.This aircraft is the last aircraft loaded into the simulation and exists until the simulation is stopped.The load is consistent through the scenario as denoted by the dotted orange line.The mean latency for timereceived is 30.771milliseconds.While the mean latency for time-recorded is 254.45 milliseconds.Spikes in latency are throughout the simulation.Noise in the latency received is notable throughout the entire simulation.There is no ramping up or down of latency that is notable at the beginning of the scenario.This is in contrast to the other aircraft call signs in the other ATG simulations.Note that the mean latency received and mean latency recorded is larger for TBED400 than TBED200 and TBED002.The overall latency behavior can be described as noisy with occasional valleys.The update rate characteristics of aircraft callsign TBED002 is seen in Figures 42a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from The update rate characteristics of aircraft callsign TBED002 is seen in Figures 44a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 44a.Figure 44b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 44c do not seem to have any clear relationship to the spikes seen in Figures 44a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the data is noisier for TBED002 in this scenario than in the simulation with 10 aircraft.The update rate characteristics of aircraft callsign TBED050 is seen in Figures 46a-c.This aircraft is the last aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 46a.Figure 46b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 46c do not seem to have any clear relationship to the spikes seen in Figures 46a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.The update rate characteristics of aircraft callsign TBED002 is seen in Figures 47a-c.This aircraft is one of the first aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 47a.Figure 47b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 47c do not seem to have any clear relationship to the spikes seen in Figures 47a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the noise is more prominent for TBED002 in this simulation than the 10 and 50 aircraft simulations.The update rate characteristics of aircraft callsign TBED200 is seen in Figures 49a-c.This aircraft is the final aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 49a.Figure 49b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 49c do not seem to have any clear relationship to the spikes seen in Figures 49a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that that the update rates for TBED200 are noisier than the update rates for TBED002 and TBED050.The update rate characteristics of aircraft callsign TBED400 is seen in Figures 52a-c.This aircraft is the last aircraft loaded into the simulation and exists until the simulation ends.The load is constant throughout the simulation as denoted by the dotted orange line.The mean update rates for time-created, time-received, and time-recorded do not significantly deviate from 1 second.There are various locations throughout the simulation where spikes in latency for update rate created can be observed as seen in Figure 52a.Figure 52b also shows spikes in the update rate received data; however, they do not clearly correspond to the update rate created data.Like the update rate received, the time-recorded update rates in Figure 52c do not seem to have any clear relationship to the spikes seen in Figures 52a-b.Rather, noise around the mean of 1 second is small with small spikes throughout the aircraft lifespan.Note that the noise is more prominent for TBED400 than the TBED002 and TBED200 in this aircraft simulation.
Update rate of aircraft in 10AC scenario: (TBED002, TBED010)
Update rate of aircraft in 50AC scenario: (TBED002, TBED010, TBED050)
Update rate of aircraft in 200AC scenario: (TBED002, TBED050, TBED200)
Update Rate Trends of Mean and Standard Deviation for Varying Aircraft Load in ATG
Figure 58a (Top), 58b (Middle). 58c (Bottom). Mean Update Rates and Standard Deviation for Target Callsign TBED002 in ATG.Figures 58a-c shows the behaviors of the mean and standard deviation for the update rate created, received, and recorded for aircraft target TBED002, respectively, at loads of 10, 50, 200, and 400 aircraft.It is apparent from all figures that as aircraft load increases, so does the standard deviation and mean update rate created.It should be noted that the mean and standard deviation values are larger for the update rate recorded versus the update rate created and received.Figure 59 depicts the trends of the mean and standard deviation for the latency received for both MACS and ATG.A dot is used to signify data acquired from MACS, while a diamond marker is used to signify data from ATG.It is clear that the mean and standard deviation for the latency received with MACS as a target generator is consistently near 0 milliseconds for all loads.This is in contrast to ATG, where the standard deviation and mean latency received trend upward as aircraft load increases.Note that both latency standard deviations are small with the range between 0 and 0.6 milliseconds.Figure 60 depicts the trends of the mean and standard deviation for the latency recorded for both MACS and ATG.A dot symbol is used to signify data acquired from MACS, while a diamond symbol is used to signify data from ATG.The mean and standard deviation for the latency recorded for ATG is approximately 0 milliseconds and slowly increases with the increasing traffic load.For MACS, the mean latency recorded starts near 50 milliseconds and increases up to 250 milliseconds.The standard deviation for the latency recorded for MACS ranges from 20 milliseconds to 100 milliseconds under increasing load.
Comparison between ATG and MACS Latency Trends
ConclusionsThe results of the data analysis exhibited not only the performance of the TestBed system depicted in Figure 1 and 2, but also the performance of the target generators utilized in this study.Data analysis of the performed load tests for the tested system configuration shows that the performance of the overall system strongly coupled on the performance of both data sources as aircraft load increases.It appears that MACS shows better latency performance with smaller aircraft loads when compared to ATG.However, the tests show that ATG can handle a larger number of aircraft in the TestBed infrastructure before the performance begins to degrade.MACS performance begins to degrade for scenarios containing between 200 and 300 aircraft (200 aircraft = 37.5.KB/s nominal throughput), while ATG can support up to 1200 aircraft (225.KB/s nominal throughput) for an extended period of time.From the latency trends for both MACS and ATG, it is clear that as aircraft load increases, the latency in the system increases linearly.Likewise, the trends for the update data rate for both MACS and ATG show that as the aircraft load increases on the system, so does the standard deviation and mean of the update rates.It was observed that the latency recorded was significantly larger than the latency received when using MACS or ATG.Note that latency for time received is defined as the difference between the time created by the source and the time received by TestBed, and similarly the latency for time recorded is defined as the difference between the time created and the time recorded.ATG achieved mean latency recorded values between approximately 1 millisecond and 255 milliseconds for traffic loads between 10 and 400 aircraft (1.875 and 75 KB/s nominal throughput, respectively), while MACS achieved mean latency based on time-recorded values between approximately 33 milliseconds and 408 milliseconds for loads between 10 and 400 aircraft.For the mean latency received values, ATG achieved values between approximately 0 milliseconds and 31 milliseconds for traffic loads between 10 and 400 aircraft, while MACS values remained at approximately 0 milliseconds for traffic loads between 10 and 400 aircraft.Update rates for each target generator hovered around 1 second as expected.However, it should be noted that for MACS to achieve this behavior, a feature had to be disabled which automatically adjusted the dispatch rate of targets to 0.5 Hz based upon load.Perhaps the most telling statistic on the stability and performance of TestBed under different target generators is the standard deviation.This metric can help understand how consistent and stable the data is around the mean values obtained above.For the latency recorded for tests with MACS, standard deviations ranged between approximately 16 milliseconds and 108 milliseconds, while standard deviations in ATG ranged between approximately 1 millisecond and 14 milliseconds.For the latency received data for MACS, standard deviations ranged between approximately 0 milliseconds and 0.3 milliseconds, while standard deviations in ATG ranged between approximately 0 milliseconds and 4 milliseconds.In all cases, the standard deviation increased linearly for increasing load.From this data, it is reasonable to conclude that ATG is the more stable target generator for increasing loads within the TestBed infrastructure.Standard deviations and the mean for the update rates are just as important as it is for the latency in the system.For MACS, the standard deviations for the update rate of time-created ranged between approximately 0 milliseconds and 42 milliseconds with a mean between 999 milliseconds and 1001 milliseconds.Meanwhile, ATG exhibited a tighter standard deviation range between approximately 0 milliseconds and 25 milliseconds with a mean between 1000 milliseconds and 1000.6 milliseconds.For the update rate of time-received, MACS had a standard deviation between approximately 0 milliseconds and 41 milliseconds with a mean between 999 milliseconds and 1001 milliseconds.Meanwhile, ATG had a standard deviation that ranged			
			

				
			
		
	
